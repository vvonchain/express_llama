import OpenAI$1, { ClientOptions as ClientOptions$1 } from 'openai';
import { Portkey as Portkey$1, LLMOptions } from 'portkey-ai';
import Anthropic$1, { ClientOptions } from '@anthropic-ai/sdk';
import Replicate from 'replicate';
import * as _xenova_transformers from '@xenova/transformers';
import * as assemblyai from 'assemblyai';
import { BaseServiceParams, TranscribeParams, SubtitleFormat, AssemblyAI } from 'assemblyai';
export { SubtitleFormat, TranscribeParams } from 'assemblyai';
import { ParseConfig } from 'papaparse';
import { Client } from '@notionhq/client';
import { Pages, Crawler } from 'notion-md-crawler';
import { MongoClient, BulkWriteOptions } from 'mongodb';
import { AstraDB } from '@datastax/astra-db-ts';
import { CreateCollectionOptions } from '@datastax/astra-db-ts/dist/collections/options';
import pg from 'pg';

declare enum NodeRelationship {
    SOURCE = "SOURCE",
    PREVIOUS = "PREVIOUS",
    NEXT = "NEXT",
    PARENT = "PARENT",
    CHILD = "CHILD"
}
declare enum ObjectType {
    TEXT = "TEXT",
    IMAGE = "IMAGE",
    INDEX = "INDEX",
    DOCUMENT = "DOCUMENT",
    IMAGE_DOCUMENT = "IMAGE_DOCUMENT"
}
declare enum MetadataMode {
    ALL = "ALL",
    EMBED = "EMBED",
    LLM = "LLM",
    NONE = "NONE"
}
type Metadata = Record<string, any>;
interface RelatedNodeInfo<T extends Metadata = Metadata> {
    nodeId: string;
    nodeType?: ObjectType;
    metadata: T;
    hash?: string;
}
type RelatedNodeType<T extends Metadata = Metadata> = RelatedNodeInfo<T> | RelatedNodeInfo<T>[];
/**
 * Generic abstract class for retrievable nodes
 */
declare abstract class BaseNode<T extends Metadata = Metadata> {
    /**
     * The unique ID of the Node/Document. The trailing underscore is here
     * to avoid collisions with the id keyword in Python.
     *
     * Set to a UUID by default.
     */
    id_: string;
    embedding?: number[];
    metadata: T;
    excludedEmbedMetadataKeys: string[];
    excludedLlmMetadataKeys: string[];
    relationships: Partial<Record<NodeRelationship, RelatedNodeType<T>>>;
    hash: string;
    constructor(init?: Partial<BaseNode<T>>);
    abstract getType(): ObjectType;
    abstract getContent(metadataMode: MetadataMode): string;
    abstract getMetadataStr(metadataMode: MetadataMode): string;
    abstract setContent(value: any): void;
    get sourceNode(): RelatedNodeInfo<T> | undefined;
    get prevNode(): RelatedNodeInfo<T> | undefined;
    get nextNode(): RelatedNodeInfo<T> | undefined;
    get parentNode(): RelatedNodeInfo<T> | undefined;
    get childNodes(): RelatedNodeInfo<T>[] | undefined;
    abstract generateHash(): string;
    getEmbedding(): number[];
    asRelatedNodeInfo(): RelatedNodeInfo<T>;
    /**
     * Used with built in JSON.stringify
     * @returns
     */
    toJSON(): Record<string, any>;
}
/**
 * TextNode is the default node type for text. Most common node type in LlamaIndex.TS
 */
declare class TextNode<T extends Metadata = Metadata> extends BaseNode<T> {
    text: string;
    startCharIdx?: number;
    endCharIdx?: number;
    metadataSeparator: string;
    constructor(init?: Partial<TextNode<T>>);
    /**
     * Generate a hash of the text node.
     * The ID is not part of the hash as it can change independent of content.
     * @returns
     */
    generateHash(): string;
    getType(): ObjectType;
    getContent(metadataMode?: MetadataMode): string;
    getMetadataStr(metadataMode: MetadataMode): string;
    setContent(value: string): void;
    getNodeInfo(): {
        start: number | undefined;
        end: number | undefined;
    };
    getText(): string;
}
declare class IndexNode<T extends Metadata = Metadata> extends TextNode<T> {
    indexId: string;
    constructor(init?: Partial<IndexNode<T>>);
    getType(): ObjectType;
}
/**
 * A document is just a special text node with a docId.
 */
declare class Document<T extends Metadata = Metadata> extends TextNode<T> {
    constructor(init?: Partial<Document<T>>);
    getType(): ObjectType;
}
declare function jsonToNode(json: any, type?: ObjectType): TextNode<Metadata>;
type ImageType = string | Blob | URL;
type ImageNodeConstructorProps<T extends Metadata> = Pick<ImageNode<T>, "image" | "id_"> & Partial<ImageNode<T>>;
declare class ImageNode<T extends Metadata = Metadata> extends TextNode<T> {
    image: ImageType;
    constructor(init: ImageNodeConstructorProps<T>);
    getType(): ObjectType;
    getUrl(): URL;
}
declare class ImageDocument<T extends Metadata = Metadata> extends ImageNode<T> {
    constructor(init: ImageNodeConstructorProps<T>);
    getType(): ObjectType;
}
/**
 * A node with a similarity score
 */
interface NodeWithScore<T extends Metadata = Metadata> {
    node: BaseNode<T>;
    score?: number;
}
declare function splitNodesByType(nodes: BaseNode[]): {
    imageNodes: ImageNode[];
    textNodes: TextNode[];
};

type EventTag = "intermediate" | "final";
type EventType = "retrieve" | "llmPredict" | "wrapper";
interface Event {
    id: string;
    type: EventType;
    tags?: EventTag[];
    parentId?: string;
}
interface BaseCallbackResponse {
    event: Event;
}
interface DefaultStreamToken {
    id: string;
    object: string;
    created: number;
    model: string;
    choices: {
        index: number;
        delta: {
            content?: string | null;
            role?: "user" | "assistant" | "system" | "function" | "tool";
        };
        finish_reason: string | null;
    }[];
}
type OpenAIStreamToken = DefaultStreamToken;
type AnthropicStreamToken = {
    completion: string;
    model: string;
    stop_reason: string | undefined;
    stop?: boolean | undefined;
    log_id?: string;
};
interface StreamCallbackResponse extends BaseCallbackResponse {
    index: number;
    isDone?: boolean;
    token?: DefaultStreamToken;
}
interface RetrievalCallbackResponse extends BaseCallbackResponse {
    query: string;
    nodes: NodeWithScore[];
}
interface CallbackManagerMethods {
    onLLMStream?: (params: StreamCallbackResponse) => Promise<void> | void;
    onRetrieve?: (params: RetrievalCallbackResponse) => Promise<void> | void;
}
declare class CallbackManager implements CallbackManagerMethods {
    onLLMStream?: (params: StreamCallbackResponse) => Promise<void> | void;
    onRetrieve?: (params: RetrievalCallbackResponse) => Promise<void> | void;
    constructor(handlers?: CallbackManagerMethods);
}

declare enum Tokenizers {
    CL100K_BASE = "cl100k_base"
}
/**
 * Helper class singleton
 */
declare class GlobalsHelper {
    defaultTokenizer: {
        encode: (text: string) => Uint32Array;
        decode: (tokens: Uint32Array) => string;
    } | null;
    private initDefaultTokenizer;
    tokenizer(encoding?: string): (text: string) => Uint32Array;
    tokenizerDecoder(encoding?: string): (tokens: Uint32Array) => string;
    createEvent({ parentEvent, type, tags, }: {
        parentEvent?: Event;
        type: EventType;
        tags?: EventTag[];
    }): Event;
}
declare const globalsHelper: GlobalsHelper;

declare class AnthropicSession {
    anthropic: Anthropic$1;
    constructor(options?: ClientOptions);
}

interface AzureOpenAIConfig {
    apiKey?: string;
    endpoint?: string;
    apiVersion?: string;
    deploymentName?: string;
}

declare class OpenAISession {
    openai: OpenAI$1;
    constructor(options?: ClientOptions$1 & {
        azure?: boolean;
    });
}

interface PortkeyOptions {
    apiKey?: string;
    baseURL?: string;
    mode?: string;
    llms?: [LLMOptions] | null;
}
declare class PortkeySession {
    portkey: Portkey$1;
    constructor(options?: PortkeyOptions);
}

declare class ReplicateSession {
    replicateKey: string | null;
    replicate: Replicate;
    constructor(replicateKey?: string | null);
}

type MessageType = "user" | "assistant" | "system" | "generic" | "function" | "memory";
interface ChatMessage {
    content: any;
    role: MessageType;
}
interface ChatResponse {
    message: ChatMessage;
    raw?: Record<string, any>;
    delta?: string;
}
type CompletionResponse = ChatResponse;
interface LLMMetadata {
    model: string;
    temperature: number;
    topP: number;
    maxTokens?: number;
    contextWindow: number;
    tokenizer: Tokenizers | undefined;
}
/**
 * Unified language model interface
 */
interface LLM {
    metadata: LLMMetadata;
    hasStreaming: boolean;
    /**
     * Get a chat response from the LLM
     * @param messages
     *
     * The return type of chat() and complete() are set by the "streaming" parameter being set to True.
     */
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(messages: ChatMessage[], parentEvent?: Event, streaming?: T): Promise<R>;
    /**
     * Get a prompt completion from the LLM
     * @param prompt the prompt to complete
     */
    complete<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(prompt: MessageContent, parentEvent?: Event, streaming?: T): Promise<R>;
    /**
     * Calculates the number of tokens needed for the given chat messages
     */
    tokens(messages: ChatMessage[]): number;
}
declare const GPT4_MODELS: {
    "gpt-4": {
        contextWindow: number;
    };
    "gpt-4-32k": {
        contextWindow: number;
    };
    "gpt-4-1106-preview": {
        contextWindow: number;
    };
    "gpt-4-vision-preview": {
        contextWindow: number;
    };
};
declare const GPT35_MODELS: {
    "gpt-3.5-turbo": {
        contextWindow: number;
    };
    "gpt-3.5-turbo-16k": {
        contextWindow: number;
    };
    "gpt-3.5-turbo-1106": {
        contextWindow: number;
    };
};
/**
 * We currently support GPT-3.5 and GPT-4 models
 */
declare const ALL_AVAILABLE_OPENAI_MODELS: {
    "gpt-3.5-turbo": {
        contextWindow: number;
    };
    "gpt-3.5-turbo-16k": {
        contextWindow: number;
    };
    "gpt-3.5-turbo-1106": {
        contextWindow: number;
    };
    "gpt-4": {
        contextWindow: number;
    };
    "gpt-4-32k": {
        contextWindow: number;
    };
    "gpt-4-1106-preview": {
        contextWindow: number;
    };
    "gpt-4-vision-preview": {
        contextWindow: number;
    };
};
/**
 * OpenAI LLM implementation
 */
declare class OpenAI implements LLM {
    hasStreaming: boolean;
    model: keyof typeof ALL_AVAILABLE_OPENAI_MODELS;
    temperature: number;
    topP: number;
    maxTokens?: number;
    additionalChatOptions?: Omit<Partial<OpenAI$1.Chat.ChatCompletionCreateParams>, "max_tokens" | "messages" | "model" | "temperature" | "top_p" | "streaming">;
    apiKey?: string;
    maxRetries: number;
    timeout?: number;
    session: OpenAISession;
    additionalSessionOptions?: Omit<Partial<ClientOptions$1>, "apiKey" | "maxRetries" | "timeout">;
    callbackManager?: CallbackManager;
    constructor(init?: Partial<OpenAI> & {
        azure?: AzureOpenAIConfig;
    });
    get metadata(): {
        model: "gpt-3.5-turbo" | "gpt-3.5-turbo-1106" | "gpt-3.5-turbo-16k" | "gpt-4" | "gpt-4-32k" | "gpt-4-1106-preview" | "gpt-4-vision-preview";
        temperature: number;
        topP: number;
        maxTokens: number | undefined;
        contextWindow: number;
        tokenizer: Tokenizers;
    };
    tokens(messages: ChatMessage[]): number;
    mapMessageType(messageType: MessageType): "user" | "assistant" | "system" | "function";
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(messages: ChatMessage[], parentEvent?: Event, streaming?: T): Promise<R>;
    complete<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(prompt: string, parentEvent?: Event, streaming?: T): Promise<R>;
    protected streamChat(messages: ChatMessage[], parentEvent?: Event): AsyncGenerator<string, void, unknown>;
    protected streamComplete(query: string, parentEvent?: Event): AsyncGenerator<string, void, unknown>;
}
declare const ALL_AVAILABLE_LLAMADEUCE_MODELS: {
    "Llama-2-70b-chat-old": {
        contextWindow: number;
        replicateApi: string;
    };
    "Llama-2-70b-chat-4bit": {
        contextWindow: number;
        replicateApi: string;
    };
    "Llama-2-13b-chat-old": {
        contextWindow: number;
        replicateApi: string;
    };
    "Llama-2-13b-chat-4bit": {
        contextWindow: number;
        replicateApi: string;
    };
    "Llama-2-7b-chat-old": {
        contextWindow: number;
        replicateApi: string;
    };
    "Llama-2-7b-chat-4bit": {
        contextWindow: number;
        replicateApi: string;
    };
};
declare enum DeuceChatStrategy {
    A16Z = "a16z",
    META = "meta",
    METAWBOS = "metawbos",
    REPLICATE4BIT = "replicate4bit",
    REPLICATE4BITWNEWLINES = "replicate4bitwnewlines"
}
/**
 * Llama2 LLM implementation
 */
declare class LlamaDeuce implements LLM {
    model: keyof typeof ALL_AVAILABLE_LLAMADEUCE_MODELS;
    chatStrategy: DeuceChatStrategy;
    temperature: number;
    topP: number;
    maxTokens?: number;
    replicateSession: ReplicateSession;
    hasStreaming: boolean;
    constructor(init?: Partial<LlamaDeuce>);
    tokens(messages: ChatMessage[]): number;
    get metadata(): {
        model: "Llama-2-70b-chat-old" | "Llama-2-70b-chat-4bit" | "Llama-2-13b-chat-old" | "Llama-2-13b-chat-4bit" | "Llama-2-7b-chat-old" | "Llama-2-7b-chat-4bit";
        temperature: number;
        topP: number;
        maxTokens: number | undefined;
        contextWindow: number;
        tokenizer: undefined;
    };
    mapMessagesToPrompt(messages: ChatMessage[]): {
        prompt: string;
        systemPrompt: any;
    };
    mapMessagesToPromptA16Z(messages: ChatMessage[]): {
        prompt: string;
        systemPrompt: undefined;
    };
    mapMessageTypeA16Z(messageType: MessageType): string;
    mapMessagesToPromptMeta(messages: ChatMessage[], opts?: {
        withBos?: boolean;
        replicate4Bit?: boolean;
        withNewlines?: boolean;
    }): {
        prompt: string;
        systemPrompt: any;
    };
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(messages: ChatMessage[], _parentEvent?: Event, streaming?: T): Promise<R>;
    complete<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(prompt: string, parentEvent?: Event, streaming?: T): Promise<R>;
}
declare const ALL_AVAILABLE_ANTHROPIC_MODELS: {
    "claude-2": {
        contextWindow: number;
    };
    "claude-instant-1": {
        contextWindow: number;
    };
};
/**
 * Anthropic LLM implementation
 */
declare class Anthropic implements LLM {
    hasStreaming: boolean;
    model: keyof typeof ALL_AVAILABLE_ANTHROPIC_MODELS;
    temperature: number;
    topP: number;
    maxTokens?: number;
    apiKey?: string;
    maxRetries: number;
    timeout?: number;
    session: AnthropicSession;
    callbackManager?: CallbackManager;
    constructor(init?: Partial<Anthropic>);
    tokens(messages: ChatMessage[]): number;
    get metadata(): {
        model: "claude-2" | "claude-instant-1";
        temperature: number;
        topP: number;
        maxTokens: number | undefined;
        contextWindow: number;
        tokenizer: undefined;
    };
    mapMessagesToPrompt(messages: ChatMessage[]): string;
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(messages: ChatMessage[], parentEvent?: Event | undefined, streaming?: T): Promise<R>;
    protected streamChat(messages: ChatMessage[], parentEvent?: Event | undefined): AsyncGenerator<string, void, unknown>;
    complete<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(prompt: string, parentEvent?: Event | undefined, streaming?: T): Promise<R>;
    protected streamComplete(prompt: string, parentEvent?: Event | undefined): AsyncGenerator<string, void, unknown>;
}
declare class Portkey implements LLM {
    hasStreaming: boolean;
    apiKey?: string;
    baseURL?: string;
    mode?: string;
    llms?: [LLMOptions] | null;
    session: PortkeySession;
    callbackManager?: CallbackManager;
    constructor(init?: Partial<Portkey>);
    tokens(messages: ChatMessage[]): number;
    get metadata(): LLMMetadata;
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(messages: ChatMessage[], parentEvent?: Event | undefined, streaming?: T, params?: Record<string, any>): Promise<R>;
    complete<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(prompt: string, parentEvent?: Event | undefined, streaming?: T): Promise<R>;
    streamChat(messages: ChatMessage[], parentEvent?: Event, params?: Record<string, any>): AsyncGenerator<string, void, unknown>;
    streamComplete(query: string, parentEvent?: Event): AsyncGenerator<string, void, unknown>;
}

/**
 * An OutputParser is used to extract structured data from the raw output of the LLM.
 */
interface BaseOutputParser<T> {
    parse(output: string): T;
    format(output: string): string;
}
/**
 * StructuredOutput is just a combo of the raw output and the parsed output.
 */
interface StructuredOutput<T> {
    rawOutput: string;
    parsedOutput: T;
}
/**
 *
 * @param text A markdown block with JSON
 * @returns parsed JSON object
 */
declare function parseJsonMarkdown(text: string): any;
/**
 * SubQuestionOutputParser is used to parse the output of the SubQuestionGenerator.
 */
declare class SubQuestionOutputParser implements BaseOutputParser<StructuredOutput<SubQuestion[]>> {
    parse(output: string): StructuredOutput<SubQuestion[]>;
    format(output: string): string;
}

interface SubQuestion {
    subQuestion: string;
    toolName: string;
}
/**
 * QuestionGenerators generate new questions for the LLM using tools and a user query.
 */
interface BaseQuestionGenerator {
    generate(tools: ToolMetadata[], query: string): Promise<SubQuestion[]>;
}
/**
 * LLMQuestionGenerator uses the LLM to generate new questions for the LLM using tools and a user query.
 */
declare class LLMQuestionGenerator implements BaseQuestionGenerator {
    llm: LLM;
    prompt: SubQuestionPrompt;
    outputParser: BaseOutputParser<StructuredOutput<SubQuestion[]>>;
    constructor(init?: Partial<LLMQuestionGenerator>);
    generate(tools: ToolMetadata[], query: string): Promise<SubQuestion[]>;
}

/**
 * Respone is the output of a LLM
 */
declare class Response {
    response: string;
    sourceNodes?: BaseNode[];
    constructor(response: string, sourceNodes?: BaseNode[]);
    getFormattedSources(): void;
    toString(): string;
}

/**
 * Similarity type
 * Default is cosine similarity. Dot product and negative Euclidean distance are also supported.
 */
declare enum SimilarityType {
    DEFAULT = "cosine",
    DOT_PRODUCT = "dot_product",
    EUCLIDEAN = "euclidean"
}
declare abstract class BaseEmbedding {
    similarity(embedding1: number[], embedding2: number[], mode?: SimilarityType): number;
    abstract getTextEmbedding(text: string): Promise<number[]>;
    abstract getQueryEmbedding(query: string): Promise<number[]>;
}

declare abstract class MultiModalEmbedding extends BaseEmbedding {
    abstract getImageEmbedding(images: ImageType): Promise<number[]>;
    getImageEmbeddings(images: ImageType[]): Promise<number[][]>;
}

declare enum ClipEmbeddingModelType {
    XENOVA_CLIP_VIT_BASE_PATCH32 = "Xenova/clip-vit-base-patch32",
    XENOVA_CLIP_VIT_BASE_PATCH16 = "Xenova/clip-vit-base-patch16"
}
declare class ClipEmbedding extends MultiModalEmbedding {
    modelType: ClipEmbeddingModelType;
    private tokenizer;
    private processor;
    private visionModel;
    private textModel;
    getTokenizer(): Promise<any>;
    getProcessor(): Promise<any>;
    getVisionModel(): Promise<any>;
    getTextModel(): Promise<any>;
    getImageEmbedding(image: ImageType): Promise<number[]>;
    getTextEmbedding(text: string): Promise<number[]>;
    getQueryEmbedding(query: string): Promise<number[]>;
}

declare enum MistralAIEmbeddingModelType {
    MISTRAL_EMBED = "mistral-embed"
}
declare class MistralAIEmbedding extends BaseEmbedding {
    model: MistralAIEmbeddingModelType;
    apiKey?: string;
    private session;
    constructor(init?: Partial<MistralAIEmbedding>);
    private getMistralAIEmbedding;
    getTextEmbedding(text: string): Promise<number[]>;
    getQueryEmbedding(query: string): Promise<number[]>;
}

declare enum OpenAIEmbeddingModelType {
    TEXT_EMBED_ADA_002 = "text-embedding-ada-002"
}
declare class OpenAIEmbedding extends BaseEmbedding {
    model: OpenAIEmbeddingModelType;
    apiKey?: string;
    maxRetries: number;
    timeout?: number;
    additionalSessionOptions?: Omit<Partial<ClientOptions$1>, "apiKey" | "maxRetries" | "timeout">;
    session: OpenAISession;
    constructor(init?: Partial<OpenAIEmbedding> & {
        azure?: AzureOpenAIConfig;
    });
    private getOpenAIEmbedding;
    getTextEmbedding(text: string): Promise<number[]>;
    getQueryEmbedding(query: string): Promise<number[]>;
}

/**
 * A filesystem interface that is meant to be compatible with
 * the 'fs' module from Node.js.
 * Allows for the use of similar inteface implementation on
 * browsers.
 */
interface GenericFileSystem {
    writeFile(path: string, content: string, options?: any): Promise<void>;
    readFile(path: string, options?: any): Promise<string>;
    access(path: string): Promise<void>;
    mkdir(path: string, options?: any): Promise<void>;
}
interface WalkableFileSystem {
    readdir(path: string): Promise<string[]>;
    stat(path: string): Promise<any>;
}
/**
 * A filesystem implementation that stores files in memory.
 */
declare class InMemoryFileSystem implements GenericFileSystem {
    private files;
    writeFile(path: string, content: string, options?: any): Promise<void>;
    readFile(path: string, options?: any): Promise<string>;
    access(path: string): Promise<void>;
    mkdir(path: string, options?: any): Promise<void>;
}
type CompleteFileSystem = GenericFileSystem & WalkableFileSystem;
declare function getNodeFS(): CompleteFileSystem;
declare const DEFAULT_FS: GenericFileSystem | CompleteFileSystem;
/**
 * Checks if a file exists.
 * Analogous to the os.path.exists function from Python.
 * @param fs The filesystem to use.
 * @param path The path to the file to check.
 * @returns A promise that resolves to true if the file exists, false otherwise.
 */
declare function exists(fs: GenericFileSystem, path: string): Promise<boolean>;
/**
 * Recursively traverses a directory and yields all the paths to the files in it.
 * @param fs The filesystem to use.
 * @param dirPath The path to the directory to traverse.
 */
declare function walk(fs: WalkableFileSystem, dirPath: string): AsyncIterable<string>;

interface RefDocInfo {
    nodeIds: string[];
    extraInfo: Record<string, any>;
}
declare abstract class BaseDocumentStore {
    persist(persistPath?: string, fs?: GenericFileSystem): void;
    abstract docs(): Promise<Record<string, BaseNode>>;
    abstract addDocuments(docs: BaseNode[], allowUpdate: boolean): Promise<void>;
    abstract getDocument(docId: string, raiseError: boolean): Promise<BaseNode | undefined>;
    abstract deleteDocument(docId: string, raiseError: boolean): Promise<void>;
    abstract documentExists(docId: string): Promise<boolean>;
    abstract setDocumentHash(docId: string, docHash: string): void;
    abstract getDocumentHash(docId: string): Promise<string | undefined>;
    abstract getAllRefDocInfo(): Promise<Record<string, RefDocInfo> | undefined>;
    abstract getRefDocInfo(refDocId: string): Promise<RefDocInfo | undefined>;
    abstract deleteRefDoc(refDocId: string, raiseError: boolean): Promise<void>;
    getNodes(nodeIds: string[], raiseError?: boolean): Promise<BaseNode[]>;
    getNode(nodeId: string, raiseError?: boolean): Promise<BaseNode>;
    getNodeDict(nodeIdDict: {
        [index: number]: string;
    }): Promise<Record<number, BaseNode>>;
}

interface VectorStoreQueryResult {
    nodes?: BaseNode[];
    similarities: number[];
    ids: string[];
}
declare enum VectorStoreQueryMode {
    DEFAULT = "default",
    SPARSE = "sparse",
    HYBRID = "hybrid",
    SVM = "svm",
    LOGISTIC_REGRESSION = "logistic_regression",
    LINEAR_REGRESSION = "linear_regression",
    MMR = "mmr"
}
interface ExactMatchFilter {
    filterType: "ExactMatch";
    key: string;
    value: string | number;
}
interface MetadataFilters {
    filters: ExactMatchFilter[];
}
interface VectorStoreQuerySpec {
    query: string;
    filters: ExactMatchFilter[];
    topK?: number;
}
interface MetadataInfo {
    name: string;
    type: string;
    description: string;
}
interface VectorStoreInfo {
    metadataInfo: MetadataInfo[];
    contentInfo: string;
}
interface VectorStoreQuery {
    queryEmbedding?: number[];
    similarityTopK: number;
    docIds?: string[];
    queryStr?: string;
    mode: VectorStoreQueryMode;
    alpha?: number;
    filters?: MetadataFilters;
    mmrThreshold?: number;
}
interface VectorStore {
    storesText: boolean;
    isEmbeddingQuery?: boolean;
    client(): any;
    add(embeddingResults: BaseNode[]): Promise<string[]>;
    delete(refDocId: string, deleteOptions?: any): Promise<void>;
    query(query: VectorStoreQuery, options?: any): Promise<VectorStoreQueryResult>;
}

/**
 * A BaseSynthesizer is used to generate a response from a query and a list of nodes.
 * TODO: convert response builders to implement this interface (similar to Python).
 */
interface BaseSynthesizer {
    synthesize(query: string, nodesWithScore: NodeWithScore[], parentEvent?: Event): Promise<Response>;
}

declare class MultiModalResponseSynthesizer implements BaseSynthesizer {
    serviceContext: ServiceContext;
    metadataMode: MetadataMode;
    textQATemplate: TextQaPrompt;
    constructor({ serviceContext, textQATemplate, metadataMode, }?: Partial<MultiModalResponseSynthesizer>);
    synthesize(query: string, nodesWithScore: NodeWithScore[], parentEvent?: Event): Promise<Response>;
}

/**
 * Response modes of the response synthesizer
 */
declare enum ResponseMode {
    REFINE = "refine",
    COMPACT = "compact",
    TREE_SUMMARIZE = "tree_summarize",
    SIMPLE = "simple"
}
/**
 * A ResponseBuilder is used in a response synthesizer to generate a response from multiple response chunks.
 */
interface BaseResponseBuilder {
    /**
     * Get the response from a query and a list of text chunks.
     * @param query
     * @param textChunks
     * @param parentEvent
     * @param prevResponse
     */
    getResponse(query: string, textChunks: string[], parentEvent?: Event, prevResponse?: string): Promise<string>;
}
/**
 * A response builder that just concatenates responses.
 */
declare class SimpleResponseBuilder implements BaseResponseBuilder {
    llm: LLM;
    textQATemplate: SimplePrompt;
    constructor(serviceContext: ServiceContext);
    getResponse(query: string, textChunks: string[], parentEvent?: Event): Promise<string>;
}
/**
 * A response builder that uses the query to ask the LLM generate a better response using multiple text chunks.
 */
declare class Refine implements BaseResponseBuilder {
    serviceContext: ServiceContext;
    textQATemplate: TextQaPrompt;
    refineTemplate: RefinePrompt;
    constructor(serviceContext: ServiceContext, textQATemplate?: TextQaPrompt, refineTemplate?: RefinePrompt);
    getResponse(query: string, textChunks: string[], parentEvent?: Event, prevResponse?: string): Promise<string>;
    private giveResponseSingle;
    private refineResponseSingle;
}
/**
 * CompactAndRefine is a slight variation of Refine that first compacts the text chunks into the smallest possible number of chunks.
 */
declare class CompactAndRefine extends Refine {
    getResponse(query: string, textChunks: string[], parentEvent?: Event, prevResponse?: string): Promise<string>;
}
/**
 * TreeSummarize repacks the text chunks into the smallest possible number of chunks and then summarizes them, then recursively does so until there's one chunk left.
 */
declare class TreeSummarize implements BaseResponseBuilder {
    serviceContext: ServiceContext;
    summaryTemplate: TreeSummarizePrompt;
    constructor(serviceContext: ServiceContext, summaryTemplate?: TreeSummarizePrompt);
    getResponse(query: string, textChunks: string[], parentEvent?: Event): Promise<string>;
}
declare function getResponseBuilder(serviceContext: ServiceContext, responseMode?: ResponseMode): BaseResponseBuilder;

/**
 * A ResponseSynthesizer is used to generate a response from a query and a list of nodes.
 */
declare class ResponseSynthesizer implements BaseSynthesizer {
    responseBuilder: BaseResponseBuilder;
    serviceContext: ServiceContext;
    metadataMode: MetadataMode;
    constructor({ responseBuilder, serviceContext, metadataMode, }?: {
        responseBuilder?: BaseResponseBuilder;
        serviceContext?: ServiceContext;
        metadataMode?: MetadataMode;
    });
    synthesize(query: string, nodesWithScore: NodeWithScore[], parentEvent?: Event): Promise<Response>;
}

/**
 * The underlying structure of each index.
 */
declare abstract class IndexStruct {
    indexId: string;
    summary?: string;
    constructor(indexId?: string, summary?: undefined);
    toJson(): Record<string, unknown>;
    getSummary(): string;
}
declare enum IndexStructType {
    SIMPLE_DICT = "simple_dict",
    LIST = "list",
    KEYWORD_TABLE = "keyword_table"
}
declare class IndexDict extends IndexStruct {
    nodesDict: Record<string, BaseNode>;
    type: IndexStructType;
    getSummary(): string;
    addNode(node: BaseNode, textId?: string): void;
    toJson(): Record<string, unknown>;
    delete(nodeId: string): void;
}
declare function jsonToIndexStruct(json: any): IndexStruct;
declare class IndexList extends IndexStruct {
    nodes: string[];
    type: IndexStructType;
    addNode(node: BaseNode): void;
    toJson(): Record<string, unknown>;
}
declare class KeywordTable extends IndexStruct {
    table: Map<string, Set<string>>;
    type: IndexStructType;
    addNode(keywords: string[], nodeId: string): void;
    deleteNode(keywords: string[], nodeId: string): void;
    toJson(): Record<string, unknown>;
}
interface BaseIndexInit<T> {
    serviceContext: ServiceContext;
    storageContext: StorageContext;
    docStore: BaseDocumentStore;
    vectorStore?: VectorStore;
    indexStore?: BaseIndexStore;
    indexStruct: T;
}
/**
 * Indexes are the data structure that we store our nodes and embeddings in so
 * they can be retrieved for our queries.
 */
declare abstract class BaseIndex<T> {
    serviceContext: ServiceContext;
    storageContext: StorageContext;
    docStore: BaseDocumentStore;
    vectorStore?: VectorStore;
    indexStore?: BaseIndexStore;
    indexStruct: T;
    constructor(init: BaseIndexInit<T>);
    /**
     * Create a new retriever from the index.
     * @param retrieverOptions
     */
    abstract asRetriever(options?: any): BaseRetriever;
    /**
     * Create a new query engine from the index. It will also create a retriever
     * and response synthezier if they are not provided.
     * @param options you can supply your own custom Retriever and ResponseSynthesizer
     */
    abstract asQueryEngine(options?: {
        retriever?: BaseRetriever;
        responseSynthesizer?: BaseSynthesizer;
    }): BaseQueryEngine;
    /**
     * Insert a document into the index.
     * @param document
     */
    insert(document: Document): Promise<void>;
    abstract insertNodes(nodes: BaseNode[]): Promise<void>;
    abstract deleteRefDoc(refDocId: string, deleteFromDocStore?: boolean): Promise<void>;
}

declare abstract class BaseIndexStore {
    abstract getIndexStructs(): Promise<IndexStruct[]>;
    abstract addIndexStruct(indexStruct: IndexStruct): Promise<void>;
    abstract deleteIndexStruct(key: string): Promise<void>;
    abstract getIndexStruct(structId?: string): Promise<IndexStruct | undefined>;
    persist(persistPath?: string, fs?: GenericFileSystem): Promise<void>;
}

interface StorageContext {
    docStore: BaseDocumentStore;
    indexStore: BaseIndexStore;
    vectorStore: VectorStore;
    imageVectorStore?: VectorStore;
}
type BuilderParams = {
    docStore?: BaseDocumentStore;
    indexStore?: BaseIndexStore;
    vectorStore?: VectorStore;
    imageVectorStore?: VectorStore;
    storeImages?: boolean;
    persistDir?: string;
    fs?: GenericFileSystem;
};
declare function storageContextFromDefaults({ docStore, indexStore, vectorStore, imageVectorStore, storeImages, persistDir, fs, }: BuilderParams): Promise<StorageContext>;

declare const DEFAULT_COLLECTION = "data";
declare const DEFAULT_PERSIST_DIR = "./storage";
declare const DEFAULT_INDEX_STORE_PERSIST_FILENAME = "index_store.json";
declare const DEFAULT_DOC_STORE_PERSIST_FILENAME = "doc_store.json";
declare const DEFAULT_VECTOR_STORE_PERSIST_FILENAME = "vector_store.json";
declare const DEFAULT_GRAPH_STORE_PERSIST_FILENAME = "graph_store.json";
declare const DEFAULT_NAMESPACE = "docstore";
declare const DEFAULT_IMAGE_VECTOR_NAMESPACE = "images";

type StoredValue = Record<string, any> | null;
declare abstract class BaseKVStore {
    abstract put(key: string, val: Record<string, any>, collection?: string): Promise<void>;
    abstract get(key: string, collection?: string): Promise<StoredValue>;
    abstract getAll(collection?: string): Promise<Record<string, StoredValue>>;
    abstract delete(key: string, collection?: string): Promise<boolean>;
}
declare abstract class BaseInMemoryKVStore extends BaseKVStore {
    abstract persist(persistPath: string, fs?: GenericFileSystem): void;
    static fromPersistPath(persistPath: string): BaseInMemoryKVStore;
}

type DataType = Record<string, Record<string, any>>;
declare class SimpleKVStore extends BaseKVStore {
    private data;
    private persistPath;
    private fs;
    constructor(data?: DataType);
    put(key: string, val: any, collection?: string): Promise<void>;
    get(key: string, collection?: string): Promise<any>;
    getAll(collection?: string): Promise<DataType>;
    delete(key: string, collection?: string): Promise<boolean>;
    persist(persistPath: string, fs?: GenericFileSystem): Promise<void>;
    static fromPersistPath(persistPath: string, fs?: GenericFileSystem): Promise<SimpleKVStore>;
    toDict(): DataType;
    static fromDict(saveDict: DataType): SimpleKVStore;
}

declare class KVDocumentStore extends BaseDocumentStore {
    private kvstore;
    private nodeCollection;
    private refDocCollection;
    private metadataCollection;
    constructor(kvstore: BaseKVStore, namespace?: string);
    docs(): Promise<Record<string, BaseNode>>;
    addDocuments(docs: BaseNode[], allowUpdate?: boolean): Promise<void>;
    getDocument(docId: string, raiseError?: boolean): Promise<BaseNode | undefined>;
    getRefDocInfo(refDocId: string): Promise<RefDocInfo | undefined>;
    getAllRefDocInfo(): Promise<Record<string, RefDocInfo> | undefined>;
    refDocExists(refDocId: string): Promise<boolean>;
    documentExists(docId: string): Promise<boolean>;
    private removeRefDocNode;
    deleteDocument(docId: string, raiseError?: boolean, removeRefDocNode?: boolean): Promise<void>;
    deleteRefDoc(refDocId: string, raiseError?: boolean): Promise<void>;
    setDocumentHash(docId: string, docHash: string): Promise<void>;
    getDocumentHash(docId: string): Promise<string | undefined>;
}

type SaveDict = Record<string, any>;
declare class SimpleDocumentStore extends KVDocumentStore {
    private kvStore;
    constructor(kvStore?: SimpleKVStore, namespace?: string);
    static fromPersistDir(persistDir?: string, namespace?: string, fsModule?: GenericFileSystem): Promise<SimpleDocumentStore>;
    static fromPersistPath(persistPath: string, namespace?: string, fs?: GenericFileSystem): Promise<SimpleDocumentStore>;
    persist(persistPath?: string, fs?: GenericFileSystem): Promise<void>;
    static fromDict(saveDict: SaveDict, namespace?: string): SimpleDocumentStore;
    toDict(): SaveDict;
}

declare class KVIndexStore extends BaseIndexStore {
    private _kvStore;
    private _collection;
    constructor(kvStore: BaseKVStore, namespace?: string);
    addIndexStruct(indexStruct: IndexStruct): Promise<void>;
    deleteIndexStruct(key: string): Promise<void>;
    getIndexStruct(structId?: string): Promise<IndexStruct | undefined>;
    getIndexStructs(): Promise<IndexStruct[]>;
}

declare class SimpleIndexStore extends KVIndexStore {
    private kvStore;
    constructor(kvStore?: BaseInMemoryKVStore);
    static fromPersistDir(persistDir?: string, fs?: GenericFileSystem): Promise<SimpleIndexStore>;
    static fromPersistPath(persistPath: string, fs?: GenericFileSystem): Promise<SimpleIndexStore>;
    persist(persistPath?: string, fs?: GenericFileSystem): Promise<void>;
    static fromDict(saveDict: DataType): SimpleIndexStore;
    toDict(): Record<string, unknown>;
}

declare class AstraDBVectorStore implements VectorStore {
    storesText: boolean;
    flatMetadata: boolean;
    astraDBClient: AstraDB;
    idKey: string;
    contentKey: string | undefined;
    metadataKey: string;
    private collection;
    constructor(init?: Partial<AstraDBVectorStore> & {
        params?: {
            token: string;
            endpoint: string;
        };
    });
    /**
     * Create a new collection in your Astra DB vector database.
     * You must still use connect() to connect to the collection.
     *
     * @param collection your new colletion's name
     * @param options: CreateCollectionOptions used to set the number of vector dimensions and similarity metric
     * @returns Promise that resolves if the creation did not throw an error.
     */
    create(collection: string, options: CreateCollectionOptions): Promise<void>;
    /**
     * Connect to an existing collection in your Astra DB vector database.
     * You must call this before adding, deleting, or querying.
     *
     * @param collection your existing colletion's name
     * @returns Promise that resolves if the connection did not throw an error.
     */
    connect(collection: string): Promise<void>;
    /**
     * Get an instance of your Astra DB client.
     * @returns the AstraDB client
     */
    client(): AstraDB;
    /**
     * Add your document(s) to your Astra DB collection.
     *
     * @returns and array of node ids which were added
     */
    add(nodes: BaseNode[]): Promise<string[]>;
    /**
     * Delete a document from your Astra DB collection.
     *
     * @param refDocId the id of the document to delete
     * @param deleteOptions: any DeleteOneOptions to pass to the delete query
     * @returns Promise that resolves if the delete query did not throw an error.
     */
    delete(refDocId: string, deleteOptions?: any): Promise<void>;
    /**
     * Query documents from your Astra DB collection to get the closest match to your embedding.
     *
     * @param query: VectorStoreQuery
     * @param options: Not used
     */
    query(query: VectorStoreQuery, options?: any): Promise<VectorStoreQueryResult>;
}

declare class MongoDBAtlasVectorSearch implements VectorStore {
    storesText: boolean;
    flatMetadata: boolean;
    mongodbClient: MongoClient;
    indexName: string;
    embeddingKey: string;
    idKey: string;
    textKey: string;
    metadataKey: string;
    insertOptions?: BulkWriteOptions;
    private collection;
    constructor(init: Partial<MongoDBAtlasVectorSearch> & {
        dbName: string;
        collectionName: string;
    });
    add(nodes: BaseNode[]): Promise<string[]>;
    delete(refDocId: string, deleteOptions?: any): Promise<void>;
    get client(): any;
    query(query: VectorStoreQuery, options?: any): Promise<VectorStoreQueryResult>;
}

declare class SimpleVectorStoreData {
    embeddingDict: Record<string, number[]>;
    textIdToRefDocId: Record<string, string>;
}
declare class SimpleVectorStore implements VectorStore {
    storesText: boolean;
    private data;
    private fs;
    private persistPath;
    constructor(data?: SimpleVectorStoreData, fs?: GenericFileSystem);
    static fromPersistDir(persistDir?: string, fs?: GenericFileSystem): Promise<SimpleVectorStore>;
    get client(): any;
    get(textId: string): Promise<number[]>;
    add(embeddingResults: BaseNode[]): Promise<string[]>;
    delete(refDocId: string): Promise<void>;
    query(query: VectorStoreQuery): Promise<VectorStoreQueryResult>;
    persist(persistPath?: string, fs?: GenericFileSystem): Promise<void>;
    static fromPersistPath(persistPath: string, fs?: GenericFileSystem): Promise<SimpleVectorStore>;
    static fromDict(saveDict: SimpleVectorStoreData): SimpleVectorStore;
    toDict(): SimpleVectorStoreData;
}

/**
 * Provides support for writing and querying vector data in Postgres.
 */
declare class PGVectorStore implements VectorStore {
    storesText: boolean;
    private collection;
    db?: pg.Client;
    constructor();
    /**
     * Setter for the collection property.
     * Using a collection allows for simple segregation of vector data,
     * e.g. by user, source, or access-level.
     * Leave/set blank to ignore the collection value when querying.
     * @param coll Name for the collection.
     */
    setCollection(coll: string): void;
    /**
     * Getter for the collection property.
     * Using a collection allows for simple segregation of vector data,
     * e.g. by user, source, or access-level.
     * Leave/set blank to ignore the collection value when querying.
     * @returns The currently-set collection value.  Default is empty string.
     */
    getCollection(): string;
    private getDb;
    private checkSchema;
    /**
     * Connects to the database specified in environment vars.
     * This method also checks and creates the vector extension,
     * the destination table and indexes if not found.
     * @returns A connection to the database, or the error encountered while connecting/setting up.
     */
    client(): Promise<pg.Client>;
    /**
     * Delete all vector records for the specified collection.
     * NOTE: Uses the collection property controlled by setCollection/getCollection.
     * @returns The result of the delete query.
     */
    clearCollection(): Promise<pg.QueryResult<any>>;
    /**
     * Adds vector record(s) to the table.
     * NOTE: Uses the collection property controlled by setCollection/getCollection.
     * @param embeddingResults The Nodes to be inserted, optionally including metadata tuples.
     * @returns A list of zero or more id values for the created records.
     */
    add(embeddingResults: BaseNode<Metadata>[]): Promise<string[]>;
    /**
     * Deletes a single record from the database by id.
     * NOTE: Uses the collection property controlled by setCollection/getCollection.
     * @param refDocId Unique identifier for the record to delete.
     * @param deleteKwargs Required by VectorStore interface.  Currently ignored.
     * @returns Promise that resolves if the delete query did not throw an error.
     */
    delete(refDocId: string, deleteKwargs?: any): Promise<void>;
    /**
     * Query the vector store for the closest matching data to the query embeddings
     * @param query The VectorStoreQuery to be used
     * @param options Required by VectorStore interface.  Currently ignored.
     * @returns Zero or more Document instances with data from the vector store.
     */
    query(query: VectorStoreQuery, options?: any): Promise<VectorStoreQueryResult>;
    /**
     * Required by VectorStore interface.  Currently ignored.
     * @param persistPath
     * @param fs
     * @returns Resolved Promise.
     */
    persist(persistPath: string, fs?: GenericFileSystem | undefined): Promise<void>;
}

/**
 * The similarity between two embeddings.
 * @param embedding1
 * @param embedding2
 * @param mode
 * @returns similarity score with higher numbers meaning the two embeddings are more similar
 */
declare function similarity(embedding1: number[], embedding2: number[], mode?: SimilarityType): number;
/**
 * Get the top K embeddings from a list of embeddings ordered by similarity to the query.
 * @param queryEmbedding
 * @param embeddings list of embeddings to consider
 * @param similarityTopK max number of embeddings to return, default 2
 * @param embeddingIds ids of embeddings in the embeddings list
 * @param similarityCutoff minimum similarity score
 * @returns
 */
declare function getTopKEmbeddings(queryEmbedding: number[], embeddings: number[][], similarityTopK?: number, embeddingIds?: any[] | null, similarityCutoff?: number | null): [number[], any[]];
declare function getTopKEmbeddingsLearner(queryEmbedding: number[], embeddings: number[][], similarityTopK?: number, embeddingsIds?: any[], queryMode?: VectorStoreQueryMode): [number[], any[]];
declare function getTopKMMREmbeddings(queryEmbedding: number[], embeddings: number[][], similarityFn?: ((...args: any[]) => number) | null, similarityTopK?: number | null, embeddingIds?: any[] | null, _similarityCutoff?: number | null, mmrThreshold?: number | null): [number[], any[]];
declare function readImage(input: ImageType): Promise<_xenova_transformers.RawImage>;
declare function imageToString(input: ImageType): Promise<string>;
declare function stringToImage(input: string): ImageType;
declare function imageToDataUrl(input: ImageType): Promise<string>;

declare class TextSplit {
    textChunk: string;
    numCharOverlap: number | undefined;
    constructor(textChunk: string, numCharOverlap?: number | undefined);
}
type SplitRep = {
    text: string;
    numTokens: number;
};
/**
 * Tokenizes sentences. Suitable for English and most European languages.
 * @param text
 * @returns
 */
declare const englishSentenceTokenizer: (text: string) => RegExpMatchArray | null;
/**
 * Tokenizes sentences. Suitable for Chinese, Japanese, and Korean.
 * @param text
 * @returns
 */
declare const cjkSentenceTokenizer: (text: string) => RegExpMatchArray | null;
declare const unixLineSeparator = "\n";
declare const windowsLineSeparator = "\r\n";
declare const unixParagraphSeparator: string;
declare const windowsParagraphSeparator: string;
/**
 * SentenceSplitter is our default text splitter that supports splitting into sentences, paragraphs, or fixed length chunks with overlap.
 *
 * One of the advantages of SentenceSplitter is that even in the fixed length chunks it will try to keep sentences together.
 */
declare class SentenceSplitter {
    private chunkSize;
    private chunkOverlap;
    private tokenizer;
    private tokenizerDecoder;
    private paragraphSeparator;
    private chunkingTokenizerFn;
    private splitLongSentences;
    constructor(options?: {
        chunkSize?: number;
        chunkOverlap?: number;
        tokenizer?: any;
        tokenizerDecoder?: any;
        paragraphSeparator?: string;
        chunkingTokenizerFn?: (text: string) => RegExpMatchArray | null;
        splitLongSentences?: boolean;
    });
    private getEffectiveChunkSize;
    getParagraphSplits(text: string, effectiveChunkSize?: number): string[];
    getSentenceSplits(text: string, effectiveChunkSize?: number): string[];
    /**
     * Splits sentences into chunks if necessary.
     *
     * This isn't great behavior because it can split down the middle of a
     * word or in non-English split down the middle of a Unicode codepoint
     * so the splitting is turned off by default. If you need it, please
     * set the splitLongSentences option to true.
     * @param sentenceSplits
     * @param effectiveChunkSize
     * @returns
     */
    private processSentenceSplits;
    combineTextSplits(newSentenceSplits: SplitRep[], effectiveChunkSize: number): TextSplit[];
    splitTextWithOverlaps(text: string, extraInfoStr?: string): TextSplit[];
    splitText(text: string, extraInfoStr?: string): string[];
}

/**
 * Splits the text of a document into smaller parts.
 * @param document - The document to split.
 * @param textSplitter - The text splitter to use.
 * @returns An array of text splits.
 */
declare function getTextSplitsFromDocument(document: Document, textSplitter: SentenceSplitter): string[];
/**
 * Generates an array of nodes from a document.
 * @param document - The document to generate nodes from.
 * @param textSplitter - The text splitter to use.
 * @param includeMetadata - Whether to include metadata in the nodes.
 * @param includePrevNextRel - Whether to include previous and next relationships in the nodes.
 * @returns An array of nodes.
 */
declare function getNodesFromDocument(doc: BaseNode, textSplitter: SentenceSplitter, includeMetadata?: boolean, includePrevNextRel?: boolean): TextNode<Metadata>[] | ImageDocument<any>[];
/**
 * A NodeParser generates Nodes from Documents
 */
interface NodeParser {
    /**
     * Generates an array of nodes from an array of documents.
     * @param documents - The documents to generate nodes from.
     * @returns An array of nodes.
     */
    getNodesFromDocuments(documents: BaseNode[]): BaseNode[];
}
/**
 * SimpleNodeParser is the default NodeParser. It splits documents into TextNodes using a splitter, by default SentenceSplitter
 */
declare class SimpleNodeParser implements NodeParser {
    /**
     * The text splitter to use.
     */
    textSplitter: SentenceSplitter;
    /**
     * Whether to include metadata in the nodes.
     */
    includeMetadata: boolean;
    /**
     * Whether to include previous and next relationships in the nodes.
     */
    includePrevNextRel: boolean;
    constructor(init?: {
        textSplitter?: SentenceSplitter;
        includeMetadata?: boolean;
        includePrevNextRel?: boolean;
        chunkSize?: number;
        chunkOverlap?: number;
    });
    static fromDefaults(init?: {
        chunkSize?: number;
        chunkOverlap?: number;
        includeMetadata?: boolean;
        includePrevNextRel?: boolean;
    }): SimpleNodeParser;
    /**
     * Generate Node objects from documents
     * @param documents
     */
    getNodesFromDocuments(documents: BaseNode[]): (TextNode<Metadata> | ImageDocument<any>)[];
}

declare function getEmptyPromptTxt(prompt: SimplePrompt): string;
/**
 * Get biggest empty prompt size from a list of prompts.
 * Used to calculate the maximum size of inputs to the LLM.
 * @param prompts
 * @returns
 */
declare function getBiggestPrompt(prompts: SimplePrompt[]): SimplePrompt;
/**
 * A collection of helper functions for working with prompts.
 */
declare class PromptHelper {
    contextWindow: number;
    numOutput: number;
    chunkOverlapRatio: number;
    chunkSizeLimit?: number;
    tokenizer: (text: string) => Uint32Array;
    separator: string;
    constructor(contextWindow?: number, numOutput?: number, chunkOverlapRatio?: number, chunkSizeLimit?: number, tokenizer?: (text: string) => Uint32Array, separator?: string);
    /**
     * Given a prompt, return the maximum size of the inputs to the prompt.
     * @param prompt
     * @returns
     */
    private getAvailableContextSize;
    /**
     * Find the maximum size of each chunk given a prompt.
     * @param prompt
     * @param numChunks
     * @param padding
     * @returns
     */
    private getAvailableChunkSize;
    /**
     * Creates a text splitter with the correct chunk sizes and overlaps given a prompt.
     * @param prompt
     * @param numChunks
     * @param padding
     * @returns
     */
    getTextSplitterGivenPrompt(prompt: SimplePrompt, numChunks?: number, padding?: number): SentenceSplitter;
    /**
     * Repack resplits the strings based on the optimal text splitter.
     * @param prompt
     * @param textChunks
     * @param padding
     * @returns
     */
    repack(prompt: SimplePrompt, textChunks: string[], padding?: number): string[];
}

/**
 * The ServiceContext is a collection of components that are used in different parts of the application.
 */
interface ServiceContext {
    llm: LLM;
    promptHelper: PromptHelper;
    embedModel: BaseEmbedding;
    nodeParser: NodeParser;
    callbackManager: CallbackManager;
}
interface ServiceContextOptions {
    llm?: LLM;
    promptHelper?: PromptHelper;
    embedModel?: BaseEmbedding;
    nodeParser?: NodeParser;
    callbackManager?: CallbackManager;
    chunkSize?: number;
    chunkOverlap?: number;
}
declare function serviceContextFromDefaults(options?: ServiceContextOptions): ServiceContext;
declare function serviceContextFromServiceContext(serviceContext: ServiceContext, options: ServiceContextOptions): {
    llm: LLM;
    promptHelper: PromptHelper;
    embedModel: BaseEmbedding;
    nodeParser: NodeParser;
    callbackManager: CallbackManager;
};

/**
 * Retrievers retrieve the nodes that most closely match our query in similarity.
 */
interface BaseRetriever {
    retrieve(query: string, parentEvent?: Event, preFilters?: unknown): Promise<NodeWithScore[]>;
    getServiceContext(): ServiceContext;
}

interface BaseNodePostprocessor {
    postprocessNodes: (nodes: NodeWithScore[]) => NodeWithScore[];
}
declare class SimilarityPostprocessor implements BaseNodePostprocessor {
    similarityCutoff?: number;
    constructor(options?: {
        similarityCutoff?: number;
    });
    postprocessNodes(nodes: NodeWithScore[]): NodeWithScore<Metadata>[];
}

/**
 * A query engine is a question answerer that can use one or more steps.
 */
interface BaseQueryEngine {
    /**
     * Query the query engine and get a response.
     * @param query
     * @param parentEvent
     */
    query(query: string, parentEvent?: Event): Promise<Response>;
}
/**
 * A query engine that uses a retriever to query an index and then synthesizes the response.
 */
declare class RetrieverQueryEngine implements BaseQueryEngine {
    retriever: BaseRetriever;
    responseSynthesizer: BaseSynthesizer;
    nodePostprocessors: BaseNodePostprocessor[];
    preFilters?: unknown;
    constructor(retriever: BaseRetriever, responseSynthesizer?: BaseSynthesizer, preFilters?: unknown, nodePostprocessors?: BaseNodePostprocessor[]);
    private applyNodePostprocessors;
    private retrieve;
    query(query: string, parentEvent?: Event): Promise<Response>;
}
/**
 * SubQuestionQueryEngine decomposes a question into subquestions and then
 */
declare class SubQuestionQueryEngine implements BaseQueryEngine {
    responseSynthesizer: BaseSynthesizer;
    questionGen: BaseQuestionGenerator;
    queryEngines: Record<string, BaseQueryEngine>;
    metadatas: ToolMetadata[];
    constructor(init: {
        questionGen: BaseQuestionGenerator;
        responseSynthesizer: BaseSynthesizer;
        queryEngineTools: QueryEngineTool[];
    });
    static fromDefaults(init: {
        queryEngineTools: QueryEngineTool[];
        questionGen?: BaseQuestionGenerator;
        responseSynthesizer?: BaseSynthesizer;
        serviceContext?: ServiceContext;
    }): SubQuestionQueryEngine;
    query(query: string): Promise<Response>;
    private querySubQ;
}

interface ToolMetadata {
    description: string;
    name: string;
}
/**
 * Simple Tool interface. Likely to change.
 */
interface BaseTool {
    metadata: ToolMetadata;
}
/**
 * A Tool that uses a QueryEngine.
 */
interface QueryEngineTool extends BaseTool {
    queryEngine: BaseQueryEngine;
}

/**
 * A SimplePrompt is a function that takes a dictionary of inputs and returns a string.
 * NOTE this is a different interface compared to LlamaIndex Python
 * NOTE 2: we default to empty string to make it easy to calculate prompt sizes
 */
type SimplePrompt = (input: Record<string, string | undefined>) => string;
declare const defaultTextQaPrompt: ({ context, query }: {
    context?: string | undefined;
    query?: string | undefined;
}) => string;
type TextQaPrompt = typeof defaultTextQaPrompt;
declare const anthropicTextQaPrompt: ({ context, query }: {
    context?: string | undefined;
    query?: string | undefined;
}) => string;
declare const defaultSummaryPrompt: ({ context }: {
    context?: string | undefined;
}) => string;
type SummaryPrompt = typeof defaultSummaryPrompt;
declare const defaultRefinePrompt: ({ query, existingAnswer, context, }: {
    query?: string | undefined;
    existingAnswer?: string | undefined;
    context?: string | undefined;
}) => string;
type RefinePrompt = typeof defaultRefinePrompt;
declare const defaultTreeSummarizePrompt: ({ context, query }: {
    context?: string | undefined;
    query?: string | undefined;
}) => string;
type TreeSummarizePrompt = typeof defaultTreeSummarizePrompt;
declare const defaultChoiceSelectPrompt: ({ context, query }: {
    context?: string | undefined;
    query?: string | undefined;
}) => string;
type ChoiceSelectPrompt = typeof defaultChoiceSelectPrompt;
declare function buildToolsText(tools: ToolMetadata[]): string;
declare const defaultSubQuestionPrompt: ({ toolsStr, queryStr }: {
    toolsStr?: string | undefined;
    queryStr?: string | undefined;
}) => string;
type SubQuestionPrompt = typeof defaultSubQuestionPrompt;
declare const defaultCondenseQuestionPrompt: ({ chatHistory, question, }: {
    chatHistory?: string | undefined;
    question?: string | undefined;
}) => string;
type CondenseQuestionPrompt = typeof defaultCondenseQuestionPrompt;
declare function messagesToHistoryStr(messages: ChatMessage[]): string;
declare const defaultContextSystemPrompt: ({ context }: {
    context?: string | undefined;
}) => string;
type ContextSystemPrompt = typeof defaultContextSystemPrompt;
declare const defaultKeywordExtractPrompt: ({ context, maxKeywords, }: {
    context?: string | undefined;
    maxKeywords?: number | undefined;
}) => string;
type KeywordExtractPrompt = typeof defaultKeywordExtractPrompt;
declare const defaultQueryKeywordExtractPrompt: ({ question, maxKeywords, }: {
    question?: string | undefined;
    maxKeywords?: number | undefined;
}) => string;
type QueryKeywordExtractPrompt = typeof defaultQueryKeywordExtractPrompt;

/**
 * A ChatHistory is used to keep the state of back and forth chat messages
 */
interface ChatHistory {
    messages: ChatMessage[];
    /**
     * Adds a message to the chat history.
     * @param message
     */
    addMessage(message: ChatMessage): void;
    /**
     * Returns the messages that should be used as input to the LLM.
     */
    requestMessages(transientMessages?: ChatMessage[]): Promise<ChatMessage[]>;
    /**
     * Resets the chat history so that it's empty.
     */
    reset(): void;
    /**
     * Returns the new messages since the last call to this function (or since calling the constructor)
     */
    newMessages(): ChatMessage[];
}
declare class SimpleChatHistory implements ChatHistory {
    messages: ChatMessage[];
    private messagesBefore;
    constructor(init?: Partial<SimpleChatHistory>);
    addMessage(message: ChatMessage): void;
    requestMessages(transientMessages?: ChatMessage[]): Promise<ChatMessage[]>;
    reset(): void;
    newMessages(): ChatMessage[];
}
declare class SummaryChatHistory implements ChatHistory {
    tokensToSummarize: number;
    messages: ChatMessage[];
    summaryPrompt: SummaryPrompt;
    llm: LLM;
    private messagesBefore;
    constructor(init?: Partial<SummaryChatHistory>);
    private summarize;
    addMessage(message: ChatMessage): void;
    private getLastSummaryIndex;
    private get systemMessages();
    private get nonSystemMessages();
    /**
     * Calculates the messages that describe the conversation so far.
     * If there's no memory, all non-system messages are used.
     * If there's a memory, uses all messages after the last summary message.
     */
    private calcConversationMessages;
    private calcCurrentRequestMessages;
    requestMessages(transientMessages?: ChatMessage[]): Promise<ChatMessage[]>;
    reset(): void;
    newMessages(): ChatMessage[];
}

/**
 * A ChatEngine is used to handle back and forth chats between the application and the LLM.
 */
interface ChatEngine {
    /**
     * Send message along with the class's current chat history to the LLM.
     * @param message
     * @param chatHistory optional chat history if you want to customize the chat history
     * @param streaming optional streaming flag, which auto-sets the return value if True.
     */
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : Response>(message: MessageContent, chatHistory?: ChatMessage[], streaming?: T): Promise<R>;
    /**
     * Resets the chat history so that it's empty.
     */
    reset(): void;
}
/**
 * SimpleChatEngine is the simplest possible chat engine. Useful for using your own custom prompts.
 */
declare class SimpleChatEngine implements ChatEngine {
    chatHistory: ChatMessage[];
    llm: LLM;
    constructor(init?: Partial<SimpleChatEngine>);
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : Response>(message: MessageContent, chatHistory?: ChatMessage[], streaming?: T): Promise<R>;
    protected streamChat(message: MessageContent, chatHistory?: ChatMessage[]): AsyncGenerator<string, void, unknown>;
    reset(): void;
}
/**
 * CondenseQuestionChatEngine is used in conjunction with a Index (for example VectorStoreIndex).
 * It does two steps on taking a user's chat message: first, it condenses the chat message
 * with the previous chat history into a question with more context.
 * Then, it queries the underlying Index using the new question with context and returns
 * the response.
 * CondenseQuestionChatEngine performs well when the input is primarily questions about the
 * underlying data. It performs less well when the chat messages are not questions about the
 * data, or are very referential to previous context.
 */
declare class CondenseQuestionChatEngine implements ChatEngine {
    queryEngine: BaseQueryEngine;
    chatHistory: ChatMessage[];
    serviceContext: ServiceContext;
    condenseMessagePrompt: CondenseQuestionPrompt;
    constructor(init: {
        queryEngine: BaseQueryEngine;
        chatHistory: ChatMessage[];
        serviceContext?: ServiceContext;
        condenseMessagePrompt?: CondenseQuestionPrompt;
    });
    private condenseQuestion;
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : Response>(message: MessageContent, chatHistory?: ChatMessage[] | undefined, streaming?: T): Promise<R>;
    reset(): void;
}
interface Context {
    message: ChatMessage;
    nodes: NodeWithScore[];
}
interface ContextGenerator {
    generate(message: string, parentEvent?: Event): Promise<Context>;
}
declare class DefaultContextGenerator implements ContextGenerator {
    retriever: BaseRetriever;
    contextSystemPrompt: ContextSystemPrompt;
    nodePostprocessors: BaseNodePostprocessor[];
    constructor(init: {
        retriever: BaseRetriever;
        contextSystemPrompt?: ContextSystemPrompt;
        nodePostprocessors?: BaseNodePostprocessor[];
    });
    private applyNodePostprocessors;
    generate(message: string, parentEvent?: Event): Promise<Context>;
}
/**
 * ContextChatEngine uses the Index to get the appropriate context for each query.
 * The context is stored in the system prompt, and the chat history is preserved,
 * ideally allowing the appropriate context to be surfaced for each query.
 */
declare class ContextChatEngine implements ChatEngine {
    chatModel: LLM;
    chatHistory: ChatMessage[];
    contextGenerator: ContextGenerator;
    constructor(init: {
        retriever: BaseRetriever;
        chatModel?: LLM;
        chatHistory?: ChatMessage[];
        contextSystemPrompt?: ContextSystemPrompt;
        nodePostprocessors?: BaseNodePostprocessor[];
    });
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : Response>(message: MessageContent, chatHistory?: ChatMessage[] | undefined, streaming?: T): Promise<R>;
    protected streamChat(message: MessageContent, chatHistory?: ChatMessage[] | undefined): AsyncGenerator<string, void, unknown>;
    reset(): void;
}
interface MessageContentDetail {
    type: "text" | "image_url";
    text?: string;
    image_url?: {
        url: string;
    };
}
/**
 * Extended type for the content of a message that allows for multi-modal messages.
 */
type MessageContent = string | MessageContentDetail[];
/**
 * HistoryChatEngine is a ChatEngine that uses a `ChatHistory` object
 * to keeps track of chat's message history.
 * A `ChatHistory` object is passed as a parameter for each call to the `chat` method,
 * so the state of the chat engine is preserved between calls.
 * Optionally, a `ContextGenerator` can be used to generate an additional context for each call to `chat`.
 */
declare class HistoryChatEngine {
    llm: LLM;
    contextGenerator?: ContextGenerator;
    constructor(init?: Partial<HistoryChatEngine>);
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : Response>(message: MessageContent, chatHistory: ChatHistory, streaming?: T): Promise<R>;
    protected streamChat(message: MessageContent, chatHistory: ChatHistory): AsyncGenerator<string, void, unknown>;
    private prepareRequestMessages;
}

declare const DEFAULT_CONTEXT_WINDOW = 3900;
declare const DEFAULT_NUM_OUTPUTS = 256;
declare const DEFAULT_CHUNK_SIZE = 1024;
declare const DEFAULT_CHUNK_OVERLAP = 20;
declare const DEFAULT_CHUNK_OVERLAP_RATIO = 0.1;
declare const DEFAULT_SIMILARITY_TOP_K = 2;
declare const DEFAULT_EMBEDDING_DIM = 1536;
declare const DEFAULT_PADDING = 5;

interface KeywordIndexOptions {
    nodes?: BaseNode[];
    indexStruct?: KeywordTable;
    indexId?: string;
    serviceContext?: ServiceContext;
    storageContext?: StorageContext;
}
declare enum KeywordTableRetrieverMode {
    DEFAULT = "DEFAULT",
    SIMPLE = "SIMPLE",
    RAKE = "RAKE"
}
/**
 * The KeywordTableIndex, an index that extracts keywords from each Node and builds a mapping from each keyword to the corresponding Nodes of that keyword.
 */
declare class KeywordTableIndex extends BaseIndex<KeywordTable> {
    constructor(init: BaseIndexInit<KeywordTable>);
    static init(options: KeywordIndexOptions): Promise<KeywordTableIndex>;
    asRetriever(options?: any): BaseRetriever;
    asQueryEngine(options?: {
        retriever?: BaseRetriever;
        responseSynthesizer?: BaseSynthesizer;
        preFilters?: unknown;
        nodePostprocessors?: BaseNodePostprocessor[];
    }): BaseQueryEngine;
    static extractKeywords(text: string, serviceContext: ServiceContext): Promise<Set<string>>;
    /**
     * High level API: split documents, get keywords, and build index.
     * @param documents
     * @param storageContext
     * @param serviceContext
     * @returns
     */
    static fromDocuments(documents: Document[], args?: {
        storageContext?: StorageContext;
        serviceContext?: ServiceContext;
    }): Promise<KeywordTableIndex>;
    /**
     * Get keywords for nodes and place them into the index.
     * @param nodes
     * @param serviceContext
     * @param vectorStore
     * @returns
     */
    static buildIndexFromNodes(nodes: BaseNode[], docStore: BaseDocumentStore, serviceContext: ServiceContext): Promise<KeywordTable>;
    insertNodes(nodes: BaseNode[]): Promise<void>;
    deleteNode(nodeId: string): void;
    deleteNodes(nodeIds: string[], deleteFromDocStore: boolean): Promise<void>;
    deleteRefDoc(refDocId: string, deleteFromDocStore?: boolean): Promise<void>;
}

declare abstract class BaseKeywordTableRetriever implements BaseRetriever {
    protected index: KeywordTableIndex;
    protected indexStruct: KeywordTable;
    protected docstore: BaseDocumentStore;
    protected serviceContext: ServiceContext;
    protected maxKeywordsPerQuery: number;
    protected numChunksPerQuery: number;
    protected keywordExtractTemplate: KeywordExtractPrompt;
    protected queryKeywordExtractTemplate: QueryKeywordExtractPrompt;
    constructor({ index, keywordExtractTemplate, queryKeywordExtractTemplate, maxKeywordsPerQuery, numChunksPerQuery, }: {
        index: KeywordTableIndex;
        keywordExtractTemplate?: KeywordExtractPrompt;
        queryKeywordExtractTemplate?: QueryKeywordExtractPrompt;
        maxKeywordsPerQuery: number;
        numChunksPerQuery: number;
    });
    abstract getKeywords(query: string): Promise<string[]>;
    retrieve(query: string): Promise<NodeWithScore[]>;
    getServiceContext(): ServiceContext;
}
declare class KeywordTableLLMRetriever extends BaseKeywordTableRetriever {
    getKeywords(query: string): Promise<string[]>;
}
declare class KeywordTableSimpleRetriever extends BaseKeywordTableRetriever {
    getKeywords(query: string): Promise<string[]>;
}
declare class KeywordTableRAKERetriever extends BaseKeywordTableRetriever {
    getKeywords(query: string): Promise<string[]>;
}

declare enum SummaryRetrieverMode {
    DEFAULT = "default",
    LLM = "llm"
}
interface SummaryIndexOptions {
    nodes?: BaseNode[];
    indexStruct?: IndexList;
    indexId?: string;
    serviceContext?: ServiceContext;
    storageContext?: StorageContext;
}
/**
 * A SummaryIndex keeps nodes in a sequential order for use with summarization.
 */
declare class SummaryIndex extends BaseIndex<IndexList> {
    constructor(init: BaseIndexInit<IndexList>);
    static init(options: SummaryIndexOptions): Promise<SummaryIndex>;
    static fromDocuments(documents: Document[], args?: {
        storageContext?: StorageContext;
        serviceContext?: ServiceContext;
    }): Promise<SummaryIndex>;
    asRetriever(options?: {
        mode: SummaryRetrieverMode;
    }): BaseRetriever;
    asQueryEngine(options?: {
        retriever?: BaseRetriever;
        responseSynthesizer?: BaseSynthesizer;
        preFilters?: unknown;
        nodePostprocessors?: BaseNodePostprocessor[];
    }): BaseQueryEngine;
    static buildIndexFromNodes(nodes: BaseNode[], docStore: BaseDocumentStore, indexStruct?: IndexList): Promise<IndexList>;
    insertNodes(nodes: BaseNode[]): Promise<void>;
    deleteRefDoc(refDocId: string, deleteFromDocStore?: boolean): Promise<void>;
    deleteNodes(nodeIds: string[], deleteFromDocStore: boolean): Promise<void>;
    getRefDocInfo(): Promise<Record<string, RefDocInfo>>;
}
type ListIndex = SummaryIndex;
type ListRetrieverMode = SummaryRetrieverMode;

type NodeFormatterFunction = (summaryNodes: BaseNode[]) => string;
type ChoiceSelectParseResult = {
    [docNumber: number]: number;
};
type ChoiceSelectParserFunction = (answer: string, numChoices: number, raiseErr?: boolean) => ChoiceSelectParseResult;

/**
 * Simple retriever for SummaryIndex that returns all nodes
 */
declare class SummaryIndexRetriever implements BaseRetriever {
    index: SummaryIndex;
    constructor(index: SummaryIndex);
    retrieve(query: string, parentEvent?: Event): Promise<NodeWithScore[]>;
    getServiceContext(): ServiceContext;
}
/**
 * LLM retriever for SummaryIndex which lets you select the most relevant chunks.
 */
declare class SummaryIndexLLMRetriever implements BaseRetriever {
    index: SummaryIndex;
    choiceSelectPrompt: ChoiceSelectPrompt;
    choiceBatchSize: number;
    formatNodeBatchFn: NodeFormatterFunction;
    parseChoiceSelectAnswerFn: ChoiceSelectParserFunction;
    serviceContext: ServiceContext;
    constructor(index: SummaryIndex, choiceSelectPrompt?: ChoiceSelectPrompt, choiceBatchSize?: number, formatNodeBatchFn?: NodeFormatterFunction, parseChoiceSelectAnswerFn?: ChoiceSelectParserFunction, serviceContext?: ServiceContext);
    retrieve(query: string, parentEvent?: Event): Promise<NodeWithScore[]>;
    getServiceContext(): ServiceContext;
}
type ListIndexRetriever = SummaryIndexRetriever;
type ListIndexLLMRetriever = SummaryIndexLLMRetriever;

interface IndexStructOptions {
    indexStruct?: IndexDict;
    indexId?: string;
}
interface VectorIndexOptions extends IndexStructOptions {
    nodes?: BaseNode[];
    serviceContext?: ServiceContext;
    storageContext?: StorageContext;
    imageVectorStore?: VectorStore;
    vectorStore?: VectorStore;
}
/**
 * The VectorStoreIndex, an index that stores the nodes only according to their vector embedings.
 */
declare class VectorStoreIndex extends BaseIndex<IndexDict> {
    vectorStore: VectorStore;
    indexStore: BaseIndexStore;
    embedModel: BaseEmbedding;
    imageVectorStore?: VectorStore;
    imageEmbedModel?: MultiModalEmbedding;
    private constructor();
    /**
     * The async init function creates a new VectorStoreIndex.
     * @param options
     * @returns
     */
    static init(options: VectorIndexOptions): Promise<VectorStoreIndex>;
    private static setupIndexStructFromStorage;
    /**
     * Get the embeddings for nodes.
     * @param nodes
     * @param logProgress log progress to console (useful for debugging)
     * @returns
     */
    getNodeEmbeddingResults(nodes: BaseNode[], logProgress?: boolean): Promise<BaseNode<Metadata>[]>;
    /**
     * Get embeddings for nodes and place them into the index.
     * @param nodes
     * @returns
     */
    buildIndexFromNodes(nodes: BaseNode[]): Promise<void>;
    /**
     * High level API: split documents, get embeddings, and build index.
     * @param documents
     * @param args
     * @returns
     */
    static fromDocuments(documents: Document[], args?: VectorIndexOptions): Promise<VectorStoreIndex>;
    static fromVectorStore(vectorStore: VectorStore, serviceContext: ServiceContext, imageVectorStore?: VectorStore): Promise<VectorStoreIndex>;
    asRetriever(options?: any): VectorIndexRetriever;
    asQueryEngine(options?: {
        retriever?: BaseRetriever;
        responseSynthesizer?: BaseSynthesizer;
        preFilters?: unknown;
        nodePostprocessors?: BaseNodePostprocessor[];
    }): BaseQueryEngine;
    protected insertNodesToStore(vectorStore: VectorStore, nodes: BaseNode[]): Promise<void>;
    insertNodes(nodes: BaseNode[]): Promise<void>;
    deleteRefDoc(refDocId: string, deleteFromDocStore?: boolean): Promise<void>;
    protected deleteRefDocFromStore(vectorStore: VectorStore, refDocId: string): Promise<void>;
    /**
     * Get the embeddings for image nodes.
     * @param nodes
     * @param serviceContext
     * @param logProgress log progress to console (useful for debugging)
     * @returns
     */
    getImageNodeEmbeddingResults(nodes: ImageNode[], logProgress?: boolean): Promise<BaseNode[]>;
}

/**
 * VectorIndexRetriever retrieves nodes from a VectorIndex.
 */
declare class VectorIndexRetriever implements BaseRetriever {
    index: VectorStoreIndex;
    similarityTopK: number;
    imageSimilarityTopK: number;
    private serviceContext;
    constructor({ index, similarityTopK, imageSimilarityTopK, }: {
        index: VectorStoreIndex;
        similarityTopK?: number;
        imageSimilarityTopK?: number;
    });
    retrieve(query: string, parentEvent?: Event, preFilters?: unknown): Promise<NodeWithScore[]>;
    protected textRetrieve(query: string, preFilters?: unknown): Promise<NodeWithScore[]>;
    private textToImageRetrieve;
    protected sendEvent(query: string, nodesWithScores: NodeWithScore<Metadata>[], parentEvent: Event | undefined): void;
    protected buildVectorStoreQuery(embedModel: BaseEmbedding, query: string, similarityTopK: number): Promise<VectorStoreQuery>;
    protected buildNodeListFromQueryResult(result: VectorStoreQueryResult): NodeWithScore<Metadata>[];
    getServiceContext(): ServiceContext;
}

declare const ALL_AVAILABLE_MISTRAL_MODELS: {
    "mistral-tiny": {
        contextWindow: number;
    };
    "mistral-small": {
        contextWindow: number;
    };
    "mistral-medium": {
        contextWindow: number;
    };
};
declare class MistralAISession {
    apiKey?: string;
    private client;
    constructor(init?: Partial<MistralAISession>);
    getClient(): Promise<any>;
}
/**
 * MistralAI LLM implementation
 */
declare class MistralAI implements LLM {
    hasStreaming: boolean;
    model: keyof typeof ALL_AVAILABLE_MISTRAL_MODELS;
    temperature: number;
    topP: number;
    maxTokens?: number;
    apiKey?: string;
    callbackManager?: CallbackManager;
    safeMode: boolean;
    randomSeed?: number;
    private session;
    constructor(init?: Partial<MistralAI>);
    get metadata(): {
        model: "mistral-tiny" | "mistral-small" | "mistral-medium";
        temperature: number;
        topP: number;
        maxTokens: number | undefined;
        contextWindow: number;
        tokenizer: undefined;
    };
    tokens(messages: ChatMessage[]): number;
    private buildParams;
    chat<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(messages: ChatMessage[], parentEvent?: Event, streaming?: T): Promise<R>;
    complete<T extends boolean | undefined = undefined, R = T extends true ? AsyncGenerator<string, void, unknown> : ChatResponse>(prompt: string, parentEvent?: Event, streaming?: T): Promise<R>;
    protected streamChat(messages: ChatMessage[], parentEvent?: Event): AsyncGenerator<string, void, unknown>;
    protected streamComplete(query: string, parentEvent?: Event): AsyncGenerator<string, void, unknown>;
}

/**
 * A reader takes imports data into Document objects.
 */
interface BaseReader {
    loadData(...args: any[]): Promise<Document[]>;
}

type AssemblyAIOptions = Partial<BaseServiceParams>;
/**
 * Base class for AssemblyAI Readers.
 */
declare abstract class AssemblyAIReader implements BaseReader {
    protected client: AssemblyAI;
    /**
     * Creates a new AssemblyAI Reader.
     * @param assemblyAIOptions The options to configure the AssemblyAI Reader.
     * Configure the `assemblyAIOptions.apiKey` with your AssemblyAI API key, or configure it as the `ASSEMBLYAI_API_KEY` environment variable.
     */
    constructor(assemblyAIOptions?: AssemblyAIOptions);
    abstract loadData(...args: any[]): Promise<Document[]>;
    protected transcribeOrGetTranscript(params: TranscribeParams | string): Promise<assemblyai.Transcript>;
    protected getTranscriptId(params: TranscribeParams | string): Promise<string>;
}
/**
 * Transcribe audio and read the transcript as a document using AssemblyAI.
 */
declare class AudioTranscriptReader extends AssemblyAIReader {
    /**
     * Transcribe audio or get a transcript and load the transcript as a document using AssemblyAI.
     * @param params Parameters to transcribe an audio file or get an existing transcript.
     * @returns A promise that resolves to a single document containing the transcript text.
     */
    loadData(params: TranscribeParams | string): Promise<Document[]>;
}
/**
 * Transcribe audio and return a document for each paragraph.
 */
declare class AudioTranscriptParagraphsReader extends AssemblyAIReader {
    /**
     * Transcribe audio or get a transcript, and returns a document for each paragraph.
     * @param params The parameters to transcribe audio or get an existing transcript.
     * @returns A promise that resolves to an array of documents, each containing a paragraph of the transcript.
     */
    loadData(params: TranscribeParams | string): Promise<Document[]>;
}
/**
 * Transcribe audio and return a document for each sentence.
 */
declare class AudioTranscriptSentencesReader extends AssemblyAIReader {
    /**
     * Transcribe audio or get a transcript, and returns a document for each sentence.
     * @param params The parameters to transcribe audio or get an existing transcript.
     * @returns A promise that resolves to an array of documents, each containing a sentence of the transcript.
     */
    loadData(params: TranscribeParams | string): Promise<Document[]>;
}
/**
 * Transcribe audio a transcript and read subtitles for the transcript as `srt` or `vtt` format.
 */
declare class AudioSubtitlesReader extends AssemblyAIReader {
    /**
     * Transcribe audio or get a transcript and reads subtitles for the transcript as `srt` or `vtt` format.
     * @param params The parameters to transcribe audio or get an existing transcript.
     * @param subtitleFormat The format of the subtitles, either `srt` or `vtt`.
     * @returns A promise that resolves a document containing the subtitles as the page content.
     */
    loadData(params: TranscribeParams | string, subtitleFormat?: SubtitleFormat): Promise<Document[]>;
}

/**
 * papaparse-based csv parser
 * @class CSVReader
 * @implements BaseReader
 */
declare class PapaCSVReader implements BaseReader {
    private concatRows;
    private colJoiner;
    private rowJoiner;
    private papaConfig?;
    /**
     * Constructs a new instance of the class.
     * @param {boolean} [concatRows=true] - whether to concatenate all rows into one document.If set to False, a Document will be created for each row.True by default.
     * @param {string} [colJoiner=', '] - Separator to use for joining cols per row. Set to ", " by default.
     * @param {string} [rowJoiner='\n'] - Separator to use for joining each row.Only used when `concat_rows=True`.Set to "\n" by default.
     */
    constructor(concatRows?: boolean, colJoiner?: string, rowJoiner?: string, papaConfig?: ParseConfig);
    /**
     * Loads data from csv files
     * @param {string} file - The path to the file to load.
     * @param {GenericFileSystem} [fs=DEFAULT_FS] - The file system to use for reading the file.
     * @returns {Promise<Document[]>}
     */
    loadData(file: string, fs?: GenericFileSystem): Promise<Document[]>;
}

/**
 * Extract the significant text from an arbitrary HTML document.
 * The contents of any head, script, style, and xml tags are removed completely.
 * The URLs for a[href] tags are extracted, along with the inner text of the tag.
 * All other tags are removed, and the inner text is kept intact.
 * Html entities (e.g., &amp;) are not decoded.
 */
declare class HTMLReader implements BaseReader {
    /**
     * Public method for this reader.
     * Required by BaseReader interface.
     * @param file Path/name of the file to be loaded.
     * @param fs fs wrapper interface for getting the file content.
     * @returns Promise<Document[]> A Promise object, eventually yielding zero or one Document parsed from the HTML content of the specified file.
     */
    loadData(file: string, fs?: GenericFileSystem): Promise<Document[]>;
    /**
     * Wrapper for string-strip-html usage.
     * @param html Raw HTML content to be parsed.
     * @param options An object of options for the underlying library
     * @see getOptions
     * @returns The HTML content, stripped of unwanted tags and attributes
     */
    parseContent(html: string, options?: any): Promise<string>;
    /**
     * Wrapper for our configuration options passed to string-strip-html library
     * @see https://codsen.com/os/string-strip-html/examples
     * @returns An object of options for the underlying library
     */
    getOptions(): {
        skipHtmlDecoding: boolean;
        stripTogetherWithTheirContents: string[];
    };
}

type MarkdownTuple = [string | null, string];
/**
 * Extract text from markdown files.
 * Returns dictionary with keys as headers and values as the text between headers.
 */
declare class MarkdownReader implements BaseReader {
    private _removeHyperlinks;
    private _removeImages;
    /**
     * @param {boolean} [removeHyperlinks=true] - Indicates whether hyperlinks should be removed.
     * @param {boolean} [removeImages=true] - Indicates whether images should be removed.
     */
    constructor(removeHyperlinks?: boolean, removeImages?: boolean);
    /**
     * Convert a markdown file to a dictionary.
     * The keys are the headers and the values are the text under each header.
     * @param {string} markdownText - The markdown text to convert.
     * @returns {Array<MarkdownTuple>} - An array of tuples, where each tuple contains a header (or null) and its corresponding text.
     */
    markdownToTups(markdownText: string): MarkdownTuple[];
    removeImages(content: string): string;
    removeHyperlinks(content: string): string;
    parseTups(content: string): MarkdownTuple[];
    loadData(file: string, fs?: GenericFileSystem): Promise<Document[]>;
}

type OptionalSerializers = Parameters<Crawler>[number]["serializers"];
/**
 * Options for initializing the NotionReader class
 * @typedef {Object} NotionReaderOptions
 * @property {Client} client - The Notion Client object for API interactions
 * @property {OptionalSerializers} [serializers] - Option to customize serialization. See [the url](https://github.com/TomPenguin/notion-md-crawler/tree/main) for details.
 */
type NotionReaderOptions = {
    client: Client;
    serializers?: OptionalSerializers;
};
/**
 * Notion pages are retrieved recursively and converted to Document objects.
 * Notion Database can also be loaded, and [the serialization method can be customized](https://github.com/TomPenguin/notion-md-crawler/tree/main).
 *
 * [Note] To use this reader, must be created the Notion integration must be created in advance
 * Please refer to [this document](https://www.notion.so/help/create-integrations-with-the-notion-api) for details.
 */
declare class NotionReader implements BaseReader {
    private crawl;
    /**
     * Constructor for the NotionReader class
     * @param {NotionReaderOptions} options - Configuration options for the reader
     */
    constructor({ client, serializers }: NotionReaderOptions);
    /**
     * Converts Pages to an array of Document objects
     * @param {Pages} pages - The Notion pages to convert (Return value of `loadPages`)
     * @returns {Document[]} An array of Document objects
     */
    toDocuments(pages: Pages): Document[];
    /**
     * Loads recursively the Notion page with the specified root page ID.
     * @param {string} rootPageId - The root Notion page ID
     * @returns {Promise<Pages>} A Promise that resolves to a Pages object(Convertible with the `toDocuments` method)
     */
    loadPages(rootPageId: string): Promise<Pages>;
    /**
     * Loads recursively Notion pages and converts them to an array of Document objects
     * @param {string} rootPageId - The root Notion page ID
     * @returns {Promise<Document[]>} A Promise that resolves to an array of Document objects
     */
    loadData(rootPageId: string): Promise<Document[]>;
}

/**
 * Read the text of a PDF
 */
declare class PDFReader implements BaseReader {
    loadData(file: string, fs?: GenericFileSystem): Promise<Document[]>;
}

type ReaderCallback = (category: "file" | "directory", name: string, status: ReaderStatus, message?: string) => boolean;
declare enum ReaderStatus {
    STARTED = 0,
    COMPLETE = 1,
    ERROR = 2
}
/**
 * Read a .txt file
 */
declare class TextFileReader implements BaseReader {
    loadData(file: string, fs?: CompleteFileSystem): Promise<Document[]>;
}
declare const FILE_EXT_TO_READER: Record<string, BaseReader>;
type SimpleDirectoryReaderLoadDataProps = {
    directoryPath: string;
    fs?: CompleteFileSystem;
    defaultReader?: BaseReader | null;
    fileExtToReader?: Record<string, BaseReader>;
};
/**
 * Read all of the documents in a directory.
 * By default, supports the list of file types
 * in the FILE_EXT_TO_READER map.
 */
declare class SimpleDirectoryReader implements BaseReader {
    private observer?;
    constructor(observer?: ReaderCallback | undefined);
    loadData({ directoryPath, fs, defaultReader, fileExtToReader, }: SimpleDirectoryReaderLoadDataProps): Promise<Document[]>;
    private doObserverCheck;
}

/**
 * Read in from MongoDB
 */
declare class SimpleMongoReader implements BaseReader {
    private client;
    constructor(client: MongoClient);
    /**
     * Flattens an array of strings or string arrays into a single-dimensional array of strings.
     * @param texts - The array of strings or string arrays to flatten.
     * @returns The flattened array of strings.
     */
    private flatten;
    /**
     * Loads data from MongoDB collection
     * @param {string} dbName - The name of the database to load.
     * @param {string} collectionName - The name of the collection to load.
     * @param {string[]} fieldNames - An array of field names to retrieve from each document. Defaults to ["text"].
     * @param {string} separator - The separator to join multiple field values. Defaults to an empty string.
     * @param {Record<string, any>} filterQuery - Specific query, as specified by MongoDB NodeJS documentation.
     * @param {Number} maxDocs - The maximum number of documents to retrieve. Defaults to 0 (retrieve all documents).
     * @param {string[]} metadataNames - An optional array of metadata field names. If specified extracts this information as metadata.
     * @returns {Promise<Document[]>}
     * @throws If a field specified in fieldNames or metadataNames is not found in a MongoDB document.
     */
    loadData(dbName: string, collectionName: string, fieldNames?: string[], separator?: string, filterQuery?: Record<string, any>, maxDocs?: number, metadataNames?: string[]): Promise<Document[]>;
}

export { ALL_AVAILABLE_ANTHROPIC_MODELS, ALL_AVAILABLE_LLAMADEUCE_MODELS, ALL_AVAILABLE_MISTRAL_MODELS, ALL_AVAILABLE_OPENAI_MODELS, Anthropic, AnthropicStreamToken, AssemblyAIOptions, AstraDBVectorStore, AudioSubtitlesReader, AudioTranscriptParagraphsReader, AudioTranscriptReader, AudioTranscriptSentencesReader, BaseDocumentStore, BaseEmbedding, BaseInMemoryKVStore, BaseIndex, BaseIndexInit, BaseIndexStore, BaseKVStore, BaseNode, BaseNodePostprocessor, BaseOutputParser, BaseQueryEngine, BaseQuestionGenerator, BaseReader, BaseResponseBuilder, BaseRetriever, BaseSynthesizer, BaseTool, CallbackManager, ChatEngine, ChatHistory, ChatMessage, ChatResponse, ChoiceSelectPrompt, ClipEmbedding, ClipEmbeddingModelType, CompactAndRefine, CompleteFileSystem, CompletionResponse, CondenseQuestionChatEngine, CondenseQuestionPrompt, Context, ContextChatEngine, ContextGenerator, ContextSystemPrompt, DEFAULT_CHUNK_OVERLAP, DEFAULT_CHUNK_OVERLAP_RATIO, DEFAULT_CHUNK_SIZE, DEFAULT_COLLECTION, DEFAULT_CONTEXT_WINDOW, DEFAULT_DOC_STORE_PERSIST_FILENAME, DEFAULT_EMBEDDING_DIM, DEFAULT_FS, DEFAULT_GRAPH_STORE_PERSIST_FILENAME, DEFAULT_IMAGE_VECTOR_NAMESPACE, DEFAULT_INDEX_STORE_PERSIST_FILENAME, DEFAULT_NAMESPACE, DEFAULT_NUM_OUTPUTS, DEFAULT_PADDING, DEFAULT_PERSIST_DIR, DEFAULT_SIMILARITY_TOP_K, DEFAULT_VECTOR_STORE_PERSIST_FILENAME, DefaultContextGenerator, DefaultStreamToken, DeuceChatStrategy, Document, Event, EventTag, EventType, ExactMatchFilter, FILE_EXT_TO_READER, GPT35_MODELS, GPT4_MODELS, GenericFileSystem, HTMLReader, HistoryChatEngine, ImageDocument, ImageNode, ImageNodeConstructorProps, ImageType, InMemoryFileSystem, IndexDict, IndexList, IndexNode, IndexStruct, IndexStructType, KeywordExtractPrompt, KeywordTable, KeywordTableIndex, KeywordTableLLMRetriever, KeywordTableRAKERetriever, KeywordTableRetrieverMode, KeywordTableSimpleRetriever, LLM, LLMMetadata, LLMQuestionGenerator, ListIndex, ListIndexLLMRetriever, ListIndexRetriever, ListRetrieverMode, LlamaDeuce, MarkdownReader, MessageContent, MessageContentDetail, MessageType, Metadata, MetadataFilters, MetadataInfo, MetadataMode, MistralAI, MistralAIEmbedding, MistralAIEmbeddingModelType, MistralAISession, MongoDBAtlasVectorSearch, MultiModalEmbedding, MultiModalResponseSynthesizer, NodeParser, NodeRelationship, NodeWithScore, NotionReader, ObjectType, OpenAI, OpenAIEmbedding, OpenAIEmbeddingModelType, OpenAIStreamToken, PDFReader, PGVectorStore, PapaCSVReader, Portkey, PromptHelper, QueryEngineTool, QueryKeywordExtractPrompt, RefDocInfo, Refine, RefinePrompt, RelatedNodeInfo, RelatedNodeType, Response, ResponseSynthesizer, RetrievalCallbackResponse, RetrieverQueryEngine, SentenceSplitter, ServiceContext, ServiceContextOptions, SimilarityPostprocessor, SimilarityType, SimpleChatEngine, SimpleChatHistory, SimpleDirectoryReader, SimpleDirectoryReaderLoadDataProps, SimpleDocumentStore, SimpleIndexStore, SimpleKVStore, SimpleMongoReader, SimpleNodeParser, SimplePrompt, SimpleResponseBuilder, SimpleVectorStore, StorageContext, StreamCallbackResponse, StructuredOutput, SubQuestion, SubQuestionOutputParser, SubQuestionPrompt, SubQuestionQueryEngine, SummaryChatHistory, SummaryIndex, SummaryIndexLLMRetriever, SummaryIndexRetriever, SummaryPrompt, SummaryRetrieverMode, TextFileReader, TextNode, TextQaPrompt, Tokenizers, ToolMetadata, TreeSummarize, TreeSummarizePrompt, VectorIndexRetriever, VectorStore, VectorStoreIndex, VectorStoreInfo, VectorStoreQuery, VectorStoreQueryMode, VectorStoreQueryResult, VectorStoreQuerySpec, WalkableFileSystem, anthropicTextQaPrompt, buildToolsText, cjkSentenceTokenizer, defaultChoiceSelectPrompt, defaultCondenseQuestionPrompt, defaultContextSystemPrompt, defaultKeywordExtractPrompt, defaultQueryKeywordExtractPrompt, defaultRefinePrompt, defaultSubQuestionPrompt, defaultSummaryPrompt, defaultTextQaPrompt, defaultTreeSummarizePrompt, englishSentenceTokenizer, exists, getBiggestPrompt, getEmptyPromptTxt, getNodeFS, getNodesFromDocument, getResponseBuilder, getTextSplitsFromDocument, getTopKEmbeddings, getTopKEmbeddingsLearner, getTopKMMREmbeddings, globalsHelper, imageToDataUrl, imageToString, jsonToIndexStruct, jsonToNode, messagesToHistoryStr, parseJsonMarkdown, readImage, serviceContextFromDefaults, serviceContextFromServiceContext, similarity, splitNodesByType, storageContextFromDefaults, stringToImage, unixLineSeparator, unixParagraphSeparator, walk, windowsLineSeparator, windowsParagraphSeparator };
