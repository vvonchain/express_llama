var __defProp = Object.defineProperty;
var __defProps = Object.defineProperties;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropDescs = Object.getOwnPropertyDescriptors;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __reflectGet = Reflect.get;
var __knownSymbol = (name, symbol) => {
  if (symbol = Symbol[name])
    return symbol;
  throw Error("Symbol." + name + " is not defined");
};
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __spreadValues = (a, b) => {
  for (var prop in b || (b = {}))
    if (__hasOwnProp.call(b, prop))
      __defNormalProp(a, prop, b[prop]);
  if (__getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(b)) {
      if (__propIsEnum.call(b, prop))
        __defNormalProp(a, prop, b[prop]);
    }
  return a;
};
var __spreadProps = (a, b) => __defProps(a, __getOwnPropDescs(b));
var __require = /* @__PURE__ */ ((x) => typeof require !== "undefined" ? require : typeof Proxy !== "undefined" ? new Proxy(x, {
  get: (a, b) => (typeof require !== "undefined" ? require : a)[b]
}) : x)(function(x) {
  if (typeof require !== "undefined")
    return require.apply(this, arguments);
  throw Error('Dynamic require of "' + x + '" is not supported');
});
var __objRest = (source, exclude) => {
  var target = {};
  for (var prop in source)
    if (__hasOwnProp.call(source, prop) && exclude.indexOf(prop) < 0)
      target[prop] = source[prop];
  if (source != null && __getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(source)) {
      if (exclude.indexOf(prop) < 0 && __propIsEnum.call(source, prop))
        target[prop] = source[prop];
    }
  return target;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __reExport = (target, mod, secondTarget) => (__copyProps(target, mod, "default"), secondTarget && __copyProps(secondTarget, mod, "default"));
var __superGet = (cls, obj, key) => __reflectGet(__getProtoOf(cls), key, obj);
var __async = (__this, __arguments, generator) => {
  return new Promise((resolve, reject) => {
    var fulfilled = (value) => {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    };
    var rejected = (value) => {
      try {
        step(generator.throw(value));
      } catch (e) {
        reject(e);
      }
    };
    var step = (x) => x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
    step((generator = generator.apply(__this, __arguments)).next());
  });
};
var __await = function(promise, isYieldStar) {
  this[0] = promise;
  this[1] = isYieldStar;
};
var __asyncGenerator = (__this, __arguments, generator) => {
  var resume = (k, v, yes, no) => {
    try {
      var x = generator[k](v), isAwait = (v = x.value) instanceof __await, done = x.done;
      Promise.resolve(isAwait ? v[0] : v).then((y) => isAwait ? resume(k === "return" ? k : "next", v[1] ? { done: y.done, value: y.value } : y, yes, no) : yes({ value: y, done })).catch((e) => resume("throw", e, yes, no));
    } catch (e) {
      no(e);
    }
  };
  var method = (k) => it[k] = (x) => new Promise((yes, no) => resume(k, x, yes, no));
  var it = {};
  return generator = generator.apply(__this, __arguments), it[Symbol.asyncIterator] = () => it, method("next"), method("throw"), method("return"), it;
};
var __yieldStar = (value) => {
  var obj = value[__knownSymbol("asyncIterator")];
  var isAwait = false;
  var method;
  var it = {};
  if (obj == null) {
    obj = value[__knownSymbol("iterator")]();
    method = (k) => it[k] = (x) => obj[k](x);
  } else {
    obj = obj.call(value);
    method = (k) => it[k] = (v) => {
      if (isAwait) {
        isAwait = false;
        if (k === "throw")
          throw v;
        return v;
      }
      isAwait = true;
      return {
        done: false,
        value: new __await(new Promise((resolve) => {
          var x = obj[k](v);
          if (!(x instanceof Object))
            throw TypeError("Object expected");
          resolve(x);
        }), 1)
      };
    };
  }
  return it[__knownSymbol("iterator")] = () => it, method("next"), "throw" in obj ? method("throw") : it.throw = (x) => {
    throw x;
  }, "return" in obj && method("return"), it;
};
var __forAwait = (obj, it, method) => (it = obj[__knownSymbol("asyncIterator")]) ? it.call(obj) : (obj = obj[__knownSymbol("iterator")](), it = {}, method = (key, fn) => (fn = obj[key]) && (it[key] = (arg) => new Promise((yes, no, done) => (arg = fn.call(obj, arg), done = arg.done, Promise.resolve(arg.value).then((value) => yes({ value, done }), no)))), method("next"), method("return"), it);

// src/ChatEngine.ts
import { v4 as uuidv44 } from "uuid";

// src/Prompt.ts
var defaultTextQaPrompt = ({ context = "", query = "" }) => {
  return `Context information is below.
---------------------
${context}
---------------------
Given the context information and not prior knowledge, answer the query.
Query: ${query}
Answer:`;
};
var anthropicTextQaPrompt = ({ context = "", query = "" }) => {
  return `Context information:
<context>
${context}
</context>
Given the context information and not prior knowledge, answer the query.
Query: ${query}`;
};
var defaultSummaryPrompt = ({ context = "" }) => {
  return `Write a summary of the following. Try to use only the information provided. Try to include as many key details as possible.


${context}


SUMMARY:"""
`;
};
var defaultRefinePrompt = ({
  query = "",
  existingAnswer = "",
  context = ""
}) => {
  return `The original query is as follows: ${query}
We have provided an existing answer: ${existingAnswer}
We have the opportunity to refine the existing answer (only if needed) with some more context below.
------------
${context}
------------
Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.
Refined Answer:`;
};
var defaultTreeSummarizePrompt = ({ context = "", query = "" }) => {
  return `Context information from multiple sources is below.
---------------------
${context}
---------------------
Given the information from multiple sources and not prior knowledge, answer the query.
Query: ${query}
Answer:`;
};
var defaultChoiceSelectPrompt = ({ context = "", query = "" }) => {
  return `A list of documents is shown below. Each document has a number next to it along 
with a summary of the document. A question is also provided.
Respond with the numbers of the documents
you should consult to answer the question, in order of relevance, as well
as the relevance score. The relevance score is a number from 1-10 based on
how relevant you think the document is to the question.
Do not include any documents that are not relevant to the question.
Example format:
Document 1:
<summary of document 1>

Document 2:
<summary of document 2>

...

Document 10:
<summary of document 10>

Question: <question>
Answer:
Doc: 9, Relevance: 7
Doc: 3, Relevance: 4
Doc: 7, Relevance: 3

Let's try this now:

${context}
Question: ${query}
Answer:`;
};
function buildToolsText(tools) {
  const toolsObj = tools.reduce((acc, tool) => {
    acc[tool.name] = tool.description;
    return acc;
  }, {});
  return JSON.stringify(toolsObj, null, 4);
}
var exampleTools = [
  {
    name: "uber_10k",
    description: "Provides information about Uber financials for year 2021"
  },
  {
    name: "lyft_10k",
    description: "Provides information about Lyft financials for year 2021"
  }
];
var exampleQueryStr = `Compare and contrast the revenue growth and EBITDA of Uber and Lyft for year 2021`;
var exampleOutput = [
  {
    subQuestion: "What is the revenue growth of Uber",
    toolName: "uber_10k"
  },
  {
    subQuestion: "What is the EBITDA of Uber",
    toolName: "uber_10k"
  },
  {
    subQuestion: "What is the revenue growth of Lyft",
    toolName: "lyft_10k"
  },
  {
    subQuestion: "What is the EBITDA of Lyft",
    toolName: "lyft_10k"
  }
];
var defaultSubQuestionPrompt = ({ toolsStr = "", queryStr = "" }) => {
  return `Given a user question, and a list of tools, output a list of relevant sub-questions that when composed can help answer the full user question:

# Example 1
<Tools>
\`\`\`json
${buildToolsText(exampleTools)}
\`\`\`

<User Question>
${exampleQueryStr}

<Output>
\`\`\`json
${JSON.stringify(exampleOutput, null, 4)}
\`\`\`

# Example 2
<Tools>
\`\`\`json
${toolsStr}
\`\`\`

<User Question>
${queryStr}

<Output>
`;
};
var defaultCondenseQuestionPrompt = ({
  chatHistory = "",
  question = ""
}) => {
  return `Given a conversation (between Human and Assistant) and a follow up message from Human, rewrite the message to be a standalone question that captures all relevant context from the conversation.

<Chat History>
${chatHistory}

<Follow Up Message>
${question}

<Standalone question>
`;
};
function messagesToHistoryStr(messages) {
  return messages.reduce((acc, message) => {
    acc += acc ? "\n" : "";
    if (message.role === "user") {
      acc += `Human: ${message.content}`;
    } else {
      acc += `Assistant: ${message.content}`;
    }
    return acc;
  }, "");
}
var defaultContextSystemPrompt = ({ context = "" }) => {
  return `Context information is below.
---------------------
${context}
---------------------`;
};
var defaultKeywordExtractPrompt = ({
  context = "",
  maxKeywords = 10
}) => {
  return `
Some text is provided below. Given the text, extract up to ${maxKeywords} keywords from the text. Avoid stopwords.
---------------------
${context}
---------------------
Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'
`;
};
var defaultQueryKeywordExtractPrompt = ({
  question = "",
  maxKeywords = 10
}) => {
  return `(
  "A question is provided below. Given the question, extract up to ${maxKeywords} "
  "keywords from the text. Focus on extracting the keywords that we can use "
  "to best lookup answers to the question. Avoid stopwords."
  "---------------------"
  "${question}"
  "---------------------"
  "Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'"
)`;
};

// src/Response.ts
var Response = class {
  constructor(response, sourceNodes) {
    this.response = response;
    this.sourceNodes = sourceNodes || [];
  }
  getFormattedSources() {
    throw new Error("Not implemented yet");
  }
  toString() {
    var _a;
    return (_a = this.response) != null ? _a : "";
  }
};

// src/callbacks/CallbackManager.ts
var CallbackManager = class {
  constructor(handlers) {
    this.onLLMStream = handlers == null ? void 0 : handlers.onLLMStream;
    this.onRetrieve = handlers == null ? void 0 : handlers.onRetrieve;
  }
};

// src/embeddings/utils.ts
import _7 from "lodash";

// src/constants.ts
var DEFAULT_CONTEXT_WINDOW = 3900;
var DEFAULT_NUM_OUTPUTS = 256;
var DEFAULT_CHUNK_SIZE = 1024;
var DEFAULT_CHUNK_OVERLAP = 20;
var DEFAULT_CHUNK_OVERLAP_RATIO = 0.1;
var DEFAULT_SIMILARITY_TOP_K = 2;
var DEFAULT_EMBEDDING_DIM = 1536;
var DEFAULT_PADDING = 5;

// src/storage/FileSystem.ts
import _ from "lodash";
var InMemoryFileSystem = class {
  constructor() {
    this.files = {};
  }
  writeFile(path7, content, options) {
    return __async(this, null, function* () {
      this.files[path7] = _.cloneDeep(content);
    });
  }
  readFile(path7, options) {
    return __async(this, null, function* () {
      if (!(path7 in this.files)) {
        throw new Error(`File ${path7} does not exist`);
      }
      return _.cloneDeep(this.files[path7]);
    });
  }
  access(path7) {
    return __async(this, null, function* () {
      if (!(path7 in this.files)) {
        throw new Error(`File ${path7} does not exist`);
      }
    });
  }
  mkdir(path7, options) {
    return __async(this, null, function* () {
      this.files[path7] = _.get(this.files, path7, null);
    });
  }
};
function getNodeFS() {
  const fs2 = __require("fs/promises");
  return fs2;
}
var fs = null;
try {
  fs = getNodeFS();
} catch (e) {
  fs = new InMemoryFileSystem();
}
var DEFAULT_FS = fs;
function exists(fs2, path7) {
  return __async(this, null, function* () {
    try {
      yield fs2.access(path7);
      return true;
    } catch (e) {
      return false;
    }
  });
}
function walk(fs2, dirPath) {
  return __asyncGenerator(this, null, function* () {
    if (fs2 instanceof InMemoryFileSystem) {
      throw new Error(
        "The InMemoryFileSystem does not support directory traversal."
      );
    }
    const entries = yield new __await(fs2.readdir(dirPath));
    for (const entry of entries) {
      const fullPath = `${dirPath}/${entry}`;
      const stats = yield new __await(fs2.stat(fullPath));
      if (stats.isDirectory()) {
        yield* __yieldStar(walk(fs2, fullPath));
      } else {
        yield fullPath;
      }
    }
  });
}

// src/storage/StorageContext.ts
import * as path6 from "path";

// src/storage/constants.ts
var DEFAULT_COLLECTION = "data";
var DEFAULT_PERSIST_DIR = "./storage";
var DEFAULT_INDEX_STORE_PERSIST_FILENAME = "index_store.json";
var DEFAULT_DOC_STORE_PERSIST_FILENAME = "doc_store.json";
var DEFAULT_VECTOR_STORE_PERSIST_FILENAME = "vector_store.json";
var DEFAULT_GRAPH_STORE_PERSIST_FILENAME = "graph_store.json";
var DEFAULT_NAMESPACE = "docstore";
var DEFAULT_IMAGE_VECTOR_NAMESPACE = "images";

// src/storage/docStore/SimpleDocumentStore.ts
import _4 from "lodash";
import * as path3 from "path";

// src/storage/kvStore/SimpleKVStore.ts
import * as _2 from "lodash";
import * as path from "path";

// src/storage/kvStore/types.ts
var BaseKVStore = class {
};
var BaseInMemoryKVStore = class extends BaseKVStore {
  static fromPersistPath(persistPath) {
    throw new Error("Method not implemented.");
  }
};

// src/storage/kvStore/SimpleKVStore.ts
var SimpleKVStore = class _SimpleKVStore extends BaseKVStore {
  constructor(data) {
    super();
    this.data = data || {};
  }
  put(_0, _1) {
    return __async(this, arguments, function* (key, val, collection = DEFAULT_COLLECTION) {
      if (!(collection in this.data)) {
        this.data[collection] = {};
      }
      this.data[collection][key] = _2.clone(val);
      if (this.persistPath) {
        yield this.persist(this.persistPath, this.fs);
      }
    });
  }
  get(_0) {
    return __async(this, arguments, function* (key, collection = DEFAULT_COLLECTION) {
      let collectionData = this.data[collection];
      if (_2.isNil(collectionData)) {
        return null;
      }
      if (!(key in collectionData)) {
        return null;
      }
      return _2.clone(collectionData[key]);
    });
  }
  getAll() {
    return __async(this, arguments, function* (collection = DEFAULT_COLLECTION) {
      return _2.clone(this.data[collection]);
    });
  }
  delete(_0) {
    return __async(this, arguments, function* (key, collection = DEFAULT_COLLECTION) {
      if (key in this.data[collection]) {
        delete this.data[collection][key];
        return true;
      }
      return false;
    });
  }
  persist(persistPath, fs2) {
    return __async(this, null, function* () {
      fs2 = fs2 || DEFAULT_FS;
      let dirPath = path.dirname(persistPath);
      if (!(yield exists(fs2, dirPath))) {
        yield fs2.mkdir(dirPath);
      }
      yield fs2.writeFile(persistPath, JSON.stringify(this.data));
    });
  }
  static fromPersistPath(persistPath, fs2) {
    return __async(this, null, function* () {
      fs2 = fs2 || DEFAULT_FS;
      let dirPath = path.dirname(persistPath);
      if (!(yield exists(fs2, dirPath))) {
        yield fs2.mkdir(dirPath);
      }
      let data = {};
      try {
        let fileData = yield fs2.readFile(persistPath);
        data = JSON.parse(fileData.toString());
      } catch (e) {
        console.error(
          `No valid data found at path: ${persistPath} starting new store.`
        );
      }
      const store = new _SimpleKVStore(data);
      store.persistPath = persistPath;
      store.fs = fs2;
      return store;
    });
  }
  toDict() {
    return this.data;
  }
  static fromDict(saveDict) {
    return new _SimpleKVStore(saveDict);
  }
};

// src/storage/docStore/KVDocumentStore.ts
import _3, * as lodash from "lodash";

// src/Node.ts
import CryptoJS from "crypto-js";
import path2 from "path";
import { v4 as uuidv4 } from "uuid";
var NodeRelationship = /* @__PURE__ */ ((NodeRelationship2) => {
  NodeRelationship2["SOURCE"] = "SOURCE";
  NodeRelationship2["PREVIOUS"] = "PREVIOUS";
  NodeRelationship2["NEXT"] = "NEXT";
  NodeRelationship2["PARENT"] = "PARENT";
  NodeRelationship2["CHILD"] = "CHILD";
  return NodeRelationship2;
})(NodeRelationship || {});
var ObjectType = /* @__PURE__ */ ((ObjectType2) => {
  ObjectType2["TEXT"] = "TEXT";
  ObjectType2["IMAGE"] = "IMAGE";
  ObjectType2["INDEX"] = "INDEX";
  ObjectType2["DOCUMENT"] = "DOCUMENT";
  ObjectType2["IMAGE_DOCUMENT"] = "IMAGE_DOCUMENT";
  return ObjectType2;
})(ObjectType || {});
var MetadataMode = /* @__PURE__ */ ((MetadataMode2) => {
  MetadataMode2["ALL"] = "ALL";
  MetadataMode2["EMBED"] = "EMBED";
  MetadataMode2["LLM"] = "LLM";
  MetadataMode2["NONE"] = "NONE";
  return MetadataMode2;
})(MetadataMode || {});
var BaseNode = class {
  constructor(init) {
    /**
     * The unique ID of the Node/Document. The trailing underscore is here
     * to avoid collisions with the id keyword in Python.
     *
     * Set to a UUID by default.
     */
    this.id_ = uuidv4();
    // Metadata fields
    this.metadata = {};
    this.excludedEmbedMetadataKeys = [];
    this.excludedLlmMetadataKeys = [];
    this.relationships = {};
    this.hash = "";
    Object.assign(this, init);
  }
  get sourceNode() {
    const relationship = this.relationships["SOURCE" /* SOURCE */];
    if (Array.isArray(relationship)) {
      throw new Error("Source object must be a single RelatedNodeInfo object");
    }
    return relationship;
  }
  get prevNode() {
    const relationship = this.relationships["PREVIOUS" /* PREVIOUS */];
    if (Array.isArray(relationship)) {
      throw new Error(
        "Previous object must be a single RelatedNodeInfo object"
      );
    }
    return relationship;
  }
  get nextNode() {
    const relationship = this.relationships["NEXT" /* NEXT */];
    if (Array.isArray(relationship)) {
      throw new Error("Next object must be a single RelatedNodeInfo object");
    }
    return relationship;
  }
  get parentNode() {
    const relationship = this.relationships["PARENT" /* PARENT */];
    if (Array.isArray(relationship)) {
      throw new Error("Parent object must be a single RelatedNodeInfo object");
    }
    return relationship;
  }
  get childNodes() {
    const relationship = this.relationships["CHILD" /* CHILD */];
    if (!Array.isArray(relationship)) {
      throw new Error(
        "Child object must be a an array of RelatedNodeInfo objects"
      );
    }
    return relationship;
  }
  getEmbedding() {
    if (this.embedding === void 0) {
      throw new Error("Embedding not set");
    }
    return this.embedding;
  }
  asRelatedNodeInfo() {
    return {
      nodeId: this.id_,
      metadata: this.metadata,
      hash: this.hash
    };
  }
  /**
   * Used with built in JSON.stringify
   * @returns
   */
  toJSON() {
    return __spreadProps(__spreadValues({}, this), { type: this.getType() });
  }
};
var TextNode = class _TextNode extends BaseNode {
  constructor(init) {
    super(init);
    this.text = "";
    // textTemplate: NOTE write your own formatter if needed
    // metadataTemplate: NOTE write your own formatter if needed
    this.metadataSeparator = "\n";
    Object.assign(this, init);
    if (new.target === _TextNode) {
      this.hash = this.generateHash();
    }
  }
  /**
   * Generate a hash of the text node.
   * The ID is not part of the hash as it can change independent of content.
   * @returns
   */
  generateHash() {
    const hashFunction = CryptoJS.algo.SHA256.create();
    hashFunction.update(`type=${this.getType()}`);
    hashFunction.update(
      `startCharIdx=${this.startCharIdx} endCharIdx=${this.endCharIdx}`
    );
    hashFunction.update(this.getContent("ALL" /* ALL */));
    return hashFunction.finalize().toString(CryptoJS.enc.Base64);
  }
  getType() {
    return "TEXT" /* TEXT */;
  }
  getContent(metadataMode = "NONE" /* NONE */) {
    const metadataStr = this.getMetadataStr(metadataMode).trim();
    return `${metadataStr}

${this.text}`.trim();
  }
  getMetadataStr(metadataMode) {
    if (metadataMode === "NONE" /* NONE */) {
      return "";
    }
    const usableMetadataKeys = new Set(Object.keys(this.metadata).sort());
    if (metadataMode === "LLM" /* LLM */) {
      for (const key of this.excludedLlmMetadataKeys) {
        usableMetadataKeys.delete(key);
      }
    } else if (metadataMode === "EMBED" /* EMBED */) {
      for (const key of this.excludedEmbedMetadataKeys) {
        usableMetadataKeys.delete(key);
      }
    }
    return [...usableMetadataKeys].map((key) => `${key}: ${this.metadata[key]}`).join(this.metadataSeparator);
  }
  setContent(value) {
    this.text = value;
    this.hash = this.generateHash();
  }
  getNodeInfo() {
    return { start: this.startCharIdx, end: this.endCharIdx };
  }
  getText() {
    return this.getContent("NONE" /* NONE */);
  }
};
var IndexNode = class _IndexNode extends TextNode {
  constructor(init) {
    super(init);
    this.indexId = "";
    Object.assign(this, init);
    if (new.target === _IndexNode) {
      this.hash = this.generateHash();
    }
  }
  getType() {
    return "INDEX" /* INDEX */;
  }
};
var Document = class _Document extends TextNode {
  constructor(init) {
    super(init);
    Object.assign(this, init);
    if (new.target === _Document) {
      this.hash = this.generateHash();
    }
  }
  getType() {
    return "DOCUMENT" /* DOCUMENT */;
  }
};
function jsonToNode(json, type) {
  if (!json.type && !type) {
    throw new Error("Node type not found");
  }
  const nodeType = type || json.type;
  switch (nodeType) {
    case "TEXT" /* TEXT */:
      return new TextNode(json);
    case "INDEX" /* INDEX */:
      return new IndexNode(json);
    case "DOCUMENT" /* DOCUMENT */:
      return new Document(json);
    case "IMAGE_DOCUMENT" /* IMAGE_DOCUMENT */:
      return new ImageDocument(json);
    default:
      throw new Error(`Invalid node type: ${nodeType}`);
  }
}
var ImageNode = class extends TextNode {
  // image as blob
  constructor(init) {
    super(init);
    this.image = init.image;
  }
  getType() {
    return "IMAGE" /* IMAGE */;
  }
  getUrl() {
    const absPath = path2.resolve(this.id_);
    return new URL(`file://${absPath}`);
  }
};
var ImageDocument = class _ImageDocument extends ImageNode {
  constructor(init) {
    super(init);
    if (new.target === _ImageDocument) {
      this.hash = this.generateHash();
    }
  }
  getType() {
    return "IMAGE_DOCUMENT" /* IMAGE_DOCUMENT */;
  }
};
function splitNodesByType(nodes) {
  let imageNodes = [];
  let textNodes = [];
  for (let node of nodes) {
    if (node instanceof ImageNode) {
      imageNodes.push(node);
    } else if (node instanceof TextNode) {
      textNodes.push(node);
    }
  }
  return {
    imageNodes,
    textNodes
  };
}

// src/storage/docStore/types.ts
var defaultPersistPath = `${DEFAULT_PERSIST_DIR}/${DEFAULT_DOC_STORE_PERSIST_FILENAME}`;
var BaseDocumentStore = class {
  // Save/load
  persist(persistPath = defaultPersistPath, fs2) {
  }
  // Nodes
  getNodes(nodeIds, raiseError = true) {
    return Promise.all(
      nodeIds.map((nodeId) => this.getNode(nodeId, raiseError))
    );
  }
  getNode(nodeId, raiseError = true) {
    return __async(this, null, function* () {
      let doc = yield this.getDocument(nodeId, raiseError);
      if (!(doc instanceof BaseNode)) {
        throw new Error(`Document ${nodeId} is not a Node.`);
      }
      return doc;
    });
  }
  getNodeDict(nodeIdDict) {
    return __async(this, null, function* () {
      let result = {};
      for (let index in nodeIdDict) {
        result[index] = yield this.getNode(nodeIdDict[index]);
      }
      return result;
    });
  }
};

// src/storage/docStore/utils.ts
var TYPE_KEY = "__type__";
var DATA_KEY = "__data__";
function docToJson(doc) {
  return {
    [DATA_KEY]: JSON.stringify(doc),
    [TYPE_KEY]: doc.getType()
  };
}
function jsonToDoc(docDict) {
  let docType = docDict[TYPE_KEY];
  let dataDict = JSON.parse(docDict[DATA_KEY]);
  let doc;
  if (docType === "DOCUMENT" /* DOCUMENT */) {
    doc = new Document({
      text: dataDict.text,
      id_: dataDict.id_,
      embedding: dataDict.embedding,
      hash: dataDict.hash,
      metadata: dataDict.metadata
    });
  } else if (docType === "TEXT" /* TEXT */) {
    doc = new TextNode({
      text: dataDict.text,
      id_: dataDict.id_,
      hash: dataDict.hash,
      metadata: dataDict.metadata
    });
  } else {
    throw new Error(`Unknown doc type: ${docType}`);
  }
  return doc;
}

// src/storage/docStore/KVDocumentStore.ts
var KVDocumentStore = class extends BaseDocumentStore {
  constructor(kvstore, namespace = DEFAULT_NAMESPACE) {
    super();
    this.kvstore = kvstore;
    this.nodeCollection = `${namespace}/data`;
    this.refDocCollection = `${namespace}/ref_doc_info`;
    this.metadataCollection = `${namespace}/metadata`;
  }
  docs() {
    return __async(this, null, function* () {
      let jsonDict = yield this.kvstore.getAll(this.nodeCollection);
      let docs = {};
      for (let key in jsonDict) {
        docs[key] = jsonToDoc(jsonDict[key]);
      }
      return docs;
    });
  }
  addDocuments(docs, allowUpdate = true) {
    return __async(this, null, function* () {
      for (var idx = 0; idx < docs.length; idx++) {
        const doc = docs[idx];
        if (doc.id_ === null) {
          throw new Error("doc_id not set");
        }
        if (!allowUpdate && (yield this.documentExists(doc.id_))) {
          throw new Error(
            `doc_id ${doc.id_} already exists. Set allow_update to True to overwrite.`
          );
        }
        let nodeKey = doc.id_;
        let data = docToJson(doc);
        yield this.kvstore.put(nodeKey, data, this.nodeCollection);
        let metadata = { docHash: doc.hash };
        if (doc.getType() === "TEXT" /* TEXT */ && doc.sourceNode !== void 0) {
          let refDocInfo = (yield this.getRefDocInfo(doc.sourceNode.nodeId)) || {
            nodeIds: [],
            extraInfo: {}
          };
          refDocInfo.nodeIds.push(doc.id_);
          if (_3.isEmpty(refDocInfo.extraInfo)) {
            refDocInfo.extraInfo = {};
          }
          yield this.kvstore.put(
            doc.sourceNode.nodeId,
            refDocInfo,
            this.refDocCollection
          );
          metadata.refDocId = doc.sourceNode.nodeId;
        }
        this.kvstore.put(nodeKey, metadata, this.metadataCollection);
      }
    });
  }
  getDocument(docId, raiseError = true) {
    return __async(this, null, function* () {
      let json = yield this.kvstore.get(docId, this.nodeCollection);
      if (_3.isNil(json)) {
        if (raiseError) {
          throw new Error(`docId ${docId} not found.`);
        } else {
          return;
        }
      }
      return jsonToDoc(json);
    });
  }
  getRefDocInfo(refDocId) {
    return __async(this, null, function* () {
      let refDocInfo = yield this.kvstore.get(refDocId, this.refDocCollection);
      return refDocInfo ? _3.clone(refDocInfo) : void 0;
    });
  }
  getAllRefDocInfo() {
    return __async(this, null, function* () {
      let refDocInfos = yield this.kvstore.getAll(this.refDocCollection);
      if (_3.isNil(refDocInfos)) {
        return;
      }
      return refDocInfos;
    });
  }
  refDocExists(refDocId) {
    return __async(this, null, function* () {
      return !_3.isNil(yield this.getRefDocInfo(refDocId));
    });
  }
  documentExists(docId) {
    return __async(this, null, function* () {
      return !_3.isNil(yield this.kvstore.get(docId, this.nodeCollection));
    });
  }
  removeRefDocNode(docId) {
    return __async(this, null, function* () {
      let metadata = yield this.kvstore.get(docId, this.metadataCollection);
      if (metadata === null) {
        return;
      }
      let refDocId = metadata.refDocId;
      if (_3.isNil(refDocId)) {
        return;
      }
      const refDocInfo = yield this.kvstore.get(refDocId, this.refDocCollection);
      if (!_3.isNil(refDocInfo)) {
        lodash.pull(refDocInfo.docIds, docId);
        if (refDocInfo.docIds.length > 0) {
          this.kvstore.put(refDocId, refDocInfo.toDict(), this.refDocCollection);
        }
        this.kvstore.delete(refDocId, this.metadataCollection);
      }
    });
  }
  deleteDocument(docId, raiseError = true, removeRefDocNode = true) {
    return __async(this, null, function* () {
      if (removeRefDocNode) {
        yield this.removeRefDocNode(docId);
      }
      let deleteSuccess = yield this.kvstore.delete(docId, this.nodeCollection);
      yield this.kvstore.delete(docId, this.metadataCollection);
      if (!deleteSuccess && raiseError) {
        throw new Error(`doc_id ${docId} not found.`);
      }
    });
  }
  deleteRefDoc(refDocId, raiseError = true) {
    return __async(this, null, function* () {
      let refDocInfo = yield this.getRefDocInfo(refDocId);
      if (_3.isNil(refDocInfo)) {
        if (raiseError) {
          throw new Error(`ref_doc_id ${refDocId} not found.`);
        } else {
          return;
        }
      }
      for (let docId of refDocInfo.nodeIds) {
        yield this.deleteDocument(docId, false, false);
      }
      yield this.kvstore.delete(refDocId, this.metadataCollection);
      yield this.kvstore.delete(refDocId, this.refDocCollection);
    });
  }
  setDocumentHash(docId, docHash) {
    return __async(this, null, function* () {
      let metadata = { docHash };
      yield this.kvstore.put(docId, metadata, this.metadataCollection);
    });
  }
  getDocumentHash(docId) {
    return __async(this, null, function* () {
      let metadata = yield this.kvstore.get(docId, this.metadataCollection);
      return _3.get(metadata, "docHash");
    });
  }
};

// src/storage/docStore/SimpleDocumentStore.ts
var SimpleDocumentStore = class _SimpleDocumentStore extends KVDocumentStore {
  constructor(kvStore, namespace) {
    kvStore = kvStore || new SimpleKVStore();
    namespace = namespace || DEFAULT_NAMESPACE;
    super(kvStore, namespace);
    this.kvStore = kvStore;
  }
  static fromPersistDir() {
    return __async(this, arguments, function* (persistDir = DEFAULT_PERSIST_DIR, namespace, fsModule) {
      const persistPath = path3.join(
        persistDir,
        DEFAULT_DOC_STORE_PERSIST_FILENAME
      );
      return yield _SimpleDocumentStore.fromPersistPath(
        persistPath,
        namespace,
        fsModule
      );
    });
  }
  static fromPersistPath(persistPath, namespace, fs2) {
    return __async(this, null, function* () {
      fs2 = fs2 || DEFAULT_FS;
      const simpleKVStore = yield SimpleKVStore.fromPersistPath(persistPath, fs2);
      return new _SimpleDocumentStore(simpleKVStore, namespace);
    });
  }
  persist() {
    return __async(this, arguments, function* (persistPath = path3.join(
      DEFAULT_PERSIST_DIR,
      DEFAULT_DOC_STORE_PERSIST_FILENAME
    ), fs2) {
      fs2 = fs2 || DEFAULT_FS;
      if (_4.isObject(this.kvStore) && this.kvStore instanceof BaseInMemoryKVStore) {
        yield this.kvStore.persist(persistPath, fs2);
      }
    });
  }
  static fromDict(saveDict, namespace) {
    const simpleKVStore = SimpleKVStore.fromDict(saveDict);
    return new _SimpleDocumentStore(simpleKVStore, namespace);
  }
  toDict() {
    if (_4.isObject(this.kvStore) && this.kvStore instanceof SimpleKVStore) {
      return this.kvStore.toDict();
    }
    throw new Error("KVStore is not a SimpleKVStore");
  }
};

// src/storage/indexStore/SimpleIndexStore.ts
import * as path4 from "path";

// src/storage/indexStore/KVIndexStore.ts
import _5 from "lodash";

// src/indices/BaseIndex.ts
import { v4 as uuidv42 } from "uuid";
var IndexStruct = class {
  constructor(indexId = uuidv42(), summary = void 0) {
    this.indexId = indexId;
    this.summary = summary;
  }
  toJson() {
    return {
      indexId: this.indexId,
      summary: this.summary
    };
  }
  getSummary() {
    if (this.summary === void 0) {
      throw new Error("summary field of the index dict is not set");
    }
    return this.summary;
  }
};
var IndexStructType = /* @__PURE__ */ ((IndexStructType2) => {
  IndexStructType2["SIMPLE_DICT"] = "simple_dict";
  IndexStructType2["LIST"] = "list";
  IndexStructType2["KEYWORD_TABLE"] = "keyword_table";
  return IndexStructType2;
})(IndexStructType || {});
var IndexDict = class extends IndexStruct {
  constructor() {
    super(...arguments);
    this.nodesDict = {};
    this.type = "simple_dict" /* SIMPLE_DICT */;
  }
  getSummary() {
    if (this.summary === void 0) {
      throw new Error("summary field of the index dict is not set");
    }
    return this.summary;
  }
  addNode(node, textId) {
    const vectorId = textId != null ? textId : node.id_;
    this.nodesDict[vectorId] = node;
  }
  toJson() {
    return __spreadProps(__spreadValues({}, super.toJson()), {
      nodesDict: this.nodesDict,
      type: this.type
    });
  }
  delete(nodeId) {
    delete this.nodesDict[nodeId];
  }
};
function jsonToIndexStruct(json) {
  if (json.type === "list" /* LIST */) {
    const indexList = new IndexList(json.indexId, json.summary);
    indexList.nodes = json.nodes;
    return indexList;
  } else if (json.type === "simple_dict" /* SIMPLE_DICT */) {
    const indexDict = new IndexDict(json.indexId, json.summary);
    indexDict.nodesDict = Object.entries(json.nodesDict).reduce((acc, [key, value]) => {
      acc[key] = jsonToNode(value);
      return acc;
    }, {});
    return indexDict;
  } else {
    throw new Error(`Unknown index struct type: ${json.type}`);
  }
}
var IndexList = class extends IndexStruct {
  constructor() {
    super(...arguments);
    this.nodes = [];
    this.type = "list" /* LIST */;
  }
  addNode(node) {
    this.nodes.push(node.id_);
  }
  toJson() {
    return __spreadProps(__spreadValues({}, super.toJson()), {
      nodes: this.nodes,
      type: this.type
    });
  }
};
var KeywordTable = class extends IndexStruct {
  constructor() {
    super(...arguments);
    this.table = /* @__PURE__ */ new Map();
    this.type = "keyword_table" /* KEYWORD_TABLE */;
  }
  addNode(keywords, nodeId) {
    keywords.forEach((keyword) => {
      if (!this.table.has(keyword)) {
        this.table.set(keyword, /* @__PURE__ */ new Set());
      }
      this.table.get(keyword).add(nodeId);
    });
  }
  deleteNode(keywords, nodeId) {
    keywords.forEach((keyword) => {
      if (this.table.has(keyword)) {
        this.table.get(keyword).delete(nodeId);
      }
    });
  }
  toJson() {
    return __spreadProps(__spreadValues({}, super.toJson()), {
      table: this.table,
      type: this.type
    });
  }
};
var BaseIndex = class {
  constructor(init) {
    this.serviceContext = init.serviceContext;
    this.storageContext = init.storageContext;
    this.docStore = init.docStore;
    this.vectorStore = init.vectorStore;
    this.indexStore = init.indexStore;
    this.indexStruct = init.indexStruct;
  }
  /**
   * Insert a document into the index.
   * @param document
   */
  insert(document) {
    return __async(this, null, function* () {
      const nodes = this.serviceContext.nodeParser.getNodesFromDocuments([
        document
      ]);
      yield this.insertNodes(nodes);
      this.docStore.setDocumentHash(document.id_, document.hash);
    });
  }
};

// src/storage/indexStore/types.ts
var defaultPersistPath2 = `${DEFAULT_PERSIST_DIR}/${DEFAULT_INDEX_STORE_PERSIST_FILENAME}`;
var BaseIndexStore = class {
  persist() {
    return __async(this, arguments, function* (persistPath = defaultPersistPath2, fs2) {
    });
  }
};

// src/storage/indexStore/KVIndexStore.ts
var KVIndexStore = class extends BaseIndexStore {
  constructor(kvStore, namespace = DEFAULT_NAMESPACE) {
    super();
    this._kvStore = kvStore;
    this._collection = `${namespace}/data`;
  }
  addIndexStruct(indexStruct) {
    return __async(this, null, function* () {
      let key = indexStruct.indexId;
      let data = indexStruct.toJson();
      yield this._kvStore.put(key, data, this._collection);
    });
  }
  deleteIndexStruct(key) {
    return __async(this, null, function* () {
      yield this._kvStore.delete(key, this._collection);
    });
  }
  getIndexStruct(structId) {
    return __async(this, null, function* () {
      if (_5.isNil(structId)) {
        let structs = yield this.getIndexStructs();
        if (structs.length !== 1) {
          throw new Error("More than one index struct found");
        }
        return structs[0];
      } else {
        let json = yield this._kvStore.get(structId, this._collection);
        if (_5.isNil(json)) {
          return;
        }
        return jsonToIndexStruct(json);
      }
    });
  }
  getIndexStructs() {
    return __async(this, null, function* () {
      let jsons = yield this._kvStore.getAll(this._collection);
      return _5.values(jsons).map((json) => jsonToIndexStruct(json));
    });
  }
};

// src/storage/indexStore/SimpleIndexStore.ts
var SimpleIndexStore = class _SimpleIndexStore extends KVIndexStore {
  constructor(kvStore) {
    kvStore = kvStore || new SimpleKVStore();
    super(kvStore);
    this.kvStore = kvStore;
  }
  static fromPersistDir() {
    return __async(this, arguments, function* (persistDir = DEFAULT_PERSIST_DIR, fs2 = DEFAULT_FS) {
      const persistPath = path4.join(
        persistDir,
        DEFAULT_INDEX_STORE_PERSIST_FILENAME
      );
      return this.fromPersistPath(persistPath, fs2);
    });
  }
  static fromPersistPath(_0) {
    return __async(this, arguments, function* (persistPath, fs2 = DEFAULT_FS) {
      let simpleKVStore = yield SimpleKVStore.fromPersistPath(persistPath, fs2);
      return new _SimpleIndexStore(simpleKVStore);
    });
  }
  persist() {
    return __async(this, arguments, function* (persistPath = DEFAULT_PERSIST_DIR, fs2 = DEFAULT_FS) {
      yield this.kvStore.persist(persistPath, fs2);
    });
  }
  static fromDict(saveDict) {
    let simpleKVStore = SimpleKVStore.fromDict(saveDict);
    return new _SimpleIndexStore(simpleKVStore);
  }
  toDict() {
    if (!(this.kvStore instanceof SimpleKVStore)) {
      throw new Error("KVStore is not a SimpleKVStore");
    }
    return this.kvStore.toDict();
  }
};

// src/storage/vectorStore/SimpleVectorStore.ts
import _6 from "lodash";
import * as path5 from "path";

// src/storage/vectorStore/types.ts
var VectorStoreQueryMode = /* @__PURE__ */ ((VectorStoreQueryMode2) => {
  VectorStoreQueryMode2["DEFAULT"] = "default";
  VectorStoreQueryMode2["SPARSE"] = "sparse";
  VectorStoreQueryMode2["HYBRID"] = "hybrid";
  VectorStoreQueryMode2["SVM"] = "svm";
  VectorStoreQueryMode2["LOGISTIC_REGRESSION"] = "logistic_regression";
  VectorStoreQueryMode2["LINEAR_REGRESSION"] = "linear_regression";
  VectorStoreQueryMode2["MMR"] = "mmr";
  return VectorStoreQueryMode2;
})(VectorStoreQueryMode || {});

// src/storage/vectorStore/SimpleVectorStore.ts
var LEARNER_MODES = /* @__PURE__ */ new Set([
  "svm" /* SVM */,
  "linear_regression" /* LINEAR_REGRESSION */,
  "logistic_regression" /* LOGISTIC_REGRESSION */
]);
var MMR_MODE = "mmr" /* MMR */;
var SimpleVectorStoreData = class {
  constructor() {
    this.embeddingDict = {};
    this.textIdToRefDocId = {};
  }
};
var SimpleVectorStore = class _SimpleVectorStore {
  constructor(data, fs2) {
    this.storesText = false;
    this.data = new SimpleVectorStoreData();
    this.fs = DEFAULT_FS;
    this.data = data || new SimpleVectorStoreData();
    this.fs = fs2 || DEFAULT_FS;
  }
  static fromPersistDir() {
    return __async(this, arguments, function* (persistDir = DEFAULT_PERSIST_DIR, fs2 = DEFAULT_FS) {
      let persistPath = `${persistDir}/vector_store.json`;
      return yield _SimpleVectorStore.fromPersistPath(persistPath, fs2);
    });
  }
  get client() {
    return null;
  }
  get(textId) {
    return __async(this, null, function* () {
      return this.data.embeddingDict[textId];
    });
  }
  add(embeddingResults) {
    return __async(this, null, function* () {
      var _a;
      for (let node of embeddingResults) {
        this.data.embeddingDict[node.id_] = node.getEmbedding();
        if (!node.sourceNode) {
          console.error("Missing source node from TextNode.");
          continue;
        }
        this.data.textIdToRefDocId[node.id_] = (_a = node.sourceNode) == null ? void 0 : _a.nodeId;
      }
      if (this.persistPath) {
        yield this.persist(this.persistPath, this.fs);
      }
      return embeddingResults.map((result) => result.id_);
    });
  }
  delete(refDocId) {
    return __async(this, null, function* () {
      let textIdsToDelete = Object.keys(this.data.textIdToRefDocId).filter(
        (textId) => this.data.textIdToRefDocId[textId] === refDocId
      );
      for (let textId of textIdsToDelete) {
        delete this.data.embeddingDict[textId];
        delete this.data.textIdToRefDocId[textId];
      }
      return Promise.resolve();
    });
  }
  query(query) {
    return __async(this, null, function* () {
      if (!_6.isNil(query.filters)) {
        throw new Error(
          "Metadata filters not implemented for SimpleVectorStore yet."
        );
      }
      let items = Object.entries(this.data.embeddingDict);
      let nodeIds, embeddings;
      if (query.docIds) {
        let availableIds = new Set(query.docIds);
        const queriedItems = items.filter((item) => availableIds.has(item[0]));
        nodeIds = queriedItems.map((item) => item[0]);
        embeddings = queriedItems.map((item) => item[1]);
      } else {
        nodeIds = items.map((item) => item[0]);
        embeddings = items.map((item) => item[1]);
      }
      let queryEmbedding = query.queryEmbedding;
      let topSimilarities, topIds;
      if (LEARNER_MODES.has(query.mode)) {
        [topSimilarities, topIds] = getTopKEmbeddingsLearner(
          queryEmbedding,
          embeddings,
          query.similarityTopK,
          nodeIds
        );
      } else if (query.mode === MMR_MODE) {
        let mmrThreshold = query.mmrThreshold;
        [topSimilarities, topIds] = getTopKMMREmbeddings(
          queryEmbedding,
          embeddings,
          null,
          query.similarityTopK,
          nodeIds,
          mmrThreshold
        );
      } else if (query.mode === "default" /* DEFAULT */) {
        [topSimilarities, topIds] = getTopKEmbeddings(
          queryEmbedding,
          embeddings,
          query.similarityTopK,
          nodeIds
        );
      } else {
        throw new Error(`Invalid query mode: ${query.mode}`);
      }
      return Promise.resolve({
        similarities: topSimilarities,
        ids: topIds
      });
    });
  }
  persist() {
    return __async(this, arguments, function* (persistPath = `${DEFAULT_PERSIST_DIR}/vector_store.json`, fs2) {
      fs2 = fs2 || this.fs;
      let dirPath = path5.dirname(persistPath);
      if (!(yield exists(fs2, dirPath))) {
        yield fs2.mkdir(dirPath);
      }
      yield fs2.writeFile(persistPath, JSON.stringify(this.data));
    });
  }
  static fromPersistPath(persistPath, fs2) {
    return __async(this, null, function* () {
      var _a, _b;
      fs2 = fs2 || DEFAULT_FS;
      let dirPath = path5.dirname(persistPath);
      if (!(yield exists(fs2, dirPath))) {
        yield fs2.mkdir(dirPath, { recursive: true });
      }
      let dataDict = {};
      try {
        let fileData = yield fs2.readFile(persistPath);
        dataDict = JSON.parse(fileData.toString());
      } catch (e) {
        console.error(
          `No valid data found at path: ${persistPath} starting new store.`
        );
      }
      let data = new SimpleVectorStoreData();
      data.embeddingDict = (_a = dataDict.embeddingDict) != null ? _a : {};
      data.textIdToRefDocId = (_b = dataDict.textIdToRefDocId) != null ? _b : {};
      const store = new _SimpleVectorStore(data);
      store.persistPath = persistPath;
      store.fs = fs2;
      return store;
    });
  }
  static fromDict(saveDict) {
    let data = new SimpleVectorStoreData();
    data.embeddingDict = saveDict.embeddingDict;
    data.textIdToRefDocId = saveDict.textIdToRefDocId;
    return new _SimpleVectorStore(data);
  }
  toDict() {
    return {
      embeddingDict: this.data.embeddingDict,
      textIdToRefDocId: this.data.textIdToRefDocId
    };
  }
};

// src/storage/StorageContext.ts
function storageContextFromDefaults(_0) {
  return __async(this, arguments, function* ({
    docStore,
    indexStore,
    vectorStore,
    imageVectorStore,
    storeImages,
    persistDir,
    fs: fs2
  }) {
    if (!persistDir) {
      docStore = docStore || new SimpleDocumentStore();
      indexStore = indexStore || new SimpleIndexStore();
      vectorStore = vectorStore || new SimpleVectorStore();
      imageVectorStore = storeImages ? new SimpleVectorStore() : imageVectorStore;
    } else {
      fs2 = fs2 || DEFAULT_FS;
      docStore = docStore || (yield SimpleDocumentStore.fromPersistDir(
        persistDir,
        DEFAULT_NAMESPACE,
        fs2
      ));
      indexStore = indexStore || (yield SimpleIndexStore.fromPersistDir(persistDir, fs2));
      vectorStore = vectorStore || (yield SimpleVectorStore.fromPersistDir(persistDir, fs2));
      imageVectorStore = storeImages ? yield SimpleVectorStore.fromPersistDir(
        path6.join(persistDir, DEFAULT_IMAGE_VECTOR_NAMESPACE),
        fs2
      ) : imageVectorStore;
    }
    return {
      docStore,
      indexStore,
      vectorStore,
      imageVectorStore
    };
  });
}

// src/storage/vectorStore/AstraDBVectorStore.ts
import { AstraDB } from "@datastax/astra-db-ts";
var MAX_INSERT_BATCH_SIZE = 20;
var AstraDBVectorStore = class {
  constructor(init) {
    this.storesText = true;
    this.flatMetadata = true;
    var _a, _b, _c, _d, _e, _f;
    if (init == null ? void 0 : init.astraDBClient) {
      this.astraDBClient = init.astraDBClient;
    } else {
      const token = (_b = (_a = init == null ? void 0 : init.params) == null ? void 0 : _a.token) != null ? _b : process.env.ASTRA_DB_APPLICATION_TOKEN;
      const endpoint = (_d = (_c = init == null ? void 0 : init.params) == null ? void 0 : _c.endpoint) != null ? _d : process.env.ASTRA_DB_ENDPOINT;
      if (!token) {
        throw new Error(
          "Must specify ASTRA_DB_APPLICATION_TOKEN via env variable."
        );
      }
      if (!endpoint) {
        throw new Error("Must specify ASTRA_DB_ENDPOINT via env variable.");
      }
      this.astraDBClient = new AstraDB(token, endpoint);
    }
    this.idKey = (_e = init == null ? void 0 : init.idKey) != null ? _e : "_id";
    this.contentKey = init == null ? void 0 : init.contentKey;
    this.metadataKey = (_f = init == null ? void 0 : init.metadataKey) != null ? _f : "metadata";
  }
  /**
   * Create a new collection in your Astra DB vector database.
   * You must still use connect() to connect to the collection.
   *
   * @param collection your new colletion's name
   * @param options: CreateCollectionOptions used to set the number of vector dimensions and similarity metric
   * @returns Promise that resolves if the creation did not throw an error.
   */
  create(collection, options) {
    return __async(this, null, function* () {
      yield this.astraDBClient.createCollection(collection, options);
      console.debug("Created Astra DB collection");
      return;
    });
  }
  /**
   * Connect to an existing collection in your Astra DB vector database.
   * You must call this before adding, deleting, or querying.
   *
   * @param collection your existing colletion's name
   * @returns Promise that resolves if the connection did not throw an error.
   */
  connect(collection) {
    return __async(this, null, function* () {
      this.collection = yield this.astraDBClient.collection(collection);
      console.debug("Connected to Astra DB collection");
      return;
    });
  }
  /**
   * Get an instance of your Astra DB client.
   * @returns the AstraDB client
   */
  client() {
    return this.astraDBClient;
  }
  /**
   * Add your document(s) to your Astra DB collection.
   *
   * @returns and array of node ids which were added
   */
  add(nodes) {
    return __async(this, null, function* () {
      if (!this.collection) {
        throw new Error("Must connect to collection before adding.");
      }
      const collection = this.collection;
      if (!nodes || nodes.length === 0) {
        return [];
      }
      const dataToInsert = nodes.map((node) => {
        return {
          _id: node.id_,
          $vector: node.getEmbedding(),
          content: node.getContent("ALL" /* ALL */),
          metadata: node.metadata
        };
      });
      console.debug(`Adding ${dataToInsert.length} rows to table`);
      let batchData = [];
      for (let i = 0; i < dataToInsert.length; i += MAX_INSERT_BATCH_SIZE) {
        batchData.push(dataToInsert.slice(i, i + MAX_INSERT_BATCH_SIZE));
      }
      for (const batch of batchData) {
        console.debug(`Inserting batch of size ${batch.length}`);
        const result = yield collection.insertMany(batch);
      }
      return dataToInsert.map((node) => node._id);
    });
  }
  /**
   * Delete a document from your Astra DB collection.
   *
   * @param refDocId the id of the document to delete
   * @param deleteOptions: any DeleteOneOptions to pass to the delete query
   * @returns Promise that resolves if the delete query did not throw an error.
   */
  delete(refDocId, deleteOptions) {
    return __async(this, null, function* () {
      if (!this.collection) {
        throw new Error("Must connect to collection before deleting.");
      }
      const collection = this.collection;
      console.debug(`Deleting row with id ${refDocId}`);
      yield collection.deleteOne(
        {
          _id: refDocId
        },
        deleteOptions
      );
    });
  }
  /**
   * Query documents from your Astra DB collection to get the closest match to your embedding.
   *
   * @param query: VectorStoreQuery
   * @param options: Not used
   */
  query(query, options) {
    return __async(this, null, function* () {
      var _a, _b;
      if (!this.collection) {
        throw new Error("Must connect to collection before querying.");
      }
      const collection = this.collection;
      const filters = {};
      (_b = (_a = query.filters) == null ? void 0 : _a.filters) == null ? void 0 : _b.forEach((f) => {
        filters[f.key] = f.value;
      });
      const cursor = yield collection.find(filters, {
        sort: query.queryEmbedding ? { $vector: query.queryEmbedding } : void 0,
        limit: query.similarityTopK,
        includeSimilarity: true
      });
      const nodes = [];
      const ids = [];
      const similarities = [];
      yield cursor.forEach((row) => __async(this, null, function* () {
        const id = row[this.idKey];
        const embedding = row.$vector;
        const similarity2 = row.$similarity;
        const metadata = row[this.metadataKey];
        delete row[this.idKey];
        delete row.$similarity;
        delete row.$vector;
        delete row[this.metadataKey];
        const content = this.contentKey ? row[this.contentKey] : JSON.stringify(row);
        const node = new Document({
          id_: id,
          text: content,
          metadata: metadata != null ? metadata : {},
          embedding
        });
        ids.push(id);
        similarities.push(similarity2);
        nodes.push(node);
      }));
      return {
        similarities,
        ids,
        nodes
      };
    });
  }
};

// src/storage/vectorStore/MongoDBAtlasVectorStore.ts
import { MongoClient } from "mongodb";

// src/storage/vectorStore/utils.ts
var DEFAULT_TEXT_KEY = "text";
function validateIsFlat(obj) {
  for (let key in obj) {
    if (typeof obj[key] === "object" && obj[key] !== null) {
      throw new Error(`Value for metadata ${key} must not be another object`);
    }
  }
}
function nodeToMetadata(node, removeText = false, textField = DEFAULT_TEXT_KEY, flatMetadata = false) {
  var _a, _b, _c;
  const nodeObj = node.toJSON();
  const metadata = node.metadata;
  if (flatMetadata) {
    validateIsFlat(node.metadata);
  }
  if (removeText) {
    nodeObj[textField] = "";
  }
  nodeObj["embedding"] = null;
  metadata["_node_content"] = JSON.stringify(nodeObj);
  metadata["_node_type"] = node.constructor.name.replace("_", "");
  metadata["document_id"] = ((_a = node.sourceNode) == null ? void 0 : _a.nodeId) || "None";
  metadata["doc_id"] = ((_b = node.sourceNode) == null ? void 0 : _b.nodeId) || "None";
  metadata["ref_doc_id"] = ((_c = node.sourceNode) == null ? void 0 : _c.nodeId) || "None";
  return metadata;
}
function metadataDictToNode(metadata) {
  const nodeContent = metadata["_node_content"];
  if (!nodeContent) {
    throw new Error("Node content not found in metadata.");
  }
  const nodeObj = JSON.parse(nodeContent);
  const node_type = metadata["_node_type"];
  switch (node_type) {
    case "IndexNode":
      return jsonToNode(nodeObj, "INDEX" /* INDEX */);
    default:
      return jsonToNode(nodeObj, "TEXT" /* TEXT */);
  }
}

// src/storage/vectorStore/MongoDBAtlasVectorStore.ts
function toMongoDBFilter(standardFilters) {
  const filters = {};
  for (const filter of standardFilters.filters) {
    filters[filter.key] = filter.value;
  }
  return filters;
}
var MongoDBAtlasVectorSearch = class {
  constructor(init) {
    this.storesText = true;
    this.flatMetadata = true;
    var _a, _b, _c, _d, _e, _f, _g;
    if (init.mongodbClient) {
      this.mongodbClient = init.mongodbClient;
    } else {
      const mongoUri = process.env.MONGODB_URI;
      if (!mongoUri) {
        throw new Error(
          "Must specify MONGODB_URI via env variable if not directly passing in client."
        );
      }
      this.mongodbClient = new MongoClient(mongoUri);
    }
    this.collection = this.mongodbClient.db((_a = init.dbName) != null ? _a : "default_db").collection((_b = init.collectionName) != null ? _b : "default_collection");
    this.indexName = (_c = init.indexName) != null ? _c : "default";
    this.embeddingKey = (_d = init.embeddingKey) != null ? _d : "embedding";
    this.idKey = (_e = init.idKey) != null ? _e : "id";
    this.textKey = (_f = init.textKey) != null ? _f : "text";
    this.metadataKey = (_g = init.metadataKey) != null ? _g : "metadata";
    this.insertOptions = init.insertOptions;
  }
  add(nodes) {
    return __async(this, null, function* () {
      if (!nodes || nodes.length === 0) {
        return [];
      }
      const dataToInsert = nodes.map((node) => {
        const metadata = nodeToMetadata(
          node,
          true,
          this.textKey,
          this.flatMetadata
        );
        return {
          [this.idKey]: node.id_,
          [this.embeddingKey]: node.getEmbedding(),
          [this.textKey]: node.getContent("NONE" /* NONE */) || "",
          [this.metadataKey]: metadata
        };
      });
      console.debug("Inserting data into MongoDB: ", dataToInsert);
      const insertResult = yield this.collection.insertMany(
        dataToInsert,
        this.insertOptions
      );
      console.debug("Result of insert: ", insertResult);
      return nodes.map((node) => node.id_);
    });
  }
  delete(refDocId, deleteOptions) {
    return __async(this, null, function* () {
      yield this.collection.deleteOne(
        {
          [`${this.metadataKey}.ref_doc_id`]: refDocId
        },
        deleteOptions
      );
    });
  }
  get client() {
    return this.mongodbClient;
  }
  query(query, options) {
    return __async(this, null, function* () {
      const params = {
        queryVector: query.queryEmbedding,
        path: this.embeddingKey,
        numCandidates: query.similarityTopK * 10,
        limit: query.similarityTopK,
        index: this.indexName
      };
      if (query.filters) {
        params.filter = toMongoDBFilter(query.filters);
      }
      const queryField = { $vectorSearch: params };
      const pipeline = [
        queryField,
        {
          $project: {
            score: { $meta: "vectorSearchScore" },
            [this.embeddingKey]: 0
          }
        }
      ];
      console.debug("Running query pipeline: ", pipeline);
      const cursor = yield this.collection.aggregate(pipeline);
      const nodes = [];
      const ids = [];
      const similarities = [];
      try {
        for (var iter = __forAwait(yield cursor), more, temp, error; more = !(temp = yield iter.next()).done; more = false) {
          const res = temp.value;
          const text = res[this.textKey];
          const score = res.score;
          const id = res[this.idKey];
          const metadata = res[this.metadataKey];
          const node = metadataDictToNode(metadata);
          node.setContent(text);
          ids.push(id);
          nodes.push(node);
          similarities.push(score);
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield temp.call(iter));
        } finally {
          if (error)
            throw error[0];
        }
      }
      const result = {
        nodes,
        similarities,
        ids
      };
      console.debug("Result of query (ids):", ids);
      return result;
    });
  }
};

// src/storage/vectorStore/PGVectorStore.ts
import pg from "pg";
import pgvector from "pgvector/pg";
var PGVECTOR_SCHEMA = "public";
var PGVECTOR_TABLE = "llamaindex_embedding";
var PGVectorStore = class {
  constructor() {
    this.storesText = true;
    this.collection = "";
  }
  /**
   * Setter for the collection property.
   * Using a collection allows for simple segregation of vector data,
   * e.g. by user, source, or access-level.
   * Leave/set blank to ignore the collection value when querying.
   * @param coll Name for the collection.
   */
  setCollection(coll) {
    this.collection = coll;
  }
  /**
   * Getter for the collection property.
   * Using a collection allows for simple segregation of vector data,
   * e.g. by user, source, or access-level.
   * Leave/set blank to ignore the collection value when querying.
   * @returns The currently-set collection value.  Default is empty string.
   */
  getCollection() {
    return this.collection;
  }
  getDb() {
    return __async(this, null, function* () {
      if (!this.db) {
        try {
          const db = new pg.Client();
          yield db.connect();
          db.query("CREATE EXTENSION IF NOT EXISTS vector");
          yield pgvector.registerType(db);
          yield this.checkSchema(db);
          this.db = db;
        } catch (err) {
          console.error(err);
          return Promise.reject(err);
        }
      }
      return Promise.resolve(this.db);
    });
  }
  checkSchema(db) {
    return __async(this, null, function* () {
      yield db.query(`CREATE SCHEMA IF NOT EXISTS ${PGVECTOR_SCHEMA}`);
      const tbl = `CREATE TABLE IF NOT EXISTS ${PGVECTOR_SCHEMA}.${PGVECTOR_TABLE}(
      id uuid DEFAULT gen_random_uuid() PRIMARY KEY,
      external_id VARCHAR,
      collection VARCHAR,
      document TEXT,
      metadata JSONB DEFAULT '{}',
      embeddings VECTOR(1536)
    )`;
      yield db.query(tbl);
      const idxs = `CREATE INDEX IF NOT EXISTS idx_${PGVECTOR_TABLE}_external_id ON ${PGVECTOR_SCHEMA}.${PGVECTOR_TABLE} (external_id);
      CREATE INDEX IF NOT EXISTS idx_${PGVECTOR_TABLE}_collection ON ${PGVECTOR_SCHEMA}.${PGVECTOR_TABLE} (collection);`;
      yield db.query(idxs);
      return db;
    });
  }
  // isEmbeddingQuery?: boolean | undefined;
  /**
   * Connects to the database specified in environment vars.
   * This method also checks and creates the vector extension,
   * the destination table and indexes if not found.
   * @returns A connection to the database, or the error encountered while connecting/setting up.
   */
  client() {
    return this.getDb();
  }
  /**
   * Delete all vector records for the specified collection.
   * NOTE: Uses the collection property controlled by setCollection/getCollection.
   * @returns The result of the delete query.
   */
  clearCollection() {
    return __async(this, null, function* () {
      const sql = `DELETE FROM ${PGVECTOR_SCHEMA}.${PGVECTOR_TABLE} 
      WHERE collection = $1`;
      const db = yield this.getDb();
      const ret = yield db.query(sql, [this.collection]);
      return ret;
    });
  }
  /**
   * Adds vector record(s) to the table.
   * NOTE: Uses the collection property controlled by setCollection/getCollection.
   * @param embeddingResults The Nodes to be inserted, optionally including metadata tuples.
   * @returns A list of zero or more id values for the created records.
   */
  add(embeddingResults) {
    return __async(this, null, function* () {
      if (embeddingResults.length == 0) {
        console.debug("Empty list sent to PGVectorStore::add");
        return Promise.resolve([]);
      }
      const sql = `INSERT INTO ${PGVECTOR_SCHEMA}.${PGVECTOR_TABLE} 
      (id, external_id, collection, document, metadata, embeddings) 
      VALUES ($1, $2, $3, $4, $5, $6)`;
      const db = yield this.getDb();
      let ret = [];
      for (let index = 0; index < embeddingResults.length; index++) {
        const row = embeddingResults[index];
        let id = row.id_.length ? row.id_ : null;
        let meta = row.metadata || {};
        meta.create_date = /* @__PURE__ */ new Date();
        const params = [
          id,
          "",
          this.collection,
          row.getContent("EMBED" /* EMBED */),
          meta,
          "[" + row.getEmbedding().join(",") + "]"
        ];
        try {
          const result = yield db.query(sql, params);
          if (result.rows.length) {
            id = result.rows[0].id;
            ret.push(id);
          }
        } catch (err) {
          const msg = `${err}`;
          console.log(msg, err);
        }
      }
      return Promise.resolve(ret);
    });
  }
  /**
   * Deletes a single record from the database by id.
   * NOTE: Uses the collection property controlled by setCollection/getCollection.
   * @param refDocId Unique identifier for the record to delete.
   * @param deleteKwargs Required by VectorStore interface.  Currently ignored.
   * @returns Promise that resolves if the delete query did not throw an error.
   */
  delete(refDocId, deleteKwargs) {
    return __async(this, null, function* () {
      const collectionCriteria = this.collection.length ? "AND collection = $2" : "";
      const sql = `DELETE FROM ${PGVECTOR_SCHEMA}.${PGVECTOR_TABLE} 
      WHERE id = $1 ${collectionCriteria}`;
      const db = yield this.getDb();
      const params = this.collection.length ? [refDocId, this.collection] : [refDocId];
      yield db.query(sql, params);
      return Promise.resolve();
    });
  }
  /**
   * Query the vector store for the closest matching data to the query embeddings
   * @param query The VectorStoreQuery to be used
   * @param options Required by VectorStore interface.  Currently ignored.
   * @returns Zero or more Document instances with data from the vector store.
   */
  query(query, options) {
    return __async(this, null, function* () {
      var _a, _b;
      const embedding = "[" + ((_a = query.queryEmbedding) == null ? void 0 : _a.join(",")) + "]";
      const max = (_b = query.similarityTopK) != null ? _b : 2;
      const where = this.collection.length ? "WHERE collection = $2" : "";
      const sql = `SELECT 
        v.*, 
        embeddings <-> $1 s 
      FROM ${PGVECTOR_SCHEMA}.${PGVECTOR_TABLE} v
      ${where}
      ORDER BY s 
      LIMIT ${max}
    `;
      const db = yield this.getDb();
      const params = this.collection.length ? [embedding, this.collection] : [embedding];
      const results = yield db.query(sql, params);
      const nodes = results.rows.map((row) => {
        return new Document({
          id_: row.id,
          text: row.document,
          metadata: row.metadata,
          embedding: row.embeddings
        });
      });
      const ret = {
        nodes,
        similarities: results.rows.map((row) => row.s),
        ids: results.rows.map((row) => row.id)
      };
      return Promise.resolve(ret);
    });
  }
  /**
   * Required by VectorStore interface.  Currently ignored.
   * @param persistPath
   * @param fs
   * @returns Resolved Promise.
   */
  persist(persistPath, fs2) {
    return Promise.resolve();
  }
};

// src/embeddings/utils.ts
function similarity(embedding1, embedding2, mode = "cosine" /* DEFAULT */) {
  if (embedding1.length !== embedding2.length) {
    throw new Error("Embedding length mismatch");
  }
  function norm(x) {
    let result = 0;
    for (let i = 0; i < x.length; i++) {
      result += x[i] * x[i];
    }
    return Math.sqrt(result);
  }
  switch (mode) {
    case "euclidean" /* EUCLIDEAN */: {
      let difference = embedding1.map((x, i) => x - embedding2[i]);
      return -norm(difference);
    }
    case "dot_product" /* DOT_PRODUCT */: {
      let result = 0;
      for (let i = 0; i < embedding1.length; i++) {
        result += embedding1[i] * embedding2[i];
      }
      return result;
    }
    case "cosine" /* DEFAULT */: {
      return similarity(embedding1, embedding2, "dot_product" /* DOT_PRODUCT */) / (norm(embedding1) * norm(embedding2));
    }
    default:
      throw new Error("Not implemented yet");
  }
}
function getTopKEmbeddings(queryEmbedding, embeddings, similarityTopK = DEFAULT_SIMILARITY_TOP_K, embeddingIds = null, similarityCutoff = null) {
  if (embeddingIds == null) {
    embeddingIds = Array(embeddings.length).map((_15, i) => i);
  }
  if (embeddingIds.length !== embeddings.length) {
    throw new Error(
      "getTopKEmbeddings: embeddings and embeddingIds length mismatch"
    );
  }
  let similarities = [];
  for (let i = 0; i < embeddings.length; i++) {
    const sim = similarity(queryEmbedding, embeddings[i]);
    if (similarityCutoff == null || sim > similarityCutoff) {
      similarities.push({ similarity: sim, id: embeddingIds[i] });
    }
  }
  similarities.sort((a, b) => b.similarity - a.similarity);
  let resultSimilarities = [];
  let resultIds = [];
  for (let i = 0; i < similarityTopK; i++) {
    if (i >= similarities.length) {
      break;
    }
    resultSimilarities.push(similarities[i].similarity);
    resultIds.push(similarities[i].id);
  }
  return [resultSimilarities, resultIds];
}
function getTopKEmbeddingsLearner(queryEmbedding, embeddings, similarityTopK, embeddingsIds, queryMode = "svm" /* SVM */) {
  throw new Error("Not implemented yet");
}
function getTopKMMREmbeddings(queryEmbedding, embeddings, similarityFn = null, similarityTopK = null, embeddingIds = null, _similarityCutoff = null, mmrThreshold = null) {
  let threshold = mmrThreshold || 0.5;
  similarityFn = similarityFn || similarity;
  if (embeddingIds === null || embeddingIds.length === 0) {
    embeddingIds = Array.from({ length: embeddings.length }, (_15, i) => i);
  }
  let fullEmbedMap = new Map(embeddingIds.map((value, i) => [value, i]));
  let embedMap = new Map(fullEmbedMap);
  let embedSimilarity = /* @__PURE__ */ new Map();
  let score = Number.NEGATIVE_INFINITY;
  let highScoreId = null;
  for (let i = 0; i < embeddings.length; i++) {
    let emb = embeddings[i];
    let similarity2 = similarityFn(queryEmbedding, emb);
    embedSimilarity.set(embeddingIds[i], similarity2);
    if (similarity2 * threshold > score) {
      highScoreId = embeddingIds[i];
      score = similarity2 * threshold;
    }
  }
  let results = [];
  let embeddingLength = embeddings.length;
  let similarityTopKCount = similarityTopK || embeddingLength;
  while (results.length < Math.min(similarityTopKCount, embeddingLength)) {
    results.push([score, highScoreId]);
    embedMap.delete(highScoreId);
    let recentEmbeddingId = highScoreId;
    score = Number.NEGATIVE_INFINITY;
    for (let embedId of Array.from(embedMap.keys())) {
      let overlapWithRecent = similarityFn(
        embeddings[embedMap.get(embedId)],
        embeddings[fullEmbedMap.get(recentEmbeddingId)]
      );
      if (threshold * embedSimilarity.get(embedId) - (1 - threshold) * overlapWithRecent > score) {
        score = threshold * embedSimilarity.get(embedId) - (1 - threshold) * overlapWithRecent;
        highScoreId = embedId;
      }
    }
  }
  let resultSimilarities = results.map(([s, _15]) => s);
  let resultIds = results.map(([_15, n]) => n);
  return [resultSimilarities, resultIds];
}
function blobToDataUrl(input) {
  return __async(this, null, function* () {
    const { fileTypeFromBuffer } = yield import("file-type");
    const buffer = Buffer.from(yield input.arrayBuffer());
    const type = yield fileTypeFromBuffer(buffer);
    if (!type) {
      throw new Error("Unsupported image type");
    }
    return "data:" + type.mime + ";base64," + buffer.toString("base64");
  });
}
function readImage(input) {
  return __async(this, null, function* () {
    const { RawImage } = yield import("@xenova/transformers");
    if (input instanceof Blob) {
      return yield RawImage.fromBlob(input);
    } else if (_7.isString(input) || input instanceof URL) {
      return yield RawImage.fromURL(input);
    } else {
      throw new Error(`Unsupported input type: ${typeof input}`);
    }
  });
}
function imageToString(input) {
  return __async(this, null, function* () {
    if (input instanceof Blob) {
      return yield blobToDataUrl(input);
    } else if (_7.isString(input)) {
      return input;
    } else if (input instanceof URL) {
      return input.toString();
    } else {
      throw new Error(`Unsupported input type: ${typeof input}`);
    }
  });
}
function stringToImage(input) {
  if (input.startsWith("data:")) {
    const base64Data = input.split(",")[1];
    const byteArray = Buffer.from(base64Data, "base64");
    return new Blob([byteArray]);
  } else if (input.startsWith("http://") || input.startsWith("https://")) {
    return new URL(input);
  } else if (_7.isString(input)) {
    return input;
  } else {
    throw new Error(`Unsupported input type: ${typeof input}`);
  }
}
function imageToDataUrl(input) {
  return __async(this, null, function* () {
    if (input instanceof URL && input.protocol === "file:" || _7.isString(input)) {
      const fs2 = DEFAULT_FS;
      const dataBuffer = yield fs2.readFile(
        input instanceof URL ? input.pathname : input
      );
      input = new Blob([dataBuffer]);
    } else if (!(input instanceof Blob)) {
      if (input instanceof URL) {
        throw new Error(`Unsupported URL with protocol: ${input.protocol}`);
      } else {
        throw new Error(`Unsupported input type: ${typeof input}`);
      }
    }
    return yield blobToDataUrl(input);
  });
}

// src/embeddings/types.ts
var SimilarityType = /* @__PURE__ */ ((SimilarityType2) => {
  SimilarityType2["DEFAULT"] = "cosine";
  SimilarityType2["DOT_PRODUCT"] = "dot_product";
  SimilarityType2["EUCLIDEAN"] = "euclidean";
  return SimilarityType2;
})(SimilarityType || {});
var BaseEmbedding = class {
  similarity(embedding1, embedding2, mode = "cosine" /* DEFAULT */) {
    return similarity(embedding1, embedding2, mode);
  }
};

// src/embeddings/MultiModalEmbedding.ts
var MultiModalEmbedding = class extends BaseEmbedding {
  getImageEmbeddings(images) {
    return __async(this, null, function* () {
      return Promise.all(
        images.map((imgFilePath) => this.getImageEmbedding(imgFilePath))
      );
    });
  }
};

// src/embeddings/ClipEmbedding.ts
var ClipEmbeddingModelType = /* @__PURE__ */ ((ClipEmbeddingModelType2) => {
  ClipEmbeddingModelType2["XENOVA_CLIP_VIT_BASE_PATCH32"] = "Xenova/clip-vit-base-patch32";
  ClipEmbeddingModelType2["XENOVA_CLIP_VIT_BASE_PATCH16"] = "Xenova/clip-vit-base-patch16";
  return ClipEmbeddingModelType2;
})(ClipEmbeddingModelType || {});
var ClipEmbedding = class extends MultiModalEmbedding {
  constructor() {
    super(...arguments);
    this.modelType = "Xenova/clip-vit-base-patch16" /* XENOVA_CLIP_VIT_BASE_PATCH16 */;
  }
  getTokenizer() {
    return __async(this, null, function* () {
      if (!this.tokenizer) {
        const { AutoTokenizer } = yield import("@xenova/transformers");
        this.tokenizer = yield AutoTokenizer.from_pretrained(this.modelType);
      }
      return this.tokenizer;
    });
  }
  getProcessor() {
    return __async(this, null, function* () {
      if (!this.processor) {
        const { AutoProcessor } = yield import("@xenova/transformers");
        this.processor = yield AutoProcessor.from_pretrained(this.modelType);
      }
      return this.processor;
    });
  }
  getVisionModel() {
    return __async(this, null, function* () {
      if (!this.visionModel) {
        const { CLIPVisionModelWithProjection } = yield import("@xenova/transformers");
        this.visionModel = yield CLIPVisionModelWithProjection.from_pretrained(
          this.modelType
        );
      }
      return this.visionModel;
    });
  }
  getTextModel() {
    return __async(this, null, function* () {
      if (!this.textModel) {
        const { CLIPTextModelWithProjection } = yield import("@xenova/transformers");
        this.textModel = yield CLIPTextModelWithProjection.from_pretrained(
          this.modelType
        );
      }
      return this.textModel;
    });
  }
  getImageEmbedding(image) {
    return __async(this, null, function* () {
      const loadedImage = yield readImage(image);
      const imageInputs = yield (yield this.getProcessor())(loadedImage);
      const { image_embeds } = yield (yield this.getVisionModel())(imageInputs);
      return Array.from(image_embeds.data);
    });
  }
  getTextEmbedding(text) {
    return __async(this, null, function* () {
      const textInputs = yield (yield this.getTokenizer())([text], { padding: true, truncation: true });
      const { text_embeds } = yield (yield this.getTextModel())(textInputs);
      return text_embeds.data;
    });
  }
  getQueryEmbedding(query) {
    return __async(this, null, function* () {
      return this.getTextEmbedding(query);
    });
  }
};

// src/llm/mistral.ts
var ALL_AVAILABLE_MISTRAL_MODELS = {
  "mistral-tiny": { contextWindow: 32e3 },
  "mistral-small": { contextWindow: 32e3 },
  "mistral-medium": { contextWindow: 32e3 }
};
var MistralAISession = class {
  constructor(init) {
    if (init == null ? void 0 : init.apiKey) {
      this.apiKey = init == null ? void 0 : init.apiKey;
    } else {
      if (typeof process !== void 0) {
        this.apiKey = process.env.MISTRAL_API_KEY;
      }
    }
    if (!this.apiKey) {
      throw new Error("Set Mistral API key in MISTRAL_API_KEY env variable");
    }
  }
  getClient() {
    return __async(this, null, function* () {
      const { default: MistralClient } = yield import("@mistralai/mistralai");
      if (!this.client) {
        this.client = new MistralClient(this.apiKey);
      }
      return this.client;
    });
  }
};
var MistralAI = class {
  constructor(init) {
    this.hasStreaming = true;
    var _a, _b, _c, _d, _e, _f;
    this.model = (_a = init == null ? void 0 : init.model) != null ? _a : "mistral-small";
    this.temperature = (_b = init == null ? void 0 : init.temperature) != null ? _b : 0.1;
    this.topP = (_c = init == null ? void 0 : init.topP) != null ? _c : 1;
    this.maxTokens = (_d = init == null ? void 0 : init.maxTokens) != null ? _d : void 0;
    this.callbackManager = init == null ? void 0 : init.callbackManager;
    this.safeMode = (_e = init == null ? void 0 : init.safeMode) != null ? _e : false;
    this.randomSeed = (_f = init == null ? void 0 : init.randomSeed) != null ? _f : void 0;
    this.session = new MistralAISession(init);
  }
  get metadata() {
    return {
      model: this.model,
      temperature: this.temperature,
      topP: this.topP,
      maxTokens: this.maxTokens,
      contextWindow: ALL_AVAILABLE_MISTRAL_MODELS[this.model].contextWindow,
      tokenizer: void 0
    };
  }
  tokens(messages) {
    throw new Error("Method not implemented.");
  }
  buildParams(messages) {
    return {
      model: this.model,
      temperature: this.temperature,
      maxTokens: this.maxTokens,
      topP: this.topP,
      safeMode: this.safeMode,
      randomSeed: this.randomSeed,
      messages
    };
  }
  chat(messages, parentEvent, streaming) {
    return __async(this, null, function* () {
      if (streaming) {
        if (!this.hasStreaming) {
          throw Error("No streaming support for this LLM.");
        }
        return this.streamChat(messages, parentEvent);
      }
      const client = yield this.session.getClient();
      const response = yield client.chat(this.buildParams(messages));
      const message = response.choices[0].message;
      return {
        message
      };
    });
  }
  complete(prompt, parentEvent, streaming) {
    return __async(this, null, function* () {
      return this.chat(
        [{ content: prompt, role: "user" }],
        parentEvent,
        streaming
      );
    });
  }
  streamChat(messages, parentEvent) {
    return __asyncGenerator(this, null, function* () {
      var _a, _b;
      const onLLMStream = ((_a = this.callbackManager) == null ? void 0 : _a.onLLMStream) ? this.callbackManager.onLLMStream : () => {
      };
      const client = yield new __await(this.session.getClient());
      const chunkStream = yield new __await(client.chatStream(this.buildParams(messages)));
      const event = parentEvent ? parentEvent : {
        id: "unspecified",
        type: "llmPredict"
      };
      var idx_counter = 0;
      try {
        for (var iter = __forAwait(chunkStream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          if (!part.choices.length)
            continue;
          part.choices[0].index = idx_counter;
          const isDone = part.choices[0].finish_reason === "stop" ? true : false;
          const stream_callback = {
            event,
            index: idx_counter,
            isDone,
            token: part
          };
          onLLMStream(stream_callback);
          idx_counter++;
          yield (_b = part.choices[0].delta.content) != null ? _b : "";
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      return;
    });
  }
  //streamComplete doesn't need to be async because it's child function is already async
  streamComplete(query, parentEvent) {
    return this.streamChat([{ content: query, role: "user" }], parentEvent);
  }
};

// src/embeddings/MistralAIEmbedding.ts
var MistralAIEmbeddingModelType = /* @__PURE__ */ ((MistralAIEmbeddingModelType2) => {
  MistralAIEmbeddingModelType2["MISTRAL_EMBED"] = "mistral-embed";
  return MistralAIEmbeddingModelType2;
})(MistralAIEmbeddingModelType || {});
var MistralAIEmbedding = class extends BaseEmbedding {
  constructor(init) {
    super();
    this.model = "mistral-embed" /* MISTRAL_EMBED */;
    this.session = new MistralAISession(init);
  }
  getMistralAIEmbedding(input) {
    return __async(this, null, function* () {
      const client = yield this.session.getClient();
      const { data } = yield client.embeddings({
        model: this.model,
        input: [input]
      });
      return data[0].embedding;
    });
  }
  getTextEmbedding(text) {
    return __async(this, null, function* () {
      return this.getMistralAIEmbedding(text);
    });
  }
  getQueryEmbedding(query) {
    return __async(this, null, function* () {
      return this.getMistralAIEmbedding(query);
    });
  }
};

// src/llm/azure.ts
var ALL_AZURE_OPENAI_CHAT_MODELS = {
  "gpt-35-turbo": { contextWindow: 4096, openAIModel: "gpt-3.5-turbo" },
  "gpt-35-turbo-16k": {
    contextWindow: 16384,
    openAIModel: "gpt-3.5-turbo-16k"
  },
  "gpt-4": { contextWindow: 8192, openAIModel: "gpt-4" },
  "gpt-4-32k": { contextWindow: 32768, openAIModel: "gpt-4-32k" }
};
var ALL_AZURE_OPENAI_EMBEDDING_MODELS = {
  "text-embedding-ada-002": {
    dimensions: 1536,
    openAIModel: "text-embedding-ada-002",
    maxTokens: 8191
  }
};
var DEFAULT_API_VERSION = "2023-05-15";
function getAzureConfigFromEnv(init) {
  var _a, _b, _c, _d, _e, _f, _g, _h, _i, _j, _k, _l, _m;
  return {
    apiKey: (_c = (_b = (_a = init == null ? void 0 : init.apiKey) != null ? _a : process.env.AZURE_OPENAI_KEY) != null ? _b : (
      // From Azure docs
      process.env.OPENAI_API_KEY
    )) != null ? _c : (
      // Python compatible
      process.env.AZURE_OPENAI_API_KEY
    ),
    // LCJS compatible
    endpoint: (_f = (_e = (_d = init == null ? void 0 : init.endpoint) != null ? _d : process.env.AZURE_OPENAI_ENDPOINT) != null ? _e : (
      // From Azure docs
      process.env.OPENAI_API_BASE
    )) != null ? _f : (
      // Python compatible
      process.env.AZURE_OPENAI_API_INSTANCE_NAME
    ),
    // LCJS compatible
    apiVersion: (_j = (_i = (_h = (_g = init == null ? void 0 : init.apiVersion) != null ? _g : process.env.AZURE_OPENAI_API_VERSION) != null ? _h : (
      // From Azure docs
      process.env.OPENAI_API_VERSION
    )) != null ? _i : (
      // Python compatible
      process.env.AZURE_OPENAI_API_VERSION
    )) != null ? _j : (
      // LCJS compatible
      DEFAULT_API_VERSION
    ),
    deploymentName: (_m = (_l = (_k = init == null ? void 0 : init.deploymentName) != null ? _k : process.env.AZURE_OPENAI_DEPLOYMENT) != null ? _l : (
      // From Azure docs
      process.env.AZURE_OPENAI_API_DEPLOYMENT_NAME
    )) != null ? _m : (
      // LCJS compatible
      init == null ? void 0 : init.model
    )
    // Fall back to model name, Python compatible
  };
}
function getAzureBaseUrl(config) {
  return `${config.endpoint}/openai/deployments/${config.deploymentName}`;
}
function getAzureModel(openAIModel) {
  for (const [key, value] of Object.entries(
    ALL_AZURE_OPENAI_EMBEDDING_MODELS
  )) {
    if (value.openAIModel === openAIModel) {
      return key;
    }
  }
  for (const [key, value] of Object.entries(ALL_AZURE_OPENAI_CHAT_MODELS)) {
    if (value.openAIModel === openAIModel) {
      return key;
    }
  }
  throw new Error(`Unknown model: ${openAIModel}`);
}
function shouldUseAzure() {
  return process.env.AZURE_OPENAI_ENDPOINT || process.env.AZURE_OPENAI_API_INSTANCE_NAME || process.env.OPENAI_API_TYPE === "azure";
}

// src/llm/openai.ts
import _8 from "lodash";
import OpenAI from "openai";
var AzureOpenAI = class extends OpenAI {
  authHeaders() {
    return { "api-key": this.apiKey };
  }
};
var OpenAISession = class {
  constructor(options = {}) {
    if (!options.apiKey) {
      if (typeof process !== void 0) {
        options.apiKey = process.env.OPENAI_API_KEY;
      }
    }
    if (!options.apiKey) {
      throw new Error("Set OpenAI Key in OPENAI_API_KEY env variable");
    }
    if (options.azure) {
      this.openai = new AzureOpenAI(options);
    } else {
      this.openai = new OpenAI(__spreadValues({}, options));
    }
  }
};
var defaultOpenAISession = [];
function getOpenAISession(options = {}) {
  var _a;
  let session = (_a = defaultOpenAISession.find((session2) => {
    return _8.isEqual(session2.options, options);
  })) == null ? void 0 : _a.session;
  if (!session) {
    session = new OpenAISession(options);
    defaultOpenAISession.push({ session, options });
  }
  return session;
}

// src/embeddings/OpenAIEmbedding.ts
var OpenAIEmbeddingModelType = /* @__PURE__ */ ((OpenAIEmbeddingModelType2) => {
  OpenAIEmbeddingModelType2["TEXT_EMBED_ADA_002"] = "text-embedding-ada-002";
  return OpenAIEmbeddingModelType2;
})(OpenAIEmbeddingModelType || {});
var OpenAIEmbedding = class extends BaseEmbedding {
  constructor(init) {
    var _a, _b, _c, _d, _e;
    super();
    // OpenAI session params
    this.apiKey = void 0;
    this.model = "text-embedding-ada-002" /* TEXT_EMBED_ADA_002 */;
    this.maxRetries = (_a = init == null ? void 0 : init.maxRetries) != null ? _a : 10;
    this.timeout = (_b = init == null ? void 0 : init.timeout) != null ? _b : 60 * 1e3;
    this.additionalSessionOptions = init == null ? void 0 : init.additionalSessionOptions;
    if ((init == null ? void 0 : init.azure) || shouldUseAzure()) {
      const azureConfig = getAzureConfigFromEnv(__spreadProps(__spreadValues({}, init == null ? void 0 : init.azure), {
        model: getAzureModel(this.model)
      }));
      if (!azureConfig.apiKey) {
        throw new Error(
          "Azure API key is required for OpenAI Azure models. Please set the AZURE_OPENAI_KEY environment variable."
        );
      }
      this.apiKey = azureConfig.apiKey;
      this.session = (_c = init == null ? void 0 : init.session) != null ? _c : getOpenAISession(__spreadValues({
        azure: true,
        apiKey: this.apiKey,
        baseURL: getAzureBaseUrl(azureConfig),
        maxRetries: this.maxRetries,
        timeout: this.timeout,
        defaultQuery: { "api-version": azureConfig.apiVersion }
      }, this.additionalSessionOptions));
    } else {
      this.apiKey = (_d = init == null ? void 0 : init.apiKey) != null ? _d : void 0;
      this.session = (_e = init == null ? void 0 : init.session) != null ? _e : getOpenAISession(__spreadValues({
        apiKey: this.apiKey,
        maxRetries: this.maxRetries,
        timeout: this.timeout
      }, this.additionalSessionOptions));
    }
  }
  getOpenAIEmbedding(input) {
    return __async(this, null, function* () {
      const { data } = yield this.session.openai.embeddings.create({
        model: this.model,
        input
      });
      return data[0].embedding;
    });
  }
  getTextEmbedding(text) {
    return __async(this, null, function* () {
      return this.getOpenAIEmbedding(text);
    });
  }
  getQueryEmbedding(query) {
    return __async(this, null, function* () {
      return this.getOpenAIEmbedding(query);
    });
  }
};

// src/GlobalsHelper.ts
import { encodingForModel } from "js-tiktoken";
import { v4 as uuidv43 } from "uuid";
var Tokenizers = /* @__PURE__ */ ((Tokenizers2) => {
  Tokenizers2["CL100K_BASE"] = "cl100k_base";
  return Tokenizers2;
})(Tokenizers || {});
var GlobalsHelper = class {
  constructor() {
    this.defaultTokenizer = null;
  }
  initDefaultTokenizer() {
    const encoding = encodingForModel("text-embedding-ada-002");
    this.defaultTokenizer = {
      encode: (text) => {
        return new Uint32Array(encoding.encode(text));
      },
      decode: (tokens) => {
        const numberArray = Array.from(tokens);
        const text = encoding.decode(numberArray);
        const uint8Array = new TextEncoder().encode(text);
        return new TextDecoder().decode(uint8Array);
      }
    };
  }
  tokenizer(encoding) {
    if (encoding && encoding !== "cl100k_base" /* CL100K_BASE */) {
      throw new Error(`Tokenizer encoding ${encoding} not yet supported`);
    }
    if (!this.defaultTokenizer) {
      this.initDefaultTokenizer();
    }
    return this.defaultTokenizer.encode.bind(this.defaultTokenizer);
  }
  tokenizerDecoder(encoding) {
    if (encoding && encoding !== "cl100k_base" /* CL100K_BASE */) {
      throw new Error(`Tokenizer encoding ${encoding} not yet supported`);
    }
    if (!this.defaultTokenizer) {
      this.initDefaultTokenizer();
    }
    return this.defaultTokenizer.decode.bind(this.defaultTokenizer);
  }
  createEvent({
    parentEvent,
    type,
    tags
  }) {
    return {
      id: uuidv43(),
      type,
      // inherit parent tags if tags not set
      tags: tags || (parentEvent == null ? void 0 : parentEvent.tags),
      parentId: parentEvent == null ? void 0 : parentEvent.id
    };
  }
};
var globalsHelper = new GlobalsHelper();

// src/llm/anthropic.ts
import Anthropic, {
  AI_PROMPT,
  HUMAN_PROMPT
} from "@anthropic-ai/sdk";
import _9 from "lodash";
var AnthropicSession = class {
  constructor(options = {}) {
    if (!options.apiKey) {
      if (typeof process !== void 0) {
        options.apiKey = process.env.ANTHROPIC_API_KEY;
      }
    }
    if (!options.apiKey) {
      throw new Error("Set Anthropic Key in ANTHROPIC_API_KEY env variable");
    }
    this.anthropic = new Anthropic(options);
  }
};
var defaultAnthropicSession = [];
function getAnthropicSession(options = {}) {
  var _a;
  let session = (_a = defaultAnthropicSession.find((session2) => {
    return _9.isEqual(session2.options, options);
  })) == null ? void 0 : _a.session;
  if (!session) {
    session = new AnthropicSession(options);
    defaultAnthropicSession.push({ session, options });
  }
  return session;
}
var ANTHROPIC_HUMAN_PROMPT = HUMAN_PROMPT;
var ANTHROPIC_AI_PROMPT = AI_PROMPT;

// src/llm/portkey.ts
import _10 from "lodash";
import { Portkey } from "portkey-ai";
var readEnv = (env, default_val) => {
  var _a, _b;
  if (typeof process !== "undefined") {
    return (_b = (_a = process.env) == null ? void 0 : _a[env]) != null ? _b : default_val;
  }
  return default_val;
};
var PortkeySession = class {
  constructor(options = {}) {
    if (!options.apiKey) {
      options.apiKey = readEnv("PORTKEY_API_KEY");
    }
    if (!options.baseURL) {
      options.baseURL = readEnv("PORTKEY_BASE_URL", "https://api.portkey.ai");
    }
    this.portkey = new Portkey({});
    this.portkey.llms = [{}];
    if (!options.apiKey) {
      throw new Error("Set Portkey ApiKey in PORTKEY_API_KEY env variable");
    }
    this.portkey = new Portkey(options);
  }
};
var defaultPortkeySession = [];
function getPortkeySession(options = {}) {
  var _a;
  let session = (_a = defaultPortkeySession.find((session2) => {
    return _10.isEqual(session2.options, options);
  })) == null ? void 0 : _a.session;
  if (!session) {
    session = new PortkeySession(options);
    defaultPortkeySession.push({ session, options });
  }
  return session;
}

// src/llm/replicate.ts
var replicate_exports = {};
__export(replicate_exports, {
  ReplicateSession: () => ReplicateSession,
  getReplicateSession: () => getReplicateSession
});
__reExport(replicate_exports, openai_star);
import Replicate from "replicate";
import * as openai_star from "openai";
var ReplicateSession = class {
  constructor(replicateKey = null) {
    this.replicateKey = null;
    if (replicateKey) {
      this.replicateKey = replicateKey;
    } else if (process.env.REPLICATE_API_TOKEN) {
      this.replicateKey = process.env.REPLICATE_API_TOKEN;
    } else {
      throw new Error(
        "Set Replicate token in REPLICATE_API_TOKEN env variable"
      );
    }
    this.replicate = new Replicate({ auth: this.replicateKey });
  }
};
var defaultReplicateSession = null;
function getReplicateSession(replicateKey = null) {
  if (!defaultReplicateSession) {
    defaultReplicateSession = new ReplicateSession(replicateKey);
  }
  return defaultReplicateSession;
}

// src/llm/LLM.ts
var GPT4_MODELS = {
  "gpt-4": { contextWindow: 8192 },
  "gpt-4-32k": { contextWindow: 32768 },
  "gpt-4-1106-preview": { contextWindow: 128e3 },
  "gpt-4-vision-preview": { contextWindow: 8192 }
};
var GPT35_MODELS = {
  "gpt-3.5-turbo": { contextWindow: 4096 },
  "gpt-3.5-turbo-16k": { contextWindow: 16384 },
  "gpt-3.5-turbo-1106": { contextWindow: 16384 }
};
var ALL_AVAILABLE_OPENAI_MODELS = __spreadValues(__spreadValues({}, GPT4_MODELS), GPT35_MODELS);
var OpenAI2 = class {
  constructor(init) {
    this.hasStreaming = true;
    // OpenAI session params
    this.apiKey = void 0;
    var _a, _b, _c, _d, _e, _f, _g, _h, _i;
    this.model = (_a = init == null ? void 0 : init.model) != null ? _a : "gpt-3.5-turbo";
    this.temperature = (_b = init == null ? void 0 : init.temperature) != null ? _b : 0.1;
    this.topP = (_c = init == null ? void 0 : init.topP) != null ? _c : 1;
    this.maxTokens = (_d = init == null ? void 0 : init.maxTokens) != null ? _d : void 0;
    this.maxRetries = (_e = init == null ? void 0 : init.maxRetries) != null ? _e : 10;
    this.timeout = (_f = init == null ? void 0 : init.timeout) != null ? _f : 60 * 1e3;
    this.additionalChatOptions = init == null ? void 0 : init.additionalChatOptions;
    this.additionalSessionOptions = init == null ? void 0 : init.additionalSessionOptions;
    if ((init == null ? void 0 : init.azure) || shouldUseAzure()) {
      const azureConfig = getAzureConfigFromEnv(__spreadProps(__spreadValues({}, init == null ? void 0 : init.azure), {
        model: getAzureModel(this.model)
      }));
      if (!azureConfig.apiKey) {
        throw new Error(
          "Azure API key is required for OpenAI Azure models. Please set the AZURE_OPENAI_KEY environment variable."
        );
      }
      this.apiKey = azureConfig.apiKey;
      this.session = (_g = init == null ? void 0 : init.session) != null ? _g : getOpenAISession(__spreadValues({
        azure: true,
        apiKey: this.apiKey,
        baseURL: getAzureBaseUrl(azureConfig),
        maxRetries: this.maxRetries,
        timeout: this.timeout,
        defaultQuery: { "api-version": azureConfig.apiVersion }
      }, this.additionalSessionOptions));
    } else {
      this.apiKey = (_h = init == null ? void 0 : init.apiKey) != null ? _h : void 0;
      this.session = (_i = init == null ? void 0 : init.session) != null ? _i : getOpenAISession(__spreadValues({
        apiKey: this.apiKey,
        maxRetries: this.maxRetries,
        timeout: this.timeout
      }, this.additionalSessionOptions));
    }
    this.callbackManager = init == null ? void 0 : init.callbackManager;
  }
  get metadata() {
    return {
      model: this.model,
      temperature: this.temperature,
      topP: this.topP,
      maxTokens: this.maxTokens,
      contextWindow: ALL_AVAILABLE_OPENAI_MODELS[this.model].contextWindow,
      tokenizer: "cl100k_base" /* CL100K_BASE */
    };
  }
  tokens(messages) {
    const tokenizer = globalsHelper.tokenizer(this.metadata.tokenizer);
    const tokensPerMessage = 3;
    let numTokens = 0;
    for (const message of messages) {
      numTokens += tokensPerMessage;
      for (const value of Object.values(message)) {
        numTokens += tokenizer(value).length;
      }
    }
    numTokens += 3;
    return numTokens;
  }
  mapMessageType(messageType) {
    switch (messageType) {
      case "user":
        return "user";
      case "assistant":
        return "assistant";
      case "system":
        return "system";
      case "function":
        return "function";
      default:
        return "user";
    }
  }
  chat(messages, parentEvent, streaming) {
    return __async(this, null, function* () {
      var _a, _b;
      const baseRequestParams = __spreadValues({
        model: this.model,
        temperature: this.temperature,
        max_tokens: this.maxTokens,
        messages: messages.map(
          (message) => ({
            role: this.mapMessageType(message.role),
            content: message.content
          })
        ),
        top_p: this.topP
      }, this.additionalChatOptions);
      if (streaming) {
        if (!this.hasStreaming) {
          throw Error("No streaming support for this LLM.");
        }
        return this.streamChat(messages, parentEvent);
      }
      const response = yield this.session.openai.chat.completions.create(__spreadProps(__spreadValues({}, baseRequestParams), {
        stream: false
      }));
      const content = (_b = (_a = response.choices[0].message) == null ? void 0 : _a.content) != null ? _b : "";
      return {
        message: { content, role: response.choices[0].message.role }
      };
    });
  }
  complete(prompt, parentEvent, streaming) {
    return __async(this, null, function* () {
      return this.chat(
        [{ content: prompt, role: "user" }],
        parentEvent,
        streaming
      );
    });
  }
  //We can wrap a stream in a generator to add some additional logging behavior
  //For future edits: syntax for generator type is <typeof Yield, typeof Return, typeof Accept>
  //"typeof Accept" refers to what types you'll accept when you manually call generator.next(<AcceptType>)
  streamChat(messages, parentEvent) {
    return __asyncGenerator(this, null, function* () {
      var _a;
      const baseRequestParams = __spreadValues({
        model: this.model,
        temperature: this.temperature,
        max_tokens: this.maxTokens,
        messages: messages.map(
          (message) => ({
            role: this.mapMessageType(message.role),
            content: message.content
          })
        ),
        top_p: this.topP
      }, this.additionalChatOptions);
      const onLLMStream = ((_a = this.callbackManager) == null ? void 0 : _a.onLLMStream) ? this.callbackManager.onLLMStream : () => {
      };
      const chunk_stream = yield new __await(this.session.openai.chat.completions.create(__spreadProps(__spreadValues({}, baseRequestParams), {
        stream: true
      })));
      const event = parentEvent ? parentEvent : {
        id: "unspecified",
        type: "llmPredict"
      };
      var idx_counter = 0;
      try {
        for (var iter = __forAwait(chunk_stream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          if (!part.choices.length)
            continue;
          part.choices[0].index = idx_counter;
          const is_done = part.choices[0].finish_reason === "stop" ? true : false;
          const stream_callback = {
            event,
            index: idx_counter,
            isDone: is_done,
            token: part
          };
          onLLMStream(stream_callback);
          idx_counter++;
          yield part.choices[0].delta.content ? part.choices[0].delta.content : "";
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      return;
    });
  }
  //streamComplete doesn't need to be async because it's child function is already async
  streamComplete(query, parentEvent) {
    return this.streamChat([{ content: query, role: "user" }], parentEvent);
  }
};
var ALL_AVAILABLE_LLAMADEUCE_MODELS = {
  "Llama-2-70b-chat-old": {
    contextWindow: 4096,
    replicateApi: "replicate/llama70b-v2-chat:e951f18578850b652510200860fc4ea62b3b16fac280f83ff32282f87bbd2e48"
    //^ Previous 70b model. This is also actually 4 bit, although not exllama.
  },
  "Llama-2-70b-chat-4bit": {
    contextWindow: 4096,
    replicateApi: "meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3"
    //^ Model is based off of exllama 4bit.
  },
  "Llama-2-13b-chat-old": {
    contextWindow: 4096,
    replicateApi: "a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5"
  },
  //^ Last known good 13b non-quantized model. In future versions they add the SYS and INST tags themselves
  "Llama-2-13b-chat-4bit": {
    contextWindow: 4096,
    replicateApi: "meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d"
  },
  "Llama-2-7b-chat-old": {
    contextWindow: 4096,
    replicateApi: "a16z-infra/llama7b-v2-chat:4f0a4744c7295c024a1de15e1a63c880d3da035fa1f49bfd344fe076074c8eea"
    //^ Last (somewhat) known good 7b non-quantized model. In future versions they add the SYS and INST
    // tags themselves
    // https://github.com/replicate/cog-llama-template/commit/fa5ce83912cf82fc2b9c01a4e9dc9bff6f2ef137
    // Problem is that they fix the max_new_tokens issue in the same commit. :-(
  },
  "Llama-2-7b-chat-4bit": {
    contextWindow: 4096,
    replicateApi: "meta/llama-2-7b-chat:13c3cdee13ee059ab779f0291d29054dab00a47dad8261375654de5540165fb0"
  }
};
var DeuceChatStrategy = /* @__PURE__ */ ((DeuceChatStrategy2) => {
  DeuceChatStrategy2["A16Z"] = "a16z";
  DeuceChatStrategy2["META"] = "meta";
  DeuceChatStrategy2["METAWBOS"] = "metawbos";
  DeuceChatStrategy2["REPLICATE4BIT"] = "replicate4bit";
  DeuceChatStrategy2["REPLICATE4BITWNEWLINES"] = "replicate4bitwnewlines";
  return DeuceChatStrategy2;
})(DeuceChatStrategy || {});
var LlamaDeuce = class {
  constructor(init) {
    var _a, _b, _c, _d, _e, _f, _g;
    this.model = (_a = init == null ? void 0 : init.model) != null ? _a : "Llama-2-70b-chat-4bit";
    this.chatStrategy = (_b = init == null ? void 0 : init.chatStrategy) != null ? _b : this.model.endsWith("4bit") ? "replicate4bitwnewlines" /* REPLICATE4BITWNEWLINES */ : "metawbos" /* METAWBOS */;
    this.temperature = (_c = init == null ? void 0 : init.temperature) != null ? _c : 0.1;
    this.topP = (_d = init == null ? void 0 : init.topP) != null ? _d : 1;
    this.maxTokens = (_e = init == null ? void 0 : init.maxTokens) != null ? _e : ALL_AVAILABLE_LLAMADEUCE_MODELS[this.model].contextWindow;
    this.replicateSession = (_f = init == null ? void 0 : init.replicateSession) != null ? _f : new ReplicateSession();
    this.hasStreaming = (_g = init == null ? void 0 : init.hasStreaming) != null ? _g : false;
  }
  tokens(messages) {
    throw new Error("Method not implemented.");
  }
  get metadata() {
    return {
      model: this.model,
      temperature: this.temperature,
      topP: this.topP,
      maxTokens: this.maxTokens,
      contextWindow: ALL_AVAILABLE_LLAMADEUCE_MODELS[this.model].contextWindow,
      tokenizer: void 0
    };
  }
  mapMessagesToPrompt(messages) {
    if (this.chatStrategy === "a16z" /* A16Z */) {
      return this.mapMessagesToPromptA16Z(messages);
    } else if (this.chatStrategy === "meta" /* META */) {
      return this.mapMessagesToPromptMeta(messages);
    } else if (this.chatStrategy === "metawbos" /* METAWBOS */) {
      return this.mapMessagesToPromptMeta(messages, { withBos: true });
    } else if (this.chatStrategy === "replicate4bit" /* REPLICATE4BIT */) {
      return this.mapMessagesToPromptMeta(messages, {
        replicate4Bit: true,
        withNewlines: true
      });
    } else if (this.chatStrategy === "replicate4bitwnewlines" /* REPLICATE4BITWNEWLINES */) {
      return this.mapMessagesToPromptMeta(messages, {
        replicate4Bit: true,
        withNewlines: true
      });
    } else {
      return this.mapMessagesToPromptMeta(messages);
    }
  }
  mapMessagesToPromptA16Z(messages) {
    return {
      prompt: messages.reduce((acc, message) => {
        return (acc && `${acc}

`) + `${this.mapMessageTypeA16Z(message.role)}${message.content}`;
      }, "") + "\n\nAssistant:",
      //^ Here we're differing from A16Z by omitting the space. Generally spaces at the end of prompts decrease performance due to tokenization
      systemPrompt: void 0
    };
  }
  mapMessageTypeA16Z(messageType) {
    switch (messageType) {
      case "user":
        return "User: ";
      case "assistant":
        return "Assistant: ";
      case "system":
        return "";
      default:
        throw new Error("Unsupported LlamaDeuce message type");
    }
  }
  mapMessagesToPromptMeta(messages, opts) {
    const {
      withBos = false,
      replicate4Bit = false,
      withNewlines = false
    } = opts != null ? opts : {};
    const DEFAULT_SYSTEM_PROMPT = `You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.

If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.`;
    const B_SYS = "<<SYS>>\n";
    const E_SYS = "\n<</SYS>>\n\n";
    const B_INST = "[INST]";
    const E_INST = "[/INST]";
    const BOS = "<s>";
    const EOS = "</s>";
    if (messages.length === 0) {
      return { prompt: "", systemPrompt: void 0 };
    }
    messages = [...messages];
    let systemPrompt = void 0;
    if (messages[0].role === "system") {
      const systemMessage = messages.shift();
      if (replicate4Bit) {
        systemPrompt = systemMessage.content;
      } else {
        const systemStr = `${B_SYS}${systemMessage.content}${E_SYS}`;
        if (messages[0].role !== "user") {
          throw new Error(
            "LlamaDeuce: if there is a system message, the second message must be a user message."
          );
        }
        const userContent = messages[0].content;
        messages[0].content = `${systemStr}${userContent}`;
      }
    } else {
      if (!replicate4Bit) {
        messages[0].content = `${B_SYS}${DEFAULT_SYSTEM_PROMPT}${E_SYS}${messages[0].content}`;
      }
    }
    return {
      prompt: messages.reduce((acc, message, index) => {
        if (index % 2 === 0) {
          return `${acc}${withBos ? BOS : ""}${B_INST} ${message.content.trim()} ${E_INST}` + (withNewlines ? "\n" : "");
        } else {
          return `${acc} ${message.content.trim()}` + (withNewlines ? "\n" : " ") + (withBos ? EOS : "");
        }
      }, ""),
      systemPrompt
    };
  }
  chat(messages, _parentEvent, streaming) {
    return __async(this, null, function* () {
      const api = ALL_AVAILABLE_LLAMADEUCE_MODELS[this.model].replicateApi;
      const { prompt, systemPrompt } = this.mapMessagesToPrompt(messages);
      const replicateOptions = {
        input: {
          prompt,
          system_prompt: systemPrompt,
          temperature: this.temperature,
          top_p: this.topP
        }
      };
      if (this.model.endsWith("4bit")) {
        replicateOptions.input.max_new_tokens = this.maxTokens;
      } else {
        replicateOptions.input.max_length = this.maxTokens;
      }
      const response = yield this.replicateSession.replicate.run(
        api,
        replicateOptions
      );
      return {
        message: {
          content: response.join("").trimStart(),
          //^ We need to do this because Replicate returns a list of strings (for streaming functionality which is not exposed by the run function)
          role: "assistant"
        }
      };
    });
  }
  complete(prompt, parentEvent, streaming) {
    return __async(this, null, function* () {
      return this.chat([{ content: prompt, role: "user" }], parentEvent);
    });
  }
};
var ALL_AVAILABLE_ANTHROPIC_MODELS = {
  // both models have 100k context window, see https://docs.anthropic.com/claude/reference/selecting-a-model
  "claude-2": { contextWindow: 2e5 },
  "claude-instant-1": { contextWindow: 1e5 }
};
var Anthropic2 = class {
  constructor(init) {
    this.hasStreaming = true;
    // Anthropic session params
    this.apiKey = void 0;
    var _a, _b, _c, _d, _e, _f, _g, _h;
    this.model = (_a = init == null ? void 0 : init.model) != null ? _a : "claude-2";
    this.temperature = (_b = init == null ? void 0 : init.temperature) != null ? _b : 0.1;
    this.topP = (_c = init == null ? void 0 : init.topP) != null ? _c : 0.999;
    this.maxTokens = (_d = init == null ? void 0 : init.maxTokens) != null ? _d : void 0;
    this.apiKey = (_e = init == null ? void 0 : init.apiKey) != null ? _e : void 0;
    this.maxRetries = (_f = init == null ? void 0 : init.maxRetries) != null ? _f : 10;
    this.timeout = (_g = init == null ? void 0 : init.timeout) != null ? _g : 60 * 1e3;
    this.session = (_h = init == null ? void 0 : init.session) != null ? _h : getAnthropicSession({
      apiKey: this.apiKey,
      maxRetries: this.maxRetries,
      timeout: this.timeout
    });
    this.callbackManager = init == null ? void 0 : init.callbackManager;
  }
  tokens(messages) {
    throw new Error("Method not implemented.");
  }
  get metadata() {
    return {
      model: this.model,
      temperature: this.temperature,
      topP: this.topP,
      maxTokens: this.maxTokens,
      contextWindow: ALL_AVAILABLE_ANTHROPIC_MODELS[this.model].contextWindow,
      tokenizer: void 0
    };
  }
  mapMessagesToPrompt(messages) {
    return messages.reduce((acc, message) => {
      return acc + `${message.role === "system" ? "" : message.role === "assistant" ? ANTHROPIC_AI_PROMPT + " " : ANTHROPIC_HUMAN_PROMPT + " "}${message.content.trim()}`;
    }, "") + ANTHROPIC_AI_PROMPT;
  }
  chat(messages, parentEvent, streaming) {
    return __async(this, null, function* () {
      var _a;
      if (streaming) {
        if (!this.hasStreaming) {
          throw Error("No streaming support for this LLM.");
        }
        return this.streamChat(messages, parentEvent);
      }
      const response = yield this.session.anthropic.completions.create({
        model: this.model,
        prompt: this.mapMessagesToPrompt(messages),
        max_tokens_to_sample: (_a = this.maxTokens) != null ? _a : 1e5,
        temperature: this.temperature,
        top_p: this.topP
      });
      return {
        message: { content: response.completion.trimStart(), role: "assistant" }
        //^ We're trimming the start because Anthropic often starts with a space in the response
        // That space will be re-added when we generate the next prompt.
      };
    });
  }
  streamChat(messages, parentEvent) {
    return __asyncGenerator(this, null, function* () {
      var _a;
      const stream = yield new __await(this.session.anthropic.completions.create({
        model: this.model,
        prompt: this.mapMessagesToPrompt(messages),
        max_tokens_to_sample: (_a = this.maxTokens) != null ? _a : 1e5,
        temperature: this.temperature,
        top_p: this.topP,
        stream: true
      }));
      var idx_counter = 0;
      try {
        for (var iter = __forAwait(stream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          idx_counter++;
          yield part.completion;
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      return;
    });
  }
  complete(prompt, parentEvent, streaming) {
    return __async(this, null, function* () {
      if (streaming) {
        return this.streamComplete(prompt, parentEvent);
      }
      return this.chat(
        [{ content: prompt, role: "user" }],
        parentEvent,
        streaming
      );
    });
  }
  streamComplete(prompt, parentEvent) {
    return this.streamChat([{ content: prompt, role: "user" }], parentEvent);
  }
};
var Portkey2 = class {
  constructor(init) {
    this.hasStreaming = true;
    this.apiKey = void 0;
    this.baseURL = void 0;
    this.mode = void 0;
    this.llms = void 0;
    this.apiKey = init == null ? void 0 : init.apiKey;
    this.baseURL = init == null ? void 0 : init.baseURL;
    this.mode = init == null ? void 0 : init.mode;
    this.llms = init == null ? void 0 : init.llms;
    this.session = getPortkeySession({
      apiKey: this.apiKey,
      baseURL: this.baseURL,
      llms: this.llms,
      mode: this.mode
    });
    this.callbackManager = init == null ? void 0 : init.callbackManager;
  }
  tokens(messages) {
    throw new Error("Method not implemented.");
  }
  get metadata() {
    throw new Error("metadata not implemented for Portkey");
  }
  chat(messages, parentEvent, streaming, params) {
    return __async(this, null, function* () {
      var _a, _b, _c;
      if (streaming) {
        return this.streamChat(messages, parentEvent, params);
      } else {
        const resolvedParams = params || {};
        const response = yield this.session.portkey.chatCompletions.create(__spreadValues({
          messages
        }, resolvedParams));
        const content = (_b = (_a = response.choices[0].message) == null ? void 0 : _a.content) != null ? _b : "";
        const role = ((_c = response.choices[0].message) == null ? void 0 : _c.role) || "assistant";
        return { message: { content, role } };
      }
    });
  }
  complete(prompt, parentEvent, streaming) {
    return __async(this, null, function* () {
      return this.chat(
        [{ content: prompt, role: "user" }],
        parentEvent,
        streaming
      );
    });
  }
  streamChat(messages, parentEvent, params) {
    return __asyncGenerator(this, null, function* () {
      var _a, _b, _c;
      const onLLMStream = ((_a = this.callbackManager) == null ? void 0 : _a.onLLMStream) ? this.callbackManager.onLLMStream : () => {
      };
      const chunkStream = yield new __await(this.session.portkey.chatCompletions.create(__spreadProps(__spreadValues({
        messages
      }, params), {
        stream: true
      })));
      const event = parentEvent ? parentEvent : {
        id: "unspecified",
        type: "llmPredict"
      };
      var idx_counter = 0;
      try {
        for (var iter = __forAwait(chunkStream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          part.choices[0].index = idx_counter;
          const is_done = part.choices[0].finish_reason === "stop" ? true : false;
          const stream_callback = {
            event,
            index: idx_counter,
            isDone: is_done
            // token: part,
          };
          onLLMStream(stream_callback);
          idx_counter++;
          yield (_c = (_b = part.choices[0].delta) == null ? void 0 : _b.content) != null ? _c : "";
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      return;
    });
  }
  streamComplete(query, parentEvent) {
    return this.streamChat([{ content: query, role: "user" }], parentEvent);
  }
};

// src/TextSplitter.ts
var TextSplit = class {
  constructor(textChunk, numCharOverlap = void 0) {
    this.textChunk = textChunk;
    this.numCharOverlap = numCharOverlap;
  }
};
var englishSentenceTokenizer = (text) => {
  return text.match(/.+?[.?!]+[\])'"`]*(?:\s|$)|.+/g);
};
var cjkSentenceTokenizer = (text) => {
  return text.match(
    /.+?[.?!]+[\])'"`]*(?:\s|$)|.+?[]+[\])'"`]*(?:\s|$)?|.+/g
  );
};
var unixLineSeparator = "\n";
var windowsLineSeparator = "\r\n";
var unixParagraphSeparator = unixLineSeparator + unixLineSeparator;
var windowsParagraphSeparator = windowsLineSeparator + windowsLineSeparator;
var SentenceSplitter = class {
  constructor(options) {
    const {
      chunkSize = DEFAULT_CHUNK_SIZE,
      chunkOverlap = DEFAULT_CHUNK_OVERLAP,
      tokenizer = null,
      tokenizerDecoder = null,
      paragraphSeparator = unixParagraphSeparator,
      chunkingTokenizerFn = void 0,
      splitLongSentences = false
    } = options != null ? options : {};
    if (chunkOverlap > chunkSize) {
      throw new Error(
        `Got a larger chunk overlap (${chunkOverlap}) than chunk size (${chunkSize}), should be smaller.`
      );
    }
    this.chunkSize = chunkSize;
    this.chunkOverlap = chunkOverlap;
    this.tokenizer = tokenizer != null ? tokenizer : globalsHelper.tokenizer();
    this.tokenizerDecoder = tokenizerDecoder != null ? tokenizerDecoder : globalsHelper.tokenizerDecoder();
    this.paragraphSeparator = paragraphSeparator;
    this.chunkingTokenizerFn = chunkingTokenizerFn != null ? chunkingTokenizerFn : englishSentenceTokenizer;
    this.splitLongSentences = splitLongSentences;
  }
  getEffectiveChunkSize(extraInfoStr) {
    let effectiveChunkSize;
    if (extraInfoStr != void 0) {
      const numExtraTokens = this.tokenizer(`${extraInfoStr}

`).length + 1;
      effectiveChunkSize = this.chunkSize - numExtraTokens;
      if (effectiveChunkSize <= 0) {
        throw new Error(
          "Effective chunk size is non positive after considering extra_info"
        );
      }
    } else {
      effectiveChunkSize = this.chunkSize;
    }
    return effectiveChunkSize;
  }
  getParagraphSplits(text, effectiveChunkSize) {
    let paragraphSplits = text.split(this.paragraphSeparator);
    let idx = 0;
    if (effectiveChunkSize == void 0) {
      return paragraphSplits;
    }
    while (idx < paragraphSplits.length) {
      if (idx < paragraphSplits.length - 1 && paragraphSplits[idx].length < effectiveChunkSize) {
        paragraphSplits[idx] = [
          paragraphSplits[idx],
          paragraphSplits[idx + 1]
        ].join(this.paragraphSeparator);
        paragraphSplits.splice(idx + 1, 1);
      } else {
        idx += 1;
      }
    }
    return paragraphSplits;
  }
  getSentenceSplits(text, effectiveChunkSize) {
    let paragraphSplits = this.getParagraphSplits(text, effectiveChunkSize);
    let splits = [];
    for (const parText of paragraphSplits) {
      const sentenceSplits = this.chunkingTokenizerFn(parText);
      if (!sentenceSplits) {
        continue;
      }
      for (const sentence_split of sentenceSplits) {
        splits.push(sentence_split.trim());
      }
    }
    return splits;
  }
  /**
   * Splits sentences into chunks if necessary.
   *
   * This isn't great behavior because it can split down the middle of a
   * word or in non-English split down the middle of a Unicode codepoint
   * so the splitting is turned off by default. If you need it, please
   * set the splitLongSentences option to true.
   * @param sentenceSplits
   * @param effectiveChunkSize
   * @returns
   */
  processSentenceSplits(sentenceSplits, effectiveChunkSize) {
    if (!this.splitLongSentences) {
      return sentenceSplits.map((split) => ({
        text: split,
        numTokens: this.tokenizer(split).length
      }));
    }
    let newSplits = [];
    for (const split of sentenceSplits) {
      let splitTokens = this.tokenizer(split);
      const splitLen = splitTokens.length;
      if (splitLen <= effectiveChunkSize) {
        newSplits.push({ text: split, numTokens: splitLen });
      } else {
        for (let i = 0; i < splitLen; i += effectiveChunkSize) {
          const cur_split = this.tokenizerDecoder(
            splitTokens.slice(i, i + effectiveChunkSize)
          );
          newSplits.push({ text: cur_split, numTokens: effectiveChunkSize });
        }
      }
    }
    return newSplits;
  }
  combineTextSplits(newSentenceSplits, effectiveChunkSize) {
    let docs = [];
    let curChunkSentences = [];
    let curChunkTokens = 0;
    for (let i = 0; i < newSentenceSplits.length; i++) {
      if (curChunkTokens + newSentenceSplits[i].numTokens > effectiveChunkSize) {
        docs.push(
          new TextSplit(
            curChunkSentences.map((sentence) => sentence.text).join(" ").trim()
          )
        );
        const lastChunkSentences = curChunkSentences;
        curChunkTokens = 0;
        curChunkSentences = [];
        for (let j = lastChunkSentences.length - 1; j >= 0; j--) {
          if (curChunkTokens + lastChunkSentences[j].numTokens > this.chunkOverlap) {
            break;
          }
          curChunkSentences.unshift(lastChunkSentences[j]);
          curChunkTokens += lastChunkSentences[j].numTokens + 1;
        }
      }
      curChunkSentences.push(newSentenceSplits[i]);
      curChunkTokens += newSentenceSplits[i].numTokens + 1;
    }
    docs.push(
      new TextSplit(
        curChunkSentences.map((sentence) => sentence.text).join(" ").trim()
      )
    );
    return docs;
  }
  splitTextWithOverlaps(text, extraInfoStr) {
    if (text == "") {
      return [];
    }
    let effectiveChunkSize = this.getEffectiveChunkSize(extraInfoStr);
    let sentenceSplits = this.getSentenceSplits(text, effectiveChunkSize);
    let newSentenceSplits = this.processSentenceSplits(
      sentenceSplits,
      effectiveChunkSize
    );
    let combinedTextSplits = this.combineTextSplits(
      newSentenceSplits,
      effectiveChunkSize
    );
    return combinedTextSplits;
  }
  splitText(text, extraInfoStr) {
    const text_splits = this.splitTextWithOverlaps(text);
    const chunks = text_splits.map((text_split) => text_split.textChunk);
    return chunks;
  }
};

// src/NodeParser.ts
function getTextSplitsFromDocument(document, textSplitter) {
  const text = document.getText();
  const splits = textSplitter.splitText(text);
  return splits;
}
function getNodesFromDocument(doc, textSplitter, includeMetadata = true, includePrevNextRel = true) {
  if (doc instanceof ImageDocument) {
    return [doc];
  }
  if (!(doc instanceof Document)) {
    throw new Error("Expected either an Image Document or Document");
  }
  const document = doc;
  const nodes = [];
  const textSplits = getTextSplitsFromDocument(document, textSplitter);
  textSplits.forEach((textSplit) => {
    const node = new TextNode({
      text: textSplit,
      metadata: includeMetadata ? document.metadata : {}
    });
    node.relationships["SOURCE" /* SOURCE */] = document.asRelatedNodeInfo();
    nodes.push(node);
  });
  if (includePrevNextRel) {
    nodes.forEach((node, index) => {
      if (index > 0) {
        node.relationships["PREVIOUS" /* PREVIOUS */] = nodes[index - 1].asRelatedNodeInfo();
      }
      if (index < nodes.length - 1) {
        node.relationships["NEXT" /* NEXT */] = nodes[index + 1].asRelatedNodeInfo();
      }
    });
  }
  return nodes;
}
var SimpleNodeParser = class _SimpleNodeParser {
  constructor(init) {
    var _a, _b, _c, _d, _e;
    this.textSplitter = (_c = init == null ? void 0 : init.textSplitter) != null ? _c : new SentenceSplitter({
      chunkSize: (_a = init == null ? void 0 : init.chunkSize) != null ? _a : DEFAULT_CHUNK_SIZE,
      chunkOverlap: (_b = init == null ? void 0 : init.chunkOverlap) != null ? _b : DEFAULT_CHUNK_OVERLAP
    });
    this.includeMetadata = (_d = init == null ? void 0 : init.includeMetadata) != null ? _d : true;
    this.includePrevNextRel = (_e = init == null ? void 0 : init.includePrevNextRel) != null ? _e : true;
  }
  static fromDefaults(init) {
    return new _SimpleNodeParser(init);
  }
  /**
   * Generate Node objects from documents
   * @param documents
   */
  getNodesFromDocuments(documents) {
    return documents.map((document) => getNodesFromDocument(document, this.textSplitter)).flat();
  }
};

// src/PromptHelper.ts
function getEmptyPromptTxt(prompt) {
  return prompt({});
}
function getBiggestPrompt(prompts) {
  const emptyPromptTexts = prompts.map(getEmptyPromptTxt);
  const emptyPromptLengths = emptyPromptTexts.map((text) => text.length);
  const maxEmptyPromptLength = Math.max(...emptyPromptLengths);
  const maxEmptyPromptIndex = emptyPromptLengths.indexOf(maxEmptyPromptLength);
  return prompts[maxEmptyPromptIndex];
}
var PromptHelper = class {
  constructor(contextWindow = DEFAULT_CONTEXT_WINDOW, numOutput = DEFAULT_NUM_OUTPUTS, chunkOverlapRatio = DEFAULT_CHUNK_OVERLAP_RATIO, chunkSizeLimit, tokenizer, separator = " ") {
    this.contextWindow = DEFAULT_CONTEXT_WINDOW;
    this.numOutput = DEFAULT_NUM_OUTPUTS;
    this.chunkOverlapRatio = DEFAULT_CHUNK_OVERLAP_RATIO;
    this.separator = " ";
    this.contextWindow = contextWindow;
    this.numOutput = numOutput;
    this.chunkOverlapRatio = chunkOverlapRatio;
    this.chunkSizeLimit = chunkSizeLimit;
    this.tokenizer = tokenizer || globalsHelper.tokenizer();
    this.separator = separator;
  }
  /**
   * Given a prompt, return the maximum size of the inputs to the prompt.
   * @param prompt
   * @returns
   */
  getAvailableContextSize(prompt) {
    const emptyPromptText = getEmptyPromptTxt(prompt);
    const promptTokens = this.tokenizer(emptyPromptText);
    const numPromptTokens = promptTokens.length;
    return this.contextWindow - numPromptTokens - this.numOutput;
  }
  /**
   * Find the maximum size of each chunk given a prompt.
   * @param prompt
   * @param numChunks
   * @param padding
   * @returns
   */
  getAvailableChunkSize(prompt, numChunks = 1, padding = 5) {
    const availableContextSize = this.getAvailableContextSize(prompt);
    const result = Math.floor(availableContextSize / numChunks) - padding;
    if (this.chunkSizeLimit) {
      return Math.min(this.chunkSizeLimit, result);
    } else {
      return result;
    }
  }
  /**
   * Creates a text splitter with the correct chunk sizes and overlaps given a prompt.
   * @param prompt
   * @param numChunks
   * @param padding
   * @returns
   */
  getTextSplitterGivenPrompt(prompt, numChunks = 1, padding = DEFAULT_PADDING) {
    const chunkSize = this.getAvailableChunkSize(prompt, numChunks, padding);
    if (chunkSize === 0) {
      throw new Error("Got 0 as available chunk size");
    }
    const chunkOverlap = this.chunkOverlapRatio * chunkSize;
    const textSplitter = new SentenceSplitter({ chunkSize, chunkOverlap });
    return textSplitter;
  }
  /**
   * Repack resplits the strings based on the optimal text splitter.
   * @param prompt
   * @param textChunks
   * @param padding
   * @returns
   */
  repack(prompt, textChunks, padding = DEFAULT_PADDING) {
    const textSplitter = this.getTextSplitterGivenPrompt(prompt, 1, padding);
    const combinedStr = textChunks.join("\n\n");
    return textSplitter.splitText(combinedStr);
  }
};

// src/ServiceContext.ts
function serviceContextFromDefaults(options) {
  var _a, _b, _c, _d, _e;
  const callbackManager = (_a = options == null ? void 0 : options.callbackManager) != null ? _a : new CallbackManager();
  const serviceContext = {
    llm: (_b = options == null ? void 0 : options.llm) != null ? _b : new OpenAI2(),
    embedModel: (_c = options == null ? void 0 : options.embedModel) != null ? _c : new OpenAIEmbedding(),
    nodeParser: (_d = options == null ? void 0 : options.nodeParser) != null ? _d : new SimpleNodeParser({
      chunkSize: options == null ? void 0 : options.chunkSize,
      chunkOverlap: options == null ? void 0 : options.chunkOverlap
    }),
    promptHelper: (_e = options == null ? void 0 : options.promptHelper) != null ? _e : new PromptHelper(),
    callbackManager
  };
  return serviceContext;
}
function serviceContextFromServiceContext(serviceContext, options) {
  const newServiceContext = __spreadValues({}, serviceContext);
  if (options.llm) {
    newServiceContext.llm = options.llm;
  }
  if (options.promptHelper) {
    newServiceContext.promptHelper = options.promptHelper;
  }
  if (options.embedModel) {
    newServiceContext.embedModel = options.embedModel;
  }
  if (options.nodeParser) {
    newServiceContext.nodeParser = options.nodeParser;
  }
  if (options.callbackManager) {
    newServiceContext.callbackManager = options.callbackManager;
  }
  return newServiceContext;
}

// src/ChatEngine.ts
var SimpleChatEngine = class {
  constructor(init) {
    var _a, _b;
    this.chatHistory = (_a = init == null ? void 0 : init.chatHistory) != null ? _a : [];
    this.llm = (_b = init == null ? void 0 : init.llm) != null ? _b : new OpenAI2();
  }
  chat(message, chatHistory, streaming) {
    return __async(this, null, function* () {
      if (streaming) {
        return this.streamChat(message, chatHistory);
      }
      chatHistory = chatHistory != null ? chatHistory : this.chatHistory;
      chatHistory.push({ content: message, role: "user" });
      const response = yield this.llm.chat(chatHistory, void 0);
      chatHistory.push(response.message);
      this.chatHistory = chatHistory;
      return new Response(response.message.content);
    });
  }
  streamChat(message, chatHistory) {
    return __asyncGenerator(this, null, function* () {
      chatHistory = chatHistory != null ? chatHistory : this.chatHistory;
      chatHistory.push({ content: message, role: "user" });
      const response_generator = yield new __await(this.llm.chat(
        chatHistory,
        void 0,
        true
      ));
      var accumulator = "";
      try {
        for (var iter = __forAwait(response_generator), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          accumulator += part;
          yield part;
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      chatHistory.push({ content: accumulator, role: "assistant" });
      this.chatHistory = chatHistory;
      return;
    });
  }
  reset() {
    this.chatHistory = [];
  }
};
var CondenseQuestionChatEngine = class {
  constructor(init) {
    var _a, _b, _c;
    this.queryEngine = init.queryEngine;
    this.chatHistory = (_a = init == null ? void 0 : init.chatHistory) != null ? _a : [];
    this.serviceContext = (_b = init == null ? void 0 : init.serviceContext) != null ? _b : serviceContextFromDefaults({});
    this.condenseMessagePrompt = (_c = init == null ? void 0 : init.condenseMessagePrompt) != null ? _c : defaultCondenseQuestionPrompt;
  }
  condenseQuestion(chatHistory, question) {
    return __async(this, null, function* () {
      const chatHistoryStr = messagesToHistoryStr(chatHistory);
      return this.serviceContext.llm.complete(
        defaultCondenseQuestionPrompt({
          question,
          chatHistory: chatHistoryStr
        })
      );
    });
  }
  chat(message, chatHistory, streaming) {
    return __async(this, null, function* () {
      chatHistory = chatHistory != null ? chatHistory : this.chatHistory;
      const condensedQuestion = (yield this.condenseQuestion(chatHistory, extractText(message))).message.content;
      const response = yield this.queryEngine.query(condensedQuestion);
      chatHistory.push({ content: message, role: "user" });
      chatHistory.push({ content: response.response, role: "assistant" });
      return response;
    });
  }
  reset() {
    this.chatHistory = [];
  }
};
var DefaultContextGenerator = class {
  constructor(init) {
    var _a;
    this.retriever = init.retriever;
    this.contextSystemPrompt = (_a = init == null ? void 0 : init.contextSystemPrompt) != null ? _a : defaultContextSystemPrompt;
    this.nodePostprocessors = init.nodePostprocessors || [];
  }
  applyNodePostprocessors(nodes) {
    return this.nodePostprocessors.reduce(
      (nodes2, nodePostprocessor) => nodePostprocessor.postprocessNodes(nodes2),
      nodes
    );
  }
  generate(message, parentEvent) {
    return __async(this, null, function* () {
      if (!parentEvent) {
        parentEvent = {
          id: uuidv44(),
          type: "wrapper",
          tags: ["final"]
        };
      }
      const sourceNodesWithScore = yield this.retriever.retrieve(
        message,
        parentEvent
      );
      const nodes = this.applyNodePostprocessors(sourceNodesWithScore);
      return {
        message: {
          content: this.contextSystemPrompt({
            context: nodes.map((r) => r.node.text).join("\n\n")
          }),
          role: "system"
        },
        nodes
      };
    });
  }
};
var ContextChatEngine = class {
  constructor(init) {
    var _a, _b;
    this.chatModel = (_a = init.chatModel) != null ? _a : new OpenAI2({ model: "gpt-3.5-turbo-16k" });
    this.chatHistory = (_b = init == null ? void 0 : init.chatHistory) != null ? _b : [];
    this.contextGenerator = new DefaultContextGenerator({
      retriever: init.retriever,
      contextSystemPrompt: init == null ? void 0 : init.contextSystemPrompt
    });
  }
  chat(message, chatHistory, streaming) {
    return __async(this, null, function* () {
      chatHistory = chatHistory != null ? chatHistory : this.chatHistory;
      if (streaming) {
        return this.streamChat(message, chatHistory);
      }
      const parentEvent = {
        id: uuidv44(),
        type: "wrapper",
        tags: ["final"]
      };
      const context = yield this.contextGenerator.generate(
        extractText(message),
        parentEvent
      );
      chatHistory.push({ content: message, role: "user" });
      const response = yield this.chatModel.chat(
        [context.message, ...chatHistory],
        parentEvent
      );
      chatHistory.push(response.message);
      this.chatHistory = chatHistory;
      return new Response(
        response.message.content,
        context.nodes.map((r) => r.node)
      );
    });
  }
  streamChat(message, chatHistory) {
    return __asyncGenerator(this, null, function* () {
      chatHistory = chatHistory != null ? chatHistory : this.chatHistory;
      const parentEvent = {
        id: uuidv44(),
        type: "wrapper",
        tags: ["final"]
      };
      const context = yield new __await(this.contextGenerator.generate(
        extractText(message),
        parentEvent
      ));
      chatHistory.push({ content: message, role: "user" });
      const response_stream = yield new __await(this.chatModel.chat(
        [context.message, ...chatHistory],
        parentEvent,
        true
      ));
      var accumulator = "";
      try {
        for (var iter = __forAwait(response_stream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          accumulator += part;
          yield part;
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      chatHistory.push({ content: accumulator, role: "assistant" });
      this.chatHistory = chatHistory;
      return;
    });
  }
  reset() {
    this.chatHistory = [];
  }
};
function extractText(message) {
  if (Array.isArray(message)) {
    return message.filter((c) => c.type === "text").map((c) => c.text).join("\n\n");
  }
  return message;
}
var HistoryChatEngine = class {
  constructor(init) {
    var _a;
    this.llm = (_a = init == null ? void 0 : init.llm) != null ? _a : new OpenAI2();
    this.contextGenerator = init == null ? void 0 : init.contextGenerator;
  }
  chat(message, chatHistory, streaming) {
    return __async(this, null, function* () {
      if (streaming) {
        return this.streamChat(message, chatHistory);
      }
      const requestMessages = yield this.prepareRequestMessages(
        message,
        chatHistory
      );
      const response = yield this.llm.chat(requestMessages);
      chatHistory.addMessage(response.message);
      return new Response(response.message.content);
    });
  }
  streamChat(message, chatHistory) {
    return __asyncGenerator(this, null, function* () {
      const requestMessages = yield new __await(this.prepareRequestMessages(
        message,
        chatHistory
      ));
      const response_stream = yield new __await(this.llm.chat(
        requestMessages,
        void 0,
        true
      ));
      var accumulator = "";
      try {
        for (var iter = __forAwait(response_stream), more, temp, error; more = !(temp = yield new __await(iter.next())).done; more = false) {
          const part = temp.value;
          accumulator += part;
          yield part;
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield new __await(temp.call(iter)));
        } finally {
          if (error)
            throw error[0];
        }
      }
      chatHistory.addMessage({
        content: accumulator,
        role: "assistant"
      });
      return;
    });
  }
  prepareRequestMessages(message, chatHistory) {
    return __async(this, null, function* () {
      chatHistory.addMessage({
        content: message,
        role: "user"
      });
      let requestMessages;
      let context;
      if (this.contextGenerator) {
        const textOnly = extractText(message);
        context = yield this.contextGenerator.generate(textOnly);
      }
      requestMessages = yield chatHistory.requestMessages(
        context ? [context.message] : void 0
      );
      return requestMessages;
    });
  }
};

// src/ChatHistory.ts
var SimpleChatHistory = class {
  constructor(init) {
    var _a;
    this.messages = (_a = init == null ? void 0 : init.messages) != null ? _a : [];
    this.messagesBefore = this.messages.length;
  }
  addMessage(message) {
    this.messages.push(message);
  }
  requestMessages(transientMessages) {
    return __async(this, null, function* () {
      return [...transientMessages != null ? transientMessages : [], ...this.messages];
    });
  }
  reset() {
    this.messages = [];
  }
  newMessages() {
    const newMessages = this.messages.slice(this.messagesBefore);
    this.messagesBefore = this.messages.length;
    return newMessages;
  }
};
var SummaryChatHistory = class {
  constructor(init) {
    var _a, _b, _c;
    this.messages = (_a = init == null ? void 0 : init.messages) != null ? _a : [];
    this.messagesBefore = this.messages.length;
    this.summaryPrompt = (_b = init == null ? void 0 : init.summaryPrompt) != null ? _b : defaultSummaryPrompt;
    this.llm = (_c = init == null ? void 0 : init.llm) != null ? _c : new OpenAI2();
    if (!this.llm.metadata.maxTokens) {
      throw new Error(
        "LLM maxTokens is not set. Needed so the summarizer ensures the context window size of the LLM."
      );
    }
    this.tokensToSummarize = this.llm.metadata.contextWindow - this.llm.metadata.maxTokens;
  }
  summarize() {
    return __async(this, null, function* () {
      const messagesToSummarize = this.calcConversationMessages();
      let promptMessages;
      do {
        promptMessages = [
          {
            content: this.summaryPrompt({
              context: messagesToHistoryStr(messagesToSummarize)
            }),
            role: "user"
          }
        ];
        messagesToSummarize.shift();
      } while (this.llm.tokens(promptMessages) > this.tokensToSummarize);
      const response = yield this.llm.chat(promptMessages);
      return { content: response.message.content, role: "memory" };
    });
  }
  addMessage(message) {
    this.messages.push(message);
  }
  // Find last summary message
  getLastSummaryIndex() {
    const reversedMessages = this.messages.slice().reverse();
    const index = reversedMessages.findIndex(
      (message) => message.role === "memory"
    );
    if (index === -1) {
      return null;
    }
    return this.messages.length - 1 - index;
  }
  get systemMessages() {
    return this.messages.filter((message) => message.role === "system");
  }
  get nonSystemMessages() {
    return this.messages.filter((message) => message.role !== "system");
  }
  /**
   * Calculates the messages that describe the conversation so far.
   * If there's no memory, all non-system messages are used.
   * If there's a memory, uses all messages after the last summary message.
   */
  calcConversationMessages(transformSummary) {
    const lastSummaryIndex = this.getLastSummaryIndex();
    if (!lastSummaryIndex) {
      return this.nonSystemMessages;
    } else {
      const summaryMessage = transformSummary ? {
        content: `Summary of the conversation so far: ${this.messages[lastSummaryIndex].content}`,
        role: "system"
      } : this.messages[lastSummaryIndex];
      return [summaryMessage, ...this.messages.slice(lastSummaryIndex + 1)];
    }
  }
  calcCurrentRequestMessages(transientMessages) {
    return [
      ...this.systemMessages,
      ...transientMessages ? transientMessages : [],
      ...this.calcConversationMessages(true)
    ];
  }
  requestMessages(transientMessages) {
    return __async(this, null, function* () {
      const requestMessages = this.calcCurrentRequestMessages(transientMessages);
      const tokens = this.llm.tokens(requestMessages);
      if (tokens > this.tokensToSummarize) {
        const memoryMessage = yield this.summarize();
        const lastMessage = this.messages.at(-1);
        if (lastMessage && lastMessage.role === "user") {
          this.messages.pop();
          this.messages.push(memoryMessage);
          this.messages.push(lastMessage);
        } else {
          this.messages.push(memoryMessage);
        }
        return this.calcCurrentRequestMessages(transientMessages);
      }
      return requestMessages;
    });
  }
  reset() {
    this.messages = [];
  }
  newMessages() {
    const newMessages = this.messages.slice(this.messagesBefore);
    this.messagesBefore = this.messages.length;
    return newMessages;
  }
};

// src/OutputParser.ts
var OutputParserError = class _OutputParserError extends Error {
  constructor(message, options = {}) {
    super(message, options);
    this.name = "OutputParserError";
    if (!this.cause) {
      this.cause = options.cause;
    }
    this.output = options.output;
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, _OutputParserError);
    }
  }
};
function parseJsonMarkdown(text) {
  text = text.trim();
  const left_square = text.indexOf("[");
  const left_brace = text.indexOf("{");
  var left;
  var right;
  if (left_square < left_brace && left_square != -1) {
    left = left_square;
    right = text.lastIndexOf("]");
  } else {
    left = left_brace;
    right = text.lastIndexOf("}");
  }
  const jsonText = text.substring(left, right + 1);
  try {
    if (left_square === -1) {
      return [JSON.parse(jsonText)];
    }
    return JSON.parse(jsonText);
  } catch (e) {
    throw new OutputParserError("Not a json markdown", { output: text });
  }
}
var SubQuestionOutputParser = class {
  parse(output) {
    const parsed = parseJsonMarkdown(output);
    return { rawOutput: output, parsedOutput: parsed };
  }
  format(output) {
    return output;
  }
};

// src/QueryEngine.ts
import { v4 as uuidv45 } from "uuid";

// src/QuestionGenerator.ts
var LLMQuestionGenerator = class {
  constructor(init) {
    var _a, _b, _c;
    this.llm = (_a = init == null ? void 0 : init.llm) != null ? _a : new OpenAI2();
    this.prompt = (_b = init == null ? void 0 : init.prompt) != null ? _b : defaultSubQuestionPrompt;
    this.outputParser = (_c = init == null ? void 0 : init.outputParser) != null ? _c : new SubQuestionOutputParser();
  }
  generate(tools, query) {
    return __async(this, null, function* () {
      const toolsStr = buildToolsText(tools);
      const queryStr = query;
      const prediction = (yield this.llm.complete(
        this.prompt({
          toolsStr,
          queryStr
        })
      )).message.content;
      const structuredOutput = this.outputParser.parse(prediction);
      return structuredOutput.parsedOutput;
    });
  }
};

// src/synthesizers/MultiModalResponseSynthesizer.ts
var MultiModalResponseSynthesizer = class {
  constructor({
    serviceContext,
    textQATemplate,
    metadataMode
  } = {}) {
    this.serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults();
    this.metadataMode = metadataMode != null ? metadataMode : "NONE" /* NONE */;
    this.textQATemplate = textQATemplate != null ? textQATemplate : defaultTextQaPrompt;
  }
  synthesize(query, nodesWithScore, parentEvent) {
    return __async(this, null, function* () {
      const nodes = nodesWithScore.map(({ node }) => node);
      const { imageNodes, textNodes } = splitNodesByType(nodes);
      const textChunks = textNodes.map(
        (node) => node.getContent(this.metadataMode)
      );
      const context = textChunks.join("\n\n");
      const textPrompt = this.textQATemplate({ context, query });
      const images = yield Promise.all(
        imageNodes.map((node) => __async(this, null, function* () {
          return {
            type: "image_url",
            image_url: {
              url: yield imageToDataUrl(node.image)
            }
          };
        }))
      );
      const prompt = [
        { type: "text", text: textPrompt },
        ...images
      ];
      let response = yield this.serviceContext.llm.complete(prompt, parentEvent);
      return new Response(response.message.content, nodes);
    });
  }
};

// src/synthesizers/builders.ts
var SimpleResponseBuilder = class {
  constructor(serviceContext) {
    this.llm = serviceContext.llm;
    this.textQATemplate = defaultTextQaPrompt;
  }
  getResponse(query, textChunks, parentEvent) {
    return __async(this, null, function* () {
      const input = {
        query,
        context: textChunks.join("\n\n")
      };
      const prompt = this.textQATemplate(input);
      const response = yield this.llm.complete(prompt, parentEvent);
      return response.message.content;
    });
  }
};
var Refine = class {
  constructor(serviceContext, textQATemplate, refineTemplate) {
    this.serviceContext = serviceContext;
    this.textQATemplate = textQATemplate != null ? textQATemplate : defaultTextQaPrompt;
    this.refineTemplate = refineTemplate != null ? refineTemplate : defaultRefinePrompt;
  }
  getResponse(query, textChunks, parentEvent, prevResponse) {
    return __async(this, null, function* () {
      let response = void 0;
      for (const chunk of textChunks) {
        if (!prevResponse) {
          response = yield this.giveResponseSingle(query, chunk, parentEvent);
        } else {
          response = yield this.refineResponseSingle(
            prevResponse,
            query,
            chunk,
            parentEvent
          );
        }
        prevResponse = response;
      }
      return response != null ? response : "Empty Response";
    });
  }
  giveResponseSingle(queryStr, textChunk, parentEvent) {
    return __async(this, null, function* () {
      const textQATemplate = (input) => this.textQATemplate(__spreadProps(__spreadValues({}, input), { query: queryStr }));
      const textChunks = this.serviceContext.promptHelper.repack(textQATemplate, [
        textChunk
      ]);
      let response = void 0;
      for (const chunk of textChunks) {
        if (!response) {
          response = (yield this.serviceContext.llm.complete(
            textQATemplate({
              context: chunk
            }),
            parentEvent
          )).message.content;
        } else {
          response = yield this.refineResponseSingle(
            response,
            queryStr,
            chunk,
            parentEvent
          );
        }
      }
      return response != null ? response : "Empty Response";
    });
  }
  refineResponseSingle(response, queryStr, textChunk, parentEvent) {
    return __async(this, null, function* () {
      const refineTemplate = (input) => this.refineTemplate(__spreadProps(__spreadValues({}, input), { query: queryStr }));
      const textChunks = this.serviceContext.promptHelper.repack(refineTemplate, [
        textChunk
      ]);
      for (const chunk of textChunks) {
        response = (yield this.serviceContext.llm.complete(
          refineTemplate({
            context: chunk,
            existingAnswer: response
          }),
          parentEvent
        )).message.content;
      }
      return response;
    });
  }
};
var CompactAndRefine = class _CompactAndRefine extends Refine {
  getResponse(query, textChunks, parentEvent, prevResponse) {
    return __async(this, null, function* () {
      const textQATemplate = (input) => this.textQATemplate(__spreadProps(__spreadValues({}, input), { query }));
      const refineTemplate = (input) => this.refineTemplate(__spreadProps(__spreadValues({}, input), { query }));
      const maxPrompt = getBiggestPrompt([textQATemplate, refineTemplate]);
      const newTexts = this.serviceContext.promptHelper.repack(
        maxPrompt,
        textChunks
      );
      const response = __superGet(_CompactAndRefine.prototype, this, "getResponse").call(
        this,
        query,
        newTexts,
        parentEvent,
        prevResponse
      );
      return response;
    });
  }
};
var TreeSummarize = class {
  constructor(serviceContext, summaryTemplate) {
    this.serviceContext = serviceContext;
    this.summaryTemplate = summaryTemplate != null ? summaryTemplate : defaultTreeSummarizePrompt;
  }
  getResponse(query, textChunks, parentEvent) {
    return __async(this, null, function* () {
      if (!textChunks || textChunks.length === 0) {
        throw new Error("Must have at least one text chunk");
      }
      const packedTextChunks = this.serviceContext.promptHelper.repack(
        this.summaryTemplate,
        textChunks
      );
      if (packedTextChunks.length === 1) {
        return (yield this.serviceContext.llm.complete(
          this.summaryTemplate({
            context: packedTextChunks[0],
            query
          }),
          parentEvent
        )).message.content;
      } else {
        const summaries = yield Promise.all(
          packedTextChunks.map(
            (chunk) => this.serviceContext.llm.complete(
              this.summaryTemplate({
                context: chunk,
                query
              }),
              parentEvent
            )
          )
        );
        return this.getResponse(
          query,
          summaries.map((s) => s.message.content)
        );
      }
    });
  }
};
function getResponseBuilder(serviceContext, responseMode) {
  switch (responseMode) {
    case "simple" /* SIMPLE */:
      return new SimpleResponseBuilder(serviceContext);
    case "refine" /* REFINE */:
      return new Refine(serviceContext);
    case "tree_summarize" /* TREE_SUMMARIZE */:
      return new TreeSummarize(serviceContext);
    default:
      return new CompactAndRefine(serviceContext);
  }
}

// src/synthesizers/ResponseSynthesizer.ts
var ResponseSynthesizer = class {
  constructor({
    responseBuilder,
    serviceContext,
    metadataMode = "NONE" /* NONE */
  } = {}) {
    this.serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults();
    this.responseBuilder = responseBuilder != null ? responseBuilder : getResponseBuilder(this.serviceContext);
    this.metadataMode = metadataMode;
  }
  synthesize(query, nodesWithScore, parentEvent) {
    return __async(this, null, function* () {
      let textChunks = nodesWithScore.map(
        ({ node }) => node.getContent(this.metadataMode)
      );
      const response = yield this.responseBuilder.getResponse(
        query,
        textChunks,
        parentEvent
      );
      return new Response(
        response,
        nodesWithScore.map(({ node }) => node)
      );
    });
  }
};

// src/QueryEngine.ts
var RetrieverQueryEngine = class {
  constructor(retriever, responseSynthesizer, preFilters, nodePostprocessors) {
    this.retriever = retriever;
    const serviceContext = this.retriever.getServiceContext();
    this.responseSynthesizer = responseSynthesizer || new ResponseSynthesizer({ serviceContext });
    this.preFilters = preFilters;
    this.nodePostprocessors = nodePostprocessors || [];
  }
  applyNodePostprocessors(nodes) {
    return this.nodePostprocessors.reduce(
      (nodes2, nodePostprocessor) => nodePostprocessor.postprocessNodes(nodes2),
      nodes
    );
  }
  retrieve(query, parentEvent) {
    return __async(this, null, function* () {
      const nodes = yield this.retriever.retrieve(
        query,
        parentEvent,
        this.preFilters
      );
      return this.applyNodePostprocessors(nodes);
    });
  }
  query(query, parentEvent) {
    return __async(this, null, function* () {
      const _parentEvent = parentEvent || {
        id: uuidv45(),
        type: "wrapper",
        tags: ["final"]
      };
      const nodes = yield this.retrieve(query, _parentEvent);
      return this.responseSynthesizer.synthesize(query, nodes, _parentEvent);
    });
  }
};
var SubQuestionQueryEngine = class _SubQuestionQueryEngine {
  constructor(init) {
    var _a;
    this.questionGen = init.questionGen;
    this.responseSynthesizer = (_a = init.responseSynthesizer) != null ? _a : new ResponseSynthesizer();
    this.queryEngines = init.queryEngineTools.reduce((acc, tool) => {
      acc[tool.metadata.name] = tool.queryEngine;
      return acc;
    }, {});
    this.metadatas = init.queryEngineTools.map((tool) => tool.metadata);
  }
  static fromDefaults(init) {
    var _a, _b, _c;
    const serviceContext = (_a = init.serviceContext) != null ? _a : serviceContextFromDefaults({});
    const questionGen = (_b = init.questionGen) != null ? _b : new LLMQuestionGenerator();
    const responseSynthesizer = (_c = init.responseSynthesizer) != null ? _c : new ResponseSynthesizer({
      responseBuilder: new CompactAndRefine(serviceContext),
      serviceContext
    });
    return new _SubQuestionQueryEngine({
      questionGen,
      responseSynthesizer,
      queryEngineTools: init.queryEngineTools
    });
  }
  query(query) {
    return __async(this, null, function* () {
      const subQuestions = yield this.questionGen.generate(this.metadatas, query);
      const parentEvent = {
        id: uuidv45(),
        type: "wrapper",
        tags: ["final"]
      };
      const subQueryParentEvent = {
        id: uuidv45(),
        parentId: parentEvent.id,
        type: "wrapper",
        tags: ["intermediate"]
      };
      const subQNodes = yield Promise.all(
        subQuestions.map((subQ) => this.querySubQ(subQ, subQueryParentEvent))
      );
      const nodes = subQNodes.filter((node) => node !== null).map((node) => node);
      return this.responseSynthesizer.synthesize(query, nodes, parentEvent);
    });
  }
  querySubQ(subQ, parentEvent) {
    return __async(this, null, function* () {
      try {
        const question = subQ.subQuestion;
        const queryEngine = this.queryEngines[subQ.toolName];
        const response = yield queryEngine.query(question, parentEvent);
        const responseText = response.response;
        const nodeText = `Sub question: ${question}
Response: ${responseText}`;
        const node = new TextNode({ text: nodeText });
        return { node, score: 0 };
      } catch (error) {
        return null;
      }
    });
  }
};

// src/indices/BaseNodePostprocessor.ts
var SimilarityPostprocessor = class {
  constructor(options) {
    this.similarityCutoff = options == null ? void 0 : options.similarityCutoff;
  }
  postprocessNodes(nodes) {
    if (this.similarityCutoff === void 0)
      return nodes;
    const cutoff = this.similarityCutoff || 0;
    return nodes.filter((node) => node.score && node.score >= cutoff);
  }
};

// src/indices/keyword/utils.ts
import rake from "rake-modified";
function expandTokensWithSubtokens(tokens) {
  const results = /* @__PURE__ */ new Set();
  const regex = /\w+/g;
  for (let token of tokens) {
    results.add(token);
    const subTokens = token.match(regex);
    if (subTokens && subTokens.length > 1) {
      for (let w of subTokens) {
        results.add(w);
      }
    }
  }
  return results;
}
function extractKeywordsGivenResponse(response, startToken = "", lowercase = true) {
  const results = [];
  response = response.trim();
  if (response.startsWith(startToken)) {
    response = response.substring(startToken.length);
  }
  const keywords = response.split(",");
  for (let k of keywords) {
    let rk = k;
    if (lowercase) {
      rk = rk.toLowerCase();
    }
    results.push(rk.trim());
  }
  return expandTokensWithSubtokens(new Set(results));
}
function simpleExtractKeywords(textChunk, maxKeywords) {
  const regex = /\w+/g;
  let tokens = [...textChunk.matchAll(regex)].map(
    (token) => token[0].toLowerCase().trim()
  );
  const valueCounts = {};
  for (let token of tokens) {
    valueCounts[token] = (valueCounts[token] || 0) + 1;
  }
  const sortedTokens = Object.keys(valueCounts).sort(
    (a, b) => valueCounts[b] - valueCounts[a]
  );
  const keywords = maxKeywords ? sortedTokens.slice(0, maxKeywords) : sortedTokens;
  return new Set(keywords);
}
function rakeExtractKeywords(textChunk, maxKeywords) {
  const keywords = Object.keys(rake(textChunk));
  const limitedKeywords = maxKeywords ? keywords.slice(0, maxKeywords) : keywords;
  return new Set(limitedKeywords);
}

// src/indices/keyword/KeywordTableIndexRetriever.ts
var BaseKeywordTableRetriever = class {
  // A Query Keyword Extraction Prompt
  constructor({
    index,
    keywordExtractTemplate,
    queryKeywordExtractTemplate,
    maxKeywordsPerQuery = 10,
    numChunksPerQuery = 10
  }) {
    this.index = index;
    this.indexStruct = index.indexStruct;
    this.docstore = index.docStore;
    this.serviceContext = index.serviceContext;
    this.maxKeywordsPerQuery = maxKeywordsPerQuery;
    this.numChunksPerQuery = numChunksPerQuery;
    this.keywordExtractTemplate = keywordExtractTemplate || defaultKeywordExtractPrompt;
    this.queryKeywordExtractTemplate = queryKeywordExtractTemplate || defaultQueryKeywordExtractPrompt;
  }
  retrieve(query) {
    return __async(this, null, function* () {
      var _a;
      const keywords = yield this.getKeywords(query);
      const chunkIndicesCount = {};
      const filteredKeywords = keywords.filter(
        (keyword) => this.indexStruct.table.has(keyword)
      );
      for (let keyword of filteredKeywords) {
        for (let nodeId of this.indexStruct.table.get(keyword) || []) {
          chunkIndicesCount[nodeId] = ((_a = chunkIndicesCount[nodeId]) != null ? _a : 0) + 1;
        }
      }
      const sortedChunkIndices = Object.keys(chunkIndicesCount).sort((a, b) => chunkIndicesCount[b] - chunkIndicesCount[a]).slice(0, this.numChunksPerQuery);
      const sortedNodes = yield this.docstore.getNodes(sortedChunkIndices);
      return sortedNodes.map((node) => ({ node }));
    });
  }
  getServiceContext() {
    return this.index.serviceContext;
  }
};
var KeywordTableLLMRetriever = class extends BaseKeywordTableRetriever {
  getKeywords(query) {
    return __async(this, null, function* () {
      const response = yield this.serviceContext.llm.complete(
        this.queryKeywordExtractTemplate({
          question: query,
          maxKeywords: this.maxKeywordsPerQuery
        })
      );
      const keywords = extractKeywordsGivenResponse(
        response.message.content,
        "KEYWORDS:"
      );
      return [...keywords];
    });
  }
};
var KeywordTableSimpleRetriever = class extends BaseKeywordTableRetriever {
  getKeywords(query) {
    return Promise.resolve([
      ...simpleExtractKeywords(query, this.maxKeywordsPerQuery)
    ]);
  }
};
var KeywordTableRAKERetriever = class extends BaseKeywordTableRetriever {
  getKeywords(query) {
    return Promise.resolve([
      ...rakeExtractKeywords(query, this.maxKeywordsPerQuery)
    ]);
  }
};

// src/indices/keyword/KeywordTableIndex.ts
var KeywordTableRetrieverMode = /* @__PURE__ */ ((KeywordTableRetrieverMode2) => {
  KeywordTableRetrieverMode2["DEFAULT"] = "DEFAULT";
  KeywordTableRetrieverMode2["SIMPLE"] = "SIMPLE";
  KeywordTableRetrieverMode2["RAKE"] = "RAKE";
  return KeywordTableRetrieverMode2;
})(KeywordTableRetrieverMode || {});
var KeywordTableRetrieverMap = {
  ["DEFAULT" /* DEFAULT */]: KeywordTableLLMRetriever,
  ["SIMPLE" /* SIMPLE */]: KeywordTableSimpleRetriever,
  ["RAKE" /* RAKE */]: KeywordTableRAKERetriever
};
var KeywordTableIndex = class _KeywordTableIndex extends BaseIndex {
  constructor(init) {
    super(init);
  }
  static init(options) {
    return __async(this, null, function* () {
      var _a, _b;
      const storageContext = (_a = options.storageContext) != null ? _a : yield storageContextFromDefaults({});
      const serviceContext = (_b = options.serviceContext) != null ? _b : serviceContextFromDefaults({});
      const { docStore, indexStore } = storageContext;
      let indexStructs = yield indexStore.getIndexStructs();
      let indexStruct;
      if (options.indexStruct && indexStructs.length > 0) {
        throw new Error(
          "Cannot initialize index with both indexStruct and indexStore"
        );
      }
      if (options.indexStruct) {
        indexStruct = options.indexStruct;
      } else if (indexStructs.length == 1) {
        indexStruct = indexStructs[0];
      } else if (indexStructs.length > 1 && options.indexId) {
        indexStruct = yield indexStore.getIndexStruct(
          options.indexId
        );
      } else {
        indexStruct = null;
      }
      if (indexStruct && indexStruct.type !== "keyword_table" /* KEYWORD_TABLE */) {
        throw new Error(
          "Attempting to initialize KeywordTableIndex with non-keyword table indexStruct"
        );
      }
      if (indexStruct) {
        if (options.nodes) {
          throw new Error(
            "Cannot initialize KeywordTableIndex with both nodes and indexStruct"
          );
        }
      } else {
        if (!options.nodes) {
          throw new Error(
            "Cannot initialize KeywordTableIndex without nodes or indexStruct"
          );
        }
        indexStruct = yield _KeywordTableIndex.buildIndexFromNodes(
          options.nodes,
          storageContext.docStore,
          serviceContext
        );
        yield indexStore.addIndexStruct(indexStruct);
      }
      return new _KeywordTableIndex({
        storageContext,
        serviceContext,
        docStore,
        indexStore,
        indexStruct
      });
    });
  }
  asRetriever(options) {
    const _a = options != null ? options : {}, { mode = "DEFAULT" /* DEFAULT */ } = _a, otherOptions = __objRest(_a, ["mode"]);
    const KeywordTableRetriever = KeywordTableRetrieverMap[mode];
    if (KeywordTableRetriever) {
      return new KeywordTableRetriever(__spreadValues({ index: this }, otherOptions));
    }
    throw new Error(`Unknown retriever mode: ${mode}`);
  }
  asQueryEngine(options) {
    const { retriever, responseSynthesizer } = options != null ? options : {};
    return new RetrieverQueryEngine(
      retriever != null ? retriever : this.asRetriever(),
      responseSynthesizer,
      options == null ? void 0 : options.preFilters,
      options == null ? void 0 : options.nodePostprocessors
    );
  }
  static extractKeywords(text, serviceContext) {
    return __async(this, null, function* () {
      const response = yield serviceContext.llm.complete(
        defaultKeywordExtractPrompt({
          context: text
        })
      );
      return extractKeywordsGivenResponse(response.message.content, "KEYWORDS:");
    });
  }
  /**
   * High level API: split documents, get keywords, and build index.
   * @param documents
   * @param storageContext
   * @param serviceContext
   * @returns
   */
  static fromDocuments(_0) {
    return __async(this, arguments, function* (documents, args = {}) {
      let { storageContext, serviceContext } = args;
      storageContext = storageContext != null ? storageContext : yield storageContextFromDefaults({});
      serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults({});
      const docStore = storageContext.docStore;
      docStore.addDocuments(documents, true);
      for (const doc of documents) {
        docStore.setDocumentHash(doc.id_, doc.hash);
      }
      const nodes = serviceContext.nodeParser.getNodesFromDocuments(documents);
      const index = yield _KeywordTableIndex.init({
        nodes,
        storageContext,
        serviceContext
      });
      return index;
    });
  }
  /**
   * Get keywords for nodes and place them into the index.
   * @param nodes
   * @param serviceContext
   * @param vectorStore
   * @returns
   */
  static buildIndexFromNodes(nodes, docStore, serviceContext) {
    return __async(this, null, function* () {
      const indexStruct = new KeywordTable();
      yield docStore.addDocuments(nodes, true);
      for (const node of nodes) {
        const keywords = yield _KeywordTableIndex.extractKeywords(
          node.getContent("LLM" /* LLM */),
          serviceContext
        );
        indexStruct.addNode([...keywords], node.id_);
      }
      return indexStruct;
    });
  }
  insertNodes(nodes) {
    return __async(this, null, function* () {
      for (let node of nodes) {
        const keywords = yield _KeywordTableIndex.extractKeywords(
          node.getContent("LLM" /* LLM */),
          this.serviceContext
        );
        this.indexStruct.addNode([...keywords], node.id_);
      }
    });
  }
  deleteNode(nodeId) {
    const keywordsToDelete = /* @__PURE__ */ new Set();
    for (const [keyword, existingNodeIds] of Object.entries(
      this.indexStruct.table
    )) {
      const index = existingNodeIds.indexOf(nodeId);
      if (index !== -1) {
        existingNodeIds.splice(index, 1);
        if (existingNodeIds.length === 0) {
          keywordsToDelete.add(keyword);
        }
      }
    }
    this.indexStruct.deleteNode([...keywordsToDelete], nodeId);
  }
  deleteNodes(nodeIds, deleteFromDocStore) {
    return __async(this, null, function* () {
      nodeIds.forEach((nodeId) => {
        this.deleteNode(nodeId);
      });
      if (deleteFromDocStore) {
        for (const nodeId of nodeIds) {
          yield this.docStore.deleteDocument(nodeId, false);
        }
      }
      yield this.storageContext.indexStore.addIndexStruct(this.indexStruct);
    });
  }
  deleteRefDoc(refDocId, deleteFromDocStore) {
    return __async(this, null, function* () {
      const refDocInfo = yield this.docStore.getRefDocInfo(refDocId);
      if (!refDocInfo) {
        return;
      }
      yield this.deleteNodes(refDocInfo.nodeIds, false);
      if (deleteFromDocStore) {
        yield this.docStore.deleteRefDoc(refDocId, false);
      }
      return;
    });
  }
};

// src/indices/summary/SummaryIndex.ts
import _13 from "lodash";

// src/indices/summary/SummaryIndexRetriever.ts
import _12 from "lodash";

// src/indices/summary/utils.ts
import _11 from "lodash";
var defaultFormatNodeBatchFn = (summaryNodes) => {
  return summaryNodes.map((node, idx) => {
    return `
Document ${idx + 1}:
${node.getContent("LLM" /* LLM */)}
        `.trim();
  }).join("\n\n");
};
var defaultParseChoiceSelectAnswerFn = (answer, numChoices, raiseErr = false) => {
  const lineTokens = answer.split("\n").map((line) => {
    let lineTokens2 = line.split(",");
    if (lineTokens2.length !== 2) {
      if (raiseErr) {
        throw new Error(
          `Invalid answer line: ${line}. Answer line must be of the form: answer_num: <int>, answer_relevance: <float>`
        );
      } else {
        return null;
      }
    }
    return lineTokens2;
  }).filter((lineTokens2) => !_11.isNil(lineTokens2));
  return lineTokens.reduce(
    (parseResult, lineToken) => {
      try {
        let docNum = parseInt(lineToken[0].split(":")[1].trim());
        let answerRelevance = parseFloat(lineToken[1].split(":")[1].trim());
        if (docNum < 1 || docNum > numChoices) {
          if (raiseErr) {
            throw new Error(
              `Invalid answer number: ${docNum}. Answer number must be between 1 and ${numChoices}`
            );
          }
        } else {
          parseResult[docNum] = answerRelevance;
        }
      } catch (e) {
        if (raiseErr) {
          throw e;
        }
      }
      return parseResult;
    },
    {}
  );
};

// src/indices/summary/SummaryIndexRetriever.ts
var SummaryIndexRetriever = class {
  constructor(index) {
    this.index = index;
  }
  retrieve(query, parentEvent) {
    return __async(this, null, function* () {
      const nodeIds = this.index.indexStruct.nodes;
      const nodes = yield this.index.docStore.getNodes(nodeIds);
      const result = nodes.map((node) => ({
        node,
        score: 1
      }));
      if (this.index.serviceContext.callbackManager.onRetrieve) {
        this.index.serviceContext.callbackManager.onRetrieve({
          query,
          nodes: result,
          event: globalsHelper.createEvent({
            parentEvent,
            type: "retrieve"
          })
        });
      }
      return result;
    });
  }
  getServiceContext() {
    return this.index.serviceContext;
  }
};
var SummaryIndexLLMRetriever = class {
  constructor(index, choiceSelectPrompt, choiceBatchSize = 10, formatNodeBatchFn, parseChoiceSelectAnswerFn, serviceContext) {
    this.index = index;
    this.choiceSelectPrompt = choiceSelectPrompt || defaultChoiceSelectPrompt;
    this.choiceBatchSize = choiceBatchSize;
    this.formatNodeBatchFn = formatNodeBatchFn || defaultFormatNodeBatchFn;
    this.parseChoiceSelectAnswerFn = parseChoiceSelectAnswerFn || defaultParseChoiceSelectAnswerFn;
    this.serviceContext = serviceContext || index.serviceContext;
  }
  retrieve(query, parentEvent) {
    return __async(this, null, function* () {
      const nodeIds = this.index.indexStruct.nodes;
      const results = [];
      for (let idx = 0; idx < nodeIds.length; idx += this.choiceBatchSize) {
        const nodeIdsBatch = nodeIds.slice(idx, idx + this.choiceBatchSize);
        const nodesBatch = yield this.index.docStore.getNodes(nodeIdsBatch);
        const fmtBatchStr = this.formatNodeBatchFn(nodesBatch);
        const input = { context: fmtBatchStr, query };
        const rawResponse = (yield this.serviceContext.llm.complete(this.choiceSelectPrompt(input))).message.content;
        const parseResult = this.parseChoiceSelectAnswerFn(
          rawResponse,
          nodesBatch.length
        );
        const choiceNodeIds = nodeIdsBatch.filter((nodeId, idx2) => {
          return `${idx2}` in parseResult;
        });
        const choiceNodes = yield this.index.docStore.getNodes(choiceNodeIds);
        const nodeWithScores = choiceNodes.map((node, i) => ({
          node,
          score: _12.get(parseResult, `${i + 1}`, 1)
        }));
        results.push(...nodeWithScores);
      }
      if (this.serviceContext.callbackManager.onRetrieve) {
        this.serviceContext.callbackManager.onRetrieve({
          query,
          nodes: results,
          event: globalsHelper.createEvent({
            parentEvent,
            type: "retrieve"
          })
        });
      }
      return results;
    });
  }
  getServiceContext() {
    return this.serviceContext;
  }
};

// src/indices/summary/SummaryIndex.ts
var SummaryRetrieverMode = /* @__PURE__ */ ((SummaryRetrieverMode2) => {
  SummaryRetrieverMode2["DEFAULT"] = "default";
  SummaryRetrieverMode2["LLM"] = "llm";
  return SummaryRetrieverMode2;
})(SummaryRetrieverMode || {});
var SummaryIndex = class _SummaryIndex extends BaseIndex {
  constructor(init) {
    super(init);
  }
  static init(options) {
    return __async(this, null, function* () {
      var _a, _b;
      const storageContext = (_a = options.storageContext) != null ? _a : yield storageContextFromDefaults({});
      const serviceContext = (_b = options.serviceContext) != null ? _b : serviceContextFromDefaults({});
      const { docStore, indexStore } = storageContext;
      let indexStructs = yield indexStore.getIndexStructs();
      let indexStruct;
      if (options.indexStruct && indexStructs.length > 0) {
        throw new Error(
          "Cannot initialize index with both indexStruct and indexStore"
        );
      }
      if (options.indexStruct) {
        indexStruct = options.indexStruct;
      } else if (indexStructs.length == 1) {
        indexStruct = indexStructs[0];
      } else if (indexStructs.length > 1 && options.indexId) {
        indexStruct = yield indexStore.getIndexStruct(
          options.indexId
        );
      } else {
        indexStruct = null;
      }
      if (indexStruct && indexStruct.type !== "list" /* LIST */) {
        throw new Error(
          "Attempting to initialize SummaryIndex with non-list indexStruct"
        );
      }
      if (indexStruct) {
        if (options.nodes) {
          throw new Error(
            "Cannot initialize SummaryIndex with both nodes and indexStruct"
          );
        }
      } else {
        if (!options.nodes) {
          throw new Error(
            "Cannot initialize SummaryIndex without nodes or indexStruct"
          );
        }
        indexStruct = yield _SummaryIndex.buildIndexFromNodes(
          options.nodes,
          storageContext.docStore
        );
        yield indexStore.addIndexStruct(indexStruct);
      }
      return new _SummaryIndex({
        storageContext,
        serviceContext,
        docStore,
        indexStore,
        indexStruct
      });
    });
  }
  static fromDocuments(_0) {
    return __async(this, arguments, function* (documents, args = {}) {
      let { storageContext, serviceContext } = args;
      storageContext = storageContext != null ? storageContext : yield storageContextFromDefaults({});
      serviceContext = serviceContext != null ? serviceContext : serviceContextFromDefaults({});
      const docStore = storageContext.docStore;
      docStore.addDocuments(documents, true);
      for (const doc of documents) {
        docStore.setDocumentHash(doc.id_, doc.hash);
      }
      const nodes = serviceContext.nodeParser.getNodesFromDocuments(documents);
      const index = yield _SummaryIndex.init({
        nodes,
        storageContext,
        serviceContext
      });
      return index;
    });
  }
  asRetriever(options) {
    const { mode = "default" /* DEFAULT */ } = options != null ? options : {};
    switch (mode) {
      case "default" /* DEFAULT */:
        return new SummaryIndexRetriever(this);
      case "llm" /* LLM */:
        return new SummaryIndexLLMRetriever(this);
      default:
        throw new Error(`Unknown retriever mode: ${mode}`);
    }
  }
  asQueryEngine(options) {
    let { retriever, responseSynthesizer } = options != null ? options : {};
    if (!retriever) {
      retriever = this.asRetriever();
    }
    if (!responseSynthesizer) {
      let responseBuilder = new CompactAndRefine(this.serviceContext);
      responseSynthesizer = new ResponseSynthesizer({
        serviceContext: this.serviceContext,
        responseBuilder
      });
    }
    return new RetrieverQueryEngine(
      retriever,
      responseSynthesizer,
      options == null ? void 0 : options.preFilters,
      options == null ? void 0 : options.nodePostprocessors
    );
  }
  static buildIndexFromNodes(nodes, docStore, indexStruct) {
    return __async(this, null, function* () {
      indexStruct = indexStruct || new IndexList();
      yield docStore.addDocuments(nodes, true);
      for (const node of nodes) {
        indexStruct.addNode(node);
      }
      return indexStruct;
    });
  }
  insertNodes(nodes) {
    return __async(this, null, function* () {
      for (const node of nodes) {
        this.indexStruct.addNode(node);
      }
    });
  }
  deleteRefDoc(refDocId, deleteFromDocStore) {
    return __async(this, null, function* () {
      const refDocInfo = yield this.docStore.getRefDocInfo(refDocId);
      if (!refDocInfo) {
        return;
      }
      yield this.deleteNodes(refDocInfo.nodeIds, false);
      if (deleteFromDocStore) {
        yield this.docStore.deleteRefDoc(refDocId, false);
      }
      return;
    });
  }
  deleteNodes(nodeIds, deleteFromDocStore) {
    return __async(this, null, function* () {
      this.indexStruct.nodes = this.indexStruct.nodes.filter(
        (existingNodeId) => !nodeIds.includes(existingNodeId)
      );
      if (deleteFromDocStore) {
        for (const nodeId of nodeIds) {
          yield this.docStore.deleteDocument(nodeId, false);
        }
      }
      yield this.storageContext.indexStore.addIndexStruct(this.indexStruct);
    });
  }
  getRefDocInfo() {
    return __async(this, null, function* () {
      const nodeDocIds = this.indexStruct.nodes;
      const nodes = yield this.docStore.getNodes(nodeDocIds);
      const refDocInfoMap = {};
      for (const node of nodes) {
        const refNode = node.sourceNode;
        if (_13.isNil(refNode)) {
          continue;
        }
        const refDocInfo = yield this.docStore.getRefDocInfo(refNode.nodeId);
        if (_13.isNil(refDocInfo)) {
          continue;
        }
        refDocInfoMap[refNode.nodeId] = refDocInfo;
      }
      return refDocInfoMap;
    });
  }
};

// src/indices/vectorStore/VectorIndexRetriever.ts
var VectorIndexRetriever = class {
  constructor({
    index,
    similarityTopK,
    imageSimilarityTopK
  }) {
    this.index = index;
    this.serviceContext = this.index.serviceContext;
    this.similarityTopK = similarityTopK != null ? similarityTopK : DEFAULT_SIMILARITY_TOP_K;
    this.imageSimilarityTopK = imageSimilarityTopK != null ? imageSimilarityTopK : DEFAULT_SIMILARITY_TOP_K;
  }
  retrieve(query, parentEvent, preFilters) {
    return __async(this, null, function* () {
      let nodesWithScores = yield this.textRetrieve(query, preFilters);
      nodesWithScores = nodesWithScores.concat(
        yield this.textToImageRetrieve(query, preFilters)
      );
      this.sendEvent(query, nodesWithScores, parentEvent);
      return nodesWithScores;
    });
  }
  textRetrieve(query, preFilters) {
    return __async(this, null, function* () {
      const q = yield this.buildVectorStoreQuery(
        this.index.embedModel,
        query,
        this.similarityTopK
      );
      const result = yield this.index.vectorStore.query(q, preFilters);
      return this.buildNodeListFromQueryResult(result);
    });
  }
  textToImageRetrieve(query, preFilters) {
    return __async(this, null, function* () {
      if (!this.index.imageEmbedModel || !this.index.imageVectorStore) {
        return [];
      }
      const q = yield this.buildVectorStoreQuery(
        this.index.imageEmbedModel,
        query,
        this.imageSimilarityTopK
      );
      const result = yield this.index.imageVectorStore.query(q, preFilters);
      return this.buildNodeListFromQueryResult(result);
    });
  }
  sendEvent(query, nodesWithScores, parentEvent) {
    if (this.serviceContext.callbackManager.onRetrieve) {
      this.serviceContext.callbackManager.onRetrieve({
        query,
        nodes: nodesWithScores,
        event: globalsHelper.createEvent({
          parentEvent,
          type: "retrieve"
        })
      });
    }
  }
  buildVectorStoreQuery(embedModel, query, similarityTopK) {
    return __async(this, null, function* () {
      const queryEmbedding = yield embedModel.getQueryEmbedding(query);
      return {
        queryEmbedding,
        mode: "default" /* DEFAULT */,
        similarityTopK
      };
    });
  }
  buildNodeListFromQueryResult(result) {
    var _a;
    let nodesWithScores = [];
    for (let i = 0; i < result.ids.length; i++) {
      const nodeFromResult = (_a = result.nodes) == null ? void 0 : _a[i];
      if (!this.index.indexStruct.nodesDict[result.ids[i]] && nodeFromResult) {
        this.index.indexStruct.nodesDict[result.ids[i]] = nodeFromResult;
      }
      const node = this.index.indexStruct.nodesDict[result.ids[i]];
      if (node instanceof ImageNode) {
        node.image = node.getUrl();
      }
      nodesWithScores.push({
        node,
        score: result.similarities[i]
      });
    }
    return nodesWithScores;
  }
  getServiceContext() {
    return this.serviceContext;
  }
};

// src/indices/vectorStore/VectorStoreIndex.ts
var VectorStoreIndex = class _VectorStoreIndex extends BaseIndex {
  constructor(init) {
    var _a, _b;
    super(init);
    this.indexStore = init.indexStore;
    this.vectorStore = (_a = init.vectorStore) != null ? _a : init.storageContext.vectorStore;
    this.embedModel = init.serviceContext.embedModel;
    this.imageVectorStore = (_b = init.imageVectorStore) != null ? _b : init.storageContext.imageVectorStore;
    if (this.imageVectorStore) {
      this.imageEmbedModel = new ClipEmbedding();
    }
  }
  /**
   * The async init function creates a new VectorStoreIndex.
   * @param options
   * @returns
   */
  static init(options) {
    return __async(this, null, function* () {
      var _a, _b;
      const storageContext = (_a = options.storageContext) != null ? _a : yield storageContextFromDefaults({});
      const serviceContext = (_b = options.serviceContext) != null ? _b : serviceContextFromDefaults({});
      const indexStore = storageContext.indexStore;
      const docStore = storageContext.docStore;
      let indexStruct = yield _VectorStoreIndex.setupIndexStructFromStorage(
        indexStore,
        options
      );
      if (!options.nodes && !indexStruct) {
        throw new Error(
          "Cannot initialize VectorStoreIndex without nodes or indexStruct"
        );
      }
      indexStruct = indexStruct != null ? indexStruct : new IndexDict();
      const index = new this({
        storageContext,
        serviceContext,
        docStore,
        indexStruct,
        indexStore,
        vectorStore: options.vectorStore,
        imageVectorStore: options.imageVectorStore
      });
      if (options.nodes) {
        yield index.buildIndexFromNodes(options.nodes);
      }
      return index;
    });
  }
  static setupIndexStructFromStorage(indexStore, options) {
    return __async(this, null, function* () {
      let indexStructs = yield indexStore.getIndexStructs();
      let indexStruct;
      if (options.indexStruct && indexStructs.length > 0) {
        throw new Error(
          "Cannot initialize index with both indexStruct and indexStore"
        );
      }
      if (options.indexStruct) {
        indexStruct = options.indexStruct;
      } else if (indexStructs.length == 1) {
        indexStruct = indexStructs[0];
      } else if (indexStructs.length > 1 && options.indexId) {
        indexStruct = yield indexStore.getIndexStruct(
          options.indexId
        );
      }
      if (indexStruct && indexStruct.type !== "simple_dict" /* SIMPLE_DICT */) {
        throw new Error(
          "Attempting to initialize VectorStoreIndex with non-vector indexStruct"
        );
      }
      return indexStruct;
    });
  }
  /**
   * Get the embeddings for nodes.
   * @param nodes
   * @param logProgress log progress to console (useful for debugging)
   * @returns
   */
  getNodeEmbeddingResults(nodes, logProgress = false) {
    return __async(this, null, function* () {
      const nodesWithEmbeddings = [];
      for (let i = 0; i < nodes.length; ++i) {
        const node = nodes[i];
        if (logProgress) {
          console.log(`getting embedding for node ${i}/${nodes.length}`);
        }
        const embedding = yield this.embedModel.getTextEmbedding(
          node.getContent("EMBED" /* EMBED */)
        );
        node.embedding = embedding;
        nodesWithEmbeddings.push(node);
      }
      return nodesWithEmbeddings;
    });
  }
  /**
   * Get embeddings for nodes and place them into the index.
   * @param nodes
   * @returns
   */
  buildIndexFromNodes(nodes) {
    return __async(this, null, function* () {
      const newNodes = nodes.filter(
        (node) => Object.entries(this.indexStruct.nodesDict).reduce(
          (acc, [key, value]) => {
            if (value.hash === node.hash) {
              acc = false;
            }
            return acc;
          },
          true
        )
      );
      yield this.insertNodes(newNodes);
    });
  }
  /**
   * High level API: split documents, get embeddings, and build index.
   * @param documents
   * @param args
   * @returns
   */
  static fromDocuments(_0) {
    return __async(this, arguments, function* (documents, args = {}) {
      var _a, _b;
      args.storageContext = (_a = args.storageContext) != null ? _a : yield storageContextFromDefaults({});
      args.serviceContext = (_b = args.serviceContext) != null ? _b : serviceContextFromDefaults({});
      const docStore = args.storageContext.docStore;
      for (const doc of documents) {
        docStore.setDocumentHash(doc.id_, doc.hash);
      }
      args.nodes = args.serviceContext.nodeParser.getNodesFromDocuments(documents);
      return yield this.init(args);
    });
  }
  static fromVectorStore(vectorStore, serviceContext, imageVectorStore) {
    return __async(this, null, function* () {
      if (!vectorStore.storesText) {
        throw new Error(
          "Cannot initialize from a vector store that does not store text"
        );
      }
      const storageContext = yield storageContextFromDefaults({
        vectorStore,
        imageVectorStore
      });
      const index = yield this.init({
        nodes: [],
        storageContext,
        serviceContext
      });
      return index;
    });
  }
  asRetriever(options) {
    return new VectorIndexRetriever(__spreadValues({ index: this }, options));
  }
  asQueryEngine(options) {
    const { retriever, responseSynthesizer } = options != null ? options : {};
    return new RetrieverQueryEngine(
      retriever != null ? retriever : this.asRetriever(),
      responseSynthesizer,
      options == null ? void 0 : options.preFilters,
      options == null ? void 0 : options.nodePostprocessors
    );
  }
  insertNodesToStore(vectorStore, nodes) {
    return __async(this, null, function* () {
      const newIds = yield vectorStore.add(nodes);
      for (let i = 0; i < nodes.length; ++i) {
        const type = nodes[i].getType();
        if (!vectorStore.storesText || type === "INDEX" /* INDEX */ || type === "IMAGE" /* IMAGE */) {
          const nodeWithoutEmbedding = jsonToNode(nodes[i].toJSON());
          nodeWithoutEmbedding.embedding = void 0;
          this.indexStruct.addNode(nodeWithoutEmbedding, newIds[i]);
          this.docStore.addDocuments([nodeWithoutEmbedding], true);
        }
      }
    });
  }
  insertNodes(nodes) {
    return __async(this, null, function* () {
      if (!nodes || nodes.length === 0) {
        return;
      }
      const { imageNodes, textNodes } = splitNodesByType(nodes);
      if (imageNodes.length > 0) {
        if (!this.imageVectorStore) {
          throw new Error("Cannot insert image nodes without image vector store");
        }
        const imageNodesWithEmbedding = yield this.getImageNodeEmbeddingResults(imageNodes);
        yield this.insertNodesToStore(
          this.imageVectorStore,
          imageNodesWithEmbedding
        );
      }
      const embeddingResults = yield this.getNodeEmbeddingResults(textNodes);
      yield this.insertNodesToStore(this.vectorStore, embeddingResults);
      yield this.indexStore.addIndexStruct(this.indexStruct);
    });
  }
  deleteRefDoc(refDocId, deleteFromDocStore = true) {
    return __async(this, null, function* () {
      yield this.deleteRefDocFromStore(this.vectorStore, refDocId);
      if (this.imageVectorStore) {
        yield this.deleteRefDocFromStore(this.imageVectorStore, refDocId);
      }
      if (deleteFromDocStore) {
        yield this.docStore.deleteDocument(refDocId, false);
      }
    });
  }
  deleteRefDocFromStore(vectorStore, refDocId) {
    return __async(this, null, function* () {
      vectorStore.delete(refDocId);
      if (!vectorStore.storesText) {
        const refDocInfo = yield this.docStore.getRefDocInfo(refDocId);
        if (refDocInfo) {
          for (const nodeId of refDocInfo.nodeIds) {
            this.indexStruct.delete(nodeId);
            vectorStore.delete(nodeId);
          }
        }
        yield this.indexStore.addIndexStruct(this.indexStruct);
      }
    });
  }
  /**
   * Get the embeddings for image nodes.
   * @param nodes
   * @param serviceContext
   * @param logProgress log progress to console (useful for debugging)
   * @returns
   */
  getImageNodeEmbeddingResults(nodes, logProgress = false) {
    return __async(this, null, function* () {
      if (!this.imageEmbedModel) {
        return [];
      }
      const nodesWithEmbeddings = [];
      for (let i = 0; i < nodes.length; ++i) {
        const node = nodes[i];
        if (logProgress) {
          console.log(`getting embedding for node ${i}/${nodes.length}`);
        }
        node.embedding = yield this.imageEmbedModel.getImageEmbedding(node.image);
        nodesWithEmbeddings.push(node);
      }
      return nodesWithEmbeddings;
    });
  }
};

// src/readers/AssemblyAI.ts
import {
  AssemblyAI
} from "assemblyai";
var AssemblyAIReader = class {
  /**
   * Creates a new AssemblyAI Reader.
   * @param assemblyAIOptions The options to configure the AssemblyAI Reader.
   * Configure the `assemblyAIOptions.apiKey` with your AssemblyAI API key, or configure it as the `ASSEMBLYAI_API_KEY` environment variable.
   */
  constructor(assemblyAIOptions) {
    let options = assemblyAIOptions;
    if (!options) {
      options = {};
    }
    if (!options.apiKey) {
      options.apiKey = process.env.ASSEMBLYAI_API_KEY;
    }
    if (!options.apiKey) {
      throw new Error(
        "No AssemblyAI API key provided. Pass an `apiKey` option, or configure the `ASSEMBLYAI_API_KEY` environment variable."
      );
    }
    this.client = new AssemblyAI(options);
  }
  transcribeOrGetTranscript(params) {
    return __async(this, null, function* () {
      if (typeof params === "string") {
        return yield this.client.transcripts.get(params);
      } else {
        return yield this.client.transcripts.transcribe(params);
      }
    });
  }
  getTranscriptId(params) {
    return __async(this, null, function* () {
      if (typeof params === "string") {
        return params;
      } else {
        return (yield this.client.transcripts.transcribe(params)).id;
      }
    });
  }
};
var AudioTranscriptReader = class extends AssemblyAIReader {
  /**
   * Transcribe audio or get a transcript and load the transcript as a document using AssemblyAI.
   * @param params Parameters to transcribe an audio file or get an existing transcript.
   * @returns A promise that resolves to a single document containing the transcript text.
   */
  loadData(params) {
    return __async(this, null, function* () {
      const transcript = yield this.transcribeOrGetTranscript(params);
      return [new Document({ text: transcript.text || void 0 })];
    });
  }
};
var AudioTranscriptParagraphsReader = class extends AssemblyAIReader {
  /**
   * Transcribe audio or get a transcript, and returns a document for each paragraph.
   * @param params The parameters to transcribe audio or get an existing transcript.
   * @returns A promise that resolves to an array of documents, each containing a paragraph of the transcript.
   */
  loadData(params) {
    return __async(this, null, function* () {
      let transcriptId = yield this.getTranscriptId(params);
      const paragraphsResponse = yield this.client.transcripts.paragraphs(transcriptId);
      return paragraphsResponse.paragraphs.map(
        (p) => new Document({ text: p.text })
      );
    });
  }
};
var AudioTranscriptSentencesReader = class extends AssemblyAIReader {
  /**
   * Transcribe audio or get a transcript, and returns a document for each sentence.
   * @param params The parameters to transcribe audio or get an existing transcript.
   * @returns A promise that resolves to an array of documents, each containing a sentence of the transcript.
   */
  loadData(params) {
    return __async(this, null, function* () {
      let transcriptId = yield this.getTranscriptId(params);
      const sentencesResponse = yield this.client.transcripts.sentences(transcriptId);
      return sentencesResponse.sentences.map(
        (p) => new Document({ text: p.text })
      );
    });
  }
};
var AudioSubtitlesReader = class extends AssemblyAIReader {
  /**
   * Transcribe audio or get a transcript and reads subtitles for the transcript as `srt` or `vtt` format.
   * @param params The parameters to transcribe audio or get an existing transcript.
   * @param subtitleFormat The format of the subtitles, either `srt` or `vtt`.
   * @returns A promise that resolves a document containing the subtitles as the page content.
   */
  loadData(params, subtitleFormat = "srt") {
    return __async(this, null, function* () {
      let transcriptId = yield this.getTranscriptId(params);
      const subtitles = yield this.client.transcripts.subtitles(
        transcriptId,
        subtitleFormat
      );
      return [new Document({ text: subtitles })];
    });
  }
};

// src/readers/CSVReader.ts
import Papa from "papaparse";
var PapaCSVReader = class {
  /**
   * Constructs a new instance of the class.
   * @param {boolean} [concatRows=true] - whether to concatenate all rows into one document.If set to False, a Document will be created for each row.True by default.
   * @param {string} [colJoiner=', '] - Separator to use for joining cols per row. Set to ", " by default.
   * @param {string} [rowJoiner='\n'] - Separator to use for joining each row.Only used when `concat_rows=True`.Set to "\n" by default.
   */
  constructor(concatRows = true, colJoiner = ", ", rowJoiner = "\n", papaConfig) {
    this.concatRows = concatRows;
    this.colJoiner = colJoiner;
    this.rowJoiner = rowJoiner;
    this.papaConfig = papaConfig;
  }
  /**
   * Loads data from csv files
   * @param {string} file - The path to the file to load.
   * @param {GenericFileSystem} [fs=DEFAULT_FS] - The file system to use for reading the file.
   * @returns {Promise<Document[]>}
   */
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const fileContent = yield fs2.readFile(file, "utf-8");
      const result = Papa.parse(fileContent, this.papaConfig);
      const textList = result.data.map((row) => {
        const rowValues = Object.values(row).map((value) => String(value));
        return rowValues.join(this.colJoiner);
      });
      if (this.concatRows) {
        return [new Document({ text: textList.join(this.rowJoiner) })];
      } else {
        return textList.map((text) => new Document({ text }));
      }
    });
  }
};

// src/readers/HTMLReader.ts
var HTMLReader = class {
  /**
   * Public method for this reader.
   * Required by BaseReader interface.
   * @param file Path/name of the file to be loaded.
   * @param fs fs wrapper interface for getting the file content.
   * @returns Promise<Document[]> A Promise object, eventually yielding zero or one Document parsed from the HTML content of the specified file.
   */
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const dataBuffer = yield fs2.readFile(file, "utf-8");
      const htmlOptions = this.getOptions();
      const content = yield this.parseContent(dataBuffer, htmlOptions);
      return [new Document({ text: content, id_: file })];
    });
  }
  /**
   * Wrapper for string-strip-html usage.
   * @param html Raw HTML content to be parsed.
   * @param options An object of options for the underlying library
   * @see getOptions
   * @returns The HTML content, stripped of unwanted tags and attributes
   */
  parseContent(_0) {
    return __async(this, arguments, function* (html, options = {}) {
      const { stripHtml } = yield import("string-strip-html");
      return stripHtml(html).result;
    });
  }
  /**
   * Wrapper for our configuration options passed to string-strip-html library
   * @see https://codsen.com/os/string-strip-html/examples
   * @returns An object of options for the underlying library
   */
  getOptions() {
    return {
      skipHtmlDecoding: true,
      stripTogetherWithTheirContents: [
        "script",
        // default
        "style",
        // default
        "xml",
        // default
        "head"
        // <-- custom-added
      ]
      // Keep the URLs for embedded links
      // cb: (tag: any, deleteFrom: number, deleteTo: number, insert: string, rangesArr: any, proposedReturn: string) => {
      //   let temp;
      //   if (
      //     tag.name === "a" &&
      //     tag.attributes &&
      //     tag.attributes.some((attr: any) => {
      //       if (attr.name === "href") {
      //         temp = attr.value;
      //         return true;
      //       }
      //     })
      //   ) {
      //     rangesArr.push([deleteFrom, deleteTo, `${temp} ${insert || ""}`]);
      //   } else {
      //     rangesArr.push(proposedReturn);
      //   }
      // },
    };
  }
};

// src/readers/MarkdownReader.ts
var MarkdownReader = class {
  /**
   * @param {boolean} [removeHyperlinks=true] - Indicates whether hyperlinks should be removed.
   * @param {boolean} [removeImages=true] - Indicates whether images should be removed.
   */
  constructor(removeHyperlinks = true, removeImages = true) {
    this._removeHyperlinks = removeHyperlinks;
    this._removeImages = removeImages;
  }
  /**
   * Convert a markdown file to a dictionary.
   * The keys are the headers and the values are the text under each header.
   * @param {string} markdownText - The markdown text to convert.
   * @returns {Array<MarkdownTuple>} - An array of tuples, where each tuple contains a header (or null) and its corresponding text.
   */
  markdownToTups(markdownText) {
    const markdownTups = [];
    const lines = markdownText.split("\n");
    let currentHeader = null;
    let currentText = "";
    for (const line of lines) {
      const headerMatch = line.match(/^#+\s/);
      if (headerMatch) {
        if (currentHeader) {
          if (!currentText) {
            currentHeader += line + "\n";
            continue;
          }
          markdownTups.push([currentHeader, currentText]);
        }
        currentHeader = line;
        currentText = "";
      } else {
        currentText += line + "\n";
      }
    }
    markdownTups.push([currentHeader, currentText]);
    if (currentHeader) {
      markdownTups.map((tuple) => {
        var _a;
        return [
          ((_a = tuple[0]) == null ? void 0 : _a.replace(/#/g, "").trim()) || null,
          tuple[1].replace(/<.*?>/g, "")
        ];
      });
    } else {
      markdownTups.map((tuple) => [tuple[0], tuple[1].replace(/<.*?>/g, "")]);
    }
    return markdownTups;
  }
  removeImages(content) {
    const pattern = /!{1}\[\[(.*)\]\]/g;
    return content.replace(pattern, "");
  }
  removeHyperlinks(content) {
    const pattern = /\[(.*?)\]\((.*?)\)/g;
    return content.replace(pattern, "$1");
  }
  parseTups(content) {
    let modifiedContent = content;
    if (this._removeHyperlinks) {
      modifiedContent = this.removeHyperlinks(modifiedContent);
    }
    if (this._removeImages) {
      modifiedContent = this.removeImages(modifiedContent);
    }
    return this.markdownToTups(modifiedContent);
  }
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const content = yield fs2.readFile(file, { encoding: "utf-8" });
      const tups = this.parseTups(content);
      const results = [];
      for (const [header, value] of tups) {
        if (header) {
          results.push(
            new Document({
              text: `

${header}
${value}`
            })
          );
        } else {
          results.push(new Document({ text: value }));
        }
      }
      return results;
    });
  }
};

// src/readers/NotionReader.ts
import { crawler, pageToString } from "notion-md-crawler";
var NotionReader = class {
  /**
   * Constructor for the NotionReader class
   * @param {NotionReaderOptions} options - Configuration options for the reader
   */
  constructor({ client, serializers }) {
    this.crawl = crawler({ client, serializers });
  }
  /**
   * Converts Pages to an array of Document objects
   * @param {Pages} pages - The Notion pages to convert (Return value of `loadPages`)
   * @returns {Document[]} An array of Document objects
   */
  toDocuments(pages) {
    return Object.values(pages).map((page) => {
      const text = pageToString(page);
      return new Document({ text, metadata: page.metadata });
    });
  }
  /**
   * Loads recursively the Notion page with the specified root page ID.
   * @param {string} rootPageId - The root Notion page ID
   * @returns {Promise<Pages>} A Promise that resolves to a Pages object(Convertible with the `toDocuments` method)
   */
  loadPages(rootPageId) {
    return __async(this, null, function* () {
      return this.crawl(rootPageId);
    });
  }
  /**
   * Loads recursively Notion pages and converts them to an array of Document objects
   * @param {string} rootPageId - The root Notion page ID
   * @returns {Promise<Document[]>} A Promise that resolves to an array of Document objects
   */
  loadData(rootPageId) {
    return __async(this, null, function* () {
      const pages = yield this.loadPages(rootPageId);
      return this.toDocuments(pages);
    });
  }
};

// src/readers/PDFReader.ts
import pdfParse from "pdf-parse";
var PDFReader = class {
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const dataBuffer = yield fs2.readFile(file);
      const data = yield pdfParse(dataBuffer);
      return [new Document({ text: data.text, id_: file })];
    });
  }
};

// src/readers/SimpleDirectoryReader.ts
import _14 from "lodash";

// src/readers/DocxReader.ts
import mammoth from "mammoth";
var DocxReader = class {
  /** DocxParser */
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const dataBuffer = yield fs2.readFile(file);
      const { value } = yield mammoth.extractRawText({ buffer: dataBuffer });
      return [new Document({ text: value, id_: file })];
    });
  }
};

// src/readers/ImageReader.ts
var ImageReader = class {
  /**
   * Public method for this reader.
   * Required by BaseReader interface.
   * @param file Path/name of the file to be loaded.
   * @param fs fs wrapper interface for getting the file content.
   * @returns Promise<Document[]> A Promise object, eventually yielding zero or one ImageDocument of the specified file.
   */
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const dataBuffer = yield fs2.readFile(file);
      const blob = new Blob([dataBuffer]);
      return [new ImageDocument({ image: blob, id_: file })];
    });
  }
};

// src/readers/SimpleDirectoryReader.ts
var TextFileReader = class {
  loadData(_0) {
    return __async(this, arguments, function* (file, fs2 = DEFAULT_FS) {
      const dataBuffer = yield fs2.readFile(file, "utf-8");
      return [new Document({ text: dataBuffer, id_: file })];
    });
  }
};
var FILE_EXT_TO_READER = {
  txt: new TextFileReader(),
  pdf: new PDFReader(),
  csv: new PapaCSVReader(),
  md: new MarkdownReader(),
  docx: new DocxReader(),
  htm: new HTMLReader(),
  html: new HTMLReader(),
  jpg: new ImageReader(),
  jpeg: new ImageReader(),
  png: new ImageReader(),
  gif: new ImageReader()
};
var SimpleDirectoryReader = class {
  constructor(observer) {
    this.observer = observer;
  }
  loadData(_0) {
    return __async(this, arguments, function* ({
      directoryPath,
      fs: fs2 = DEFAULT_FS,
      defaultReader = new TextFileReader(),
      fileExtToReader = FILE_EXT_TO_READER
    }) {
      if (!this.doObserverCheck("directory", directoryPath, 0 /* STARTED */)) {
        return [];
      }
      let docs = [];
      try {
        for (var iter = __forAwait(walk(fs2, directoryPath)), more, temp, error; more = !(temp = yield iter.next()).done; more = false) {
          const filePath = temp.value;
          try {
            const fileExt = _14.last(filePath.split(".")) || "";
            if (!this.doObserverCheck("file", filePath, 0 /* STARTED */)) {
              continue;
            }
            let reader = null;
            if (fileExt in fileExtToReader) {
              reader = fileExtToReader[fileExt];
            } else if (!_14.isNil(defaultReader)) {
              reader = defaultReader;
            } else {
              const msg = `No reader for file extension of ${filePath}`;
              console.warn(msg);
              if (!this.doObserverCheck("file", filePath, 2 /* ERROR */, msg)) {
                return [];
              }
              continue;
            }
            const fileDocs = yield reader.loadData(filePath, fs2);
            if (this.doObserverCheck("file", filePath, 1 /* COMPLETE */)) {
              docs.push(...fileDocs);
            }
          } catch (e) {
            const msg = `Error reading file ${filePath}: ${e}`;
            console.error(msg);
            if (!this.doObserverCheck("file", filePath, 2 /* ERROR */, msg)) {
              return [];
            }
          }
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield temp.call(iter));
        } finally {
          if (error)
            throw error[0];
        }
      }
      this.doObserverCheck("directory", directoryPath, 1 /* COMPLETE */);
      return docs;
    });
  }
  doObserverCheck(category, name, status, message) {
    if (this.observer) {
      return this.observer(category, name, status, message);
    }
    return true;
  }
};

// src/readers/SimpleMongoReader.ts
var SimpleMongoReader = class {
  constructor(client) {
    this.client = client;
  }
  /**
   * Flattens an array of strings or string arrays into a single-dimensional array of strings.
   * @param texts - The array of strings or string arrays to flatten.
   * @returns The flattened array of strings.
   */
  flatten(texts) {
    return texts.reduce(
      (result, text) => result.concat(text instanceof Array ? text : [text]),
      []
    );
  }
  /**
   * Loads data from MongoDB collection
   * @param {string} dbName - The name of the database to load.
   * @param {string} collectionName - The name of the collection to load.
   * @param {string[]} fieldNames - An array of field names to retrieve from each document. Defaults to ["text"].
   * @param {string} separator - The separator to join multiple field values. Defaults to an empty string.
   * @param {Record<string, any>} filterQuery - Specific query, as specified by MongoDB NodeJS documentation.
   * @param {Number} maxDocs - The maximum number of documents to retrieve. Defaults to 0 (retrieve all documents).
   * @param {string[]} metadataNames - An optional array of metadata field names. If specified extracts this information as metadata.
   * @returns {Promise<Document[]>}
   * @throws If a field specified in fieldNames or metadataNames is not found in a MongoDB document.
   */
  loadData(_0, _1) {
    return __async(this, arguments, function* (dbName, collectionName, fieldNames = ["text"], separator = "", filterQuery = {}, maxDocs = 0, metadataNames) {
      const db = this.client.db(dbName);
      const cursor = db.collection(collectionName).find(filterQuery).limit(maxDocs);
      const documents = [];
      try {
        for (var iter = __forAwait(cursor), more, temp, error; more = !(temp = yield iter.next()).done; more = false) {
          const item = temp.value;
          try {
            const texts = fieldNames.map(
              (name) => item[name]
            );
            const flattenedTexts = this.flatten(texts);
            const text = flattenedTexts.join(separator);
            let metadata = {};
            if (metadataNames) {
              metadata = Object.fromEntries(
                metadataNames.map((name) => [name, item[name]])
              );
            }
            documents.push(new Document({ text, metadata }));
          } catch (err) {
            throw new Error(
              `Field not found in Mongo document: ${err.message}`
            );
          }
        }
      } catch (temp) {
        error = [temp];
      } finally {
        try {
          more && (temp = iter.return) && (yield temp.call(iter));
        } finally {
          if (error)
            throw error[0];
        }
      }
      return documents;
    });
  }
};
export {
  ALL_AVAILABLE_ANTHROPIC_MODELS,
  ALL_AVAILABLE_LLAMADEUCE_MODELS,
  ALL_AVAILABLE_MISTRAL_MODELS,
  ALL_AVAILABLE_OPENAI_MODELS,
  Anthropic2 as Anthropic,
  AstraDBVectorStore,
  AudioSubtitlesReader,
  AudioTranscriptParagraphsReader,
  AudioTranscriptReader,
  AudioTranscriptSentencesReader,
  BaseDocumentStore,
  BaseEmbedding,
  BaseInMemoryKVStore,
  BaseIndex,
  BaseIndexStore,
  BaseKVStore,
  BaseNode,
  CallbackManager,
  ClipEmbedding,
  ClipEmbeddingModelType,
  CompactAndRefine,
  CondenseQuestionChatEngine,
  ContextChatEngine,
  DEFAULT_CHUNK_OVERLAP,
  DEFAULT_CHUNK_OVERLAP_RATIO,
  DEFAULT_CHUNK_SIZE,
  DEFAULT_COLLECTION,
  DEFAULT_CONTEXT_WINDOW,
  DEFAULT_DOC_STORE_PERSIST_FILENAME,
  DEFAULT_EMBEDDING_DIM,
  DEFAULT_FS,
  DEFAULT_GRAPH_STORE_PERSIST_FILENAME,
  DEFAULT_IMAGE_VECTOR_NAMESPACE,
  DEFAULT_INDEX_STORE_PERSIST_FILENAME,
  DEFAULT_NAMESPACE,
  DEFAULT_NUM_OUTPUTS,
  DEFAULT_PADDING,
  DEFAULT_PERSIST_DIR,
  DEFAULT_SIMILARITY_TOP_K,
  DEFAULT_VECTOR_STORE_PERSIST_FILENAME,
  DefaultContextGenerator,
  DeuceChatStrategy,
  Document,
  FILE_EXT_TO_READER,
  GPT35_MODELS,
  GPT4_MODELS,
  HTMLReader,
  HistoryChatEngine,
  ImageDocument,
  ImageNode,
  InMemoryFileSystem,
  IndexDict,
  IndexList,
  IndexNode,
  IndexStruct,
  IndexStructType,
  KeywordTable,
  KeywordTableIndex,
  KeywordTableLLMRetriever,
  KeywordTableRAKERetriever,
  KeywordTableRetrieverMode,
  KeywordTableSimpleRetriever,
  LLMQuestionGenerator,
  LlamaDeuce,
  MarkdownReader,
  MetadataMode,
  MistralAI,
  MistralAIEmbedding,
  MistralAIEmbeddingModelType,
  MistralAISession,
  MongoDBAtlasVectorSearch,
  MultiModalEmbedding,
  MultiModalResponseSynthesizer,
  NodeRelationship,
  NotionReader,
  ObjectType,
  OpenAI2 as OpenAI,
  OpenAIEmbedding,
  OpenAIEmbeddingModelType,
  PDFReader,
  PGVectorStore,
  PapaCSVReader,
  Portkey2 as Portkey,
  PromptHelper,
  Refine,
  Response,
  ResponseSynthesizer,
  RetrieverQueryEngine,
  SentenceSplitter,
  SimilarityPostprocessor,
  SimilarityType,
  SimpleChatEngine,
  SimpleChatHistory,
  SimpleDirectoryReader,
  SimpleDocumentStore,
  SimpleIndexStore,
  SimpleKVStore,
  SimpleMongoReader,
  SimpleNodeParser,
  SimpleResponseBuilder,
  SimpleVectorStore,
  SubQuestionOutputParser,
  SubQuestionQueryEngine,
  SummaryChatHistory,
  SummaryIndex,
  SummaryIndexLLMRetriever,
  SummaryIndexRetriever,
  SummaryRetrieverMode,
  TextFileReader,
  TextNode,
  Tokenizers,
  TreeSummarize,
  VectorIndexRetriever,
  VectorStoreIndex,
  VectorStoreQueryMode,
  anthropicTextQaPrompt,
  buildToolsText,
  cjkSentenceTokenizer,
  defaultChoiceSelectPrompt,
  defaultCondenseQuestionPrompt,
  defaultContextSystemPrompt,
  defaultKeywordExtractPrompt,
  defaultQueryKeywordExtractPrompt,
  defaultRefinePrompt,
  defaultSubQuestionPrompt,
  defaultSummaryPrompt,
  defaultTextQaPrompt,
  defaultTreeSummarizePrompt,
  englishSentenceTokenizer,
  exists,
  getBiggestPrompt,
  getEmptyPromptTxt,
  getNodeFS,
  getNodesFromDocument,
  getResponseBuilder,
  getTextSplitsFromDocument,
  getTopKEmbeddings,
  getTopKEmbeddingsLearner,
  getTopKMMREmbeddings,
  globalsHelper,
  imageToDataUrl,
  imageToString,
  jsonToIndexStruct,
  jsonToNode,
  messagesToHistoryStr,
  parseJsonMarkdown,
  readImage,
  serviceContextFromDefaults,
  serviceContextFromServiceContext,
  similarity,
  splitNodesByType,
  storageContextFromDefaults,
  stringToImage,
  unixLineSeparator,
  unixParagraphSeparator,
  walk,
  windowsLineSeparator,
  windowsParagraphSeparator
};
